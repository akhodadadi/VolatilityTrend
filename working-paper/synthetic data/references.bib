
@article{odoherty_dissociable_2004,
	title = {Dissociable roles of ventral and dorsal striatum in instrumental conditioning},
	volume = {304},
	number = {5669},
	urldate = {2016-06-23},
	journal = {science},
	author = {O'Doherty, John and Dayan, Peter and Schultz, Johannes and Deichmann, Ralf and Friston, Karl and Dolan, Raymond J.},
	year = {2004},
	pages = {452--454},
	file = {[PDF] from caltech.edu:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\7DWQ6EUK\\O'Doherty et al. - 2004 - Dissociable roles of ventral and dorsal striatum i.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\NPQSB45C\\452.html:text/html}
}

@article{botvinick_hierarchical_2008,
	title = {Hierarchical models of behavior and prefrontal function},
	volume = {12},
	issn = {1364-6613},
	abstract = {The recognition of hierarchical structure in human behavior was one of the founding insights of the cognitive revolution. Despite decades of research, however, the computational mechanisms underlying hierarchically organized behavior are still not fully understood. Recent findings from behavioral and neuroscientific research have fueled a resurgence of interest in the problem, inspiring a new generation of computational models. In addition to developing some classic proposals, these models also break fresh ground, teasing apart different forms of hierarchical structure, placing a new focus on the issue of learning and addressing recent findings concerning the representation of behavioral hierarchies within the prefrontal cortex. In addition to offering explanations for some key aspects of behavior and functional neuroanatomy, the latest models also pose new questions for empirical research.},
	number = {5},
	journal = {Trends in cognitive sciences},
	author = {Botvinick, Matthew},
	month = may,
	year = {2008},
	keywords = {Behavior, Cognition, Computer Simulation, Humans, Learning, Models, Psychological, Neuroanatomy, Prefrontal Cortex, Reaction Time, Task Performance and Analysis},
	pages = {201--208}
}

@article{bogacz_physics_2006,
	title = {The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks},
	volume = {113},
	shorttitle = {The physics of optimal decision making},
	abstract = {In this article, the authors consider optimal decision making in two-alternative forced-choice (TAFC) tasks. They begin by analyzing 6 models of TAFC decision making and show that all but one can be reduced to the drift diffusion model, implementing the statistically optimal algorithm (most accurate for a given speed or fastest for a given accuracy). They prove further that there is always an optimal trade-off between speed and accuracy that maximizes various reward functions, including reward rate (percentage of correct responses per unit time), as well as several other objective functions, including ones weighted for accuracy. They use these findings to address empirical data and make novel predictions about performance under optimality.},
	number = {4},
	journal = {Psychological review},
	author = {Bogacz, Rafal and Brown, Eric and Moehlis, Jeff and Holmes, Philip and Cohen, Jonathan D},
	month = oct,
	year = {2006},
	keywords = {Choice Behavior, Coercion, decision making, Humans, Models, Psychological, Physics},
	pages = {700--765}
}

@article{zacksenhouse_robust_2010,
	title = {Robust versus optimal strategies for two-alternative forced choice tasks},
	volume = {54},
	issn = {0022-2496},
	abstract = {It has been proposed that animals and humans might choose a speed-accuracy tradeoff that maximizes reward rate. For this utility function the simple drift-diffusion model of two-alternative forced-choice tasks predicts a parameter-free optimal performance curve that relates normalized decision times to error rates under varying task conditions. However, behavioral data indicate that only ≈ 30 \% of subjects achieve optimality, and here we investigate the possibility that, in allowing for uncertainties, subjects might exercise robust strategies instead of optimal ones. We consider two strategies in which robustness is achieved by relinquishing performance: maximin and robust-satisficing. The former supposes maximization of guaranteed performance under a presumed level of uncertainty; the latter assumes that subjects require a critical performance level and maximize the level of uncertainty under which it can be guaranteed. These strategies respectively yield performance curves parameterized by a presumed uncertainty level and required performance. Maximin performance curves for uncertainties in response-to-stimulus interval match data for the lower-scoring 70 \% of subjects well, and are more likely to explain it than robust-satisficing or alternative optimal performance curves that emphasize accuracy. For uncertainties in signal-to-noise ratio, neither maximin nor robust-satisficing performance curves adequately describe the data. We discuss implications for decisions under uncertainties, and suggest further behavioral assays.},
	number = {2},
	urldate = {2016-12-30},
	journal = {Journal of Mathematical Psychology},
	author = {Zacksenhouse, M. and Bogacz, R. and Holmes, P.},
	month = apr,
	year = {2010},
	keywords = {decision making, Drift–diffusion models, Info-gap, Optimal decision making, Robust decision making, Two-alternative forced-choice, Uncertainties},
	pages = {230--246},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\T5NNUVAR\\Zacksenhouse et al. - 2010 - Robust versus optimal strategies for two-alternati.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\D72MVMJU\\S002224960900159X.html:text/html}
}

@article{kim_hyfis:_1999,
	title = {{HyFIS}: adaptive neuro-fuzzy inference systems and their application to nonlinear dynamical systems},
	volume = {12},
	abstract = {This paper proposes an adaptive neuro-fuzzy system, HyFIS (Hybrid neural Fuzzy Inference System), for building and optimising fuzzy models. The proposed model introduces the learning power of neural networks to fuzzy logic systems and provides linguistic meaning to the connectionist architectures. Heuristic fuzzy logic rules and input–output fuzzy membership functions can be optimally tuned from training examples by a hybrid learning scheme comprised of two phases: rule generation phase from data; and rule tuning phase using error backpropagation learning scheme for a neural fuzzy system. To illustrate the performance and applicability of the proposed neuro-fuzzy hybrid model, extensive simulation studies of nonlinear complex dynamic systems are carried out. The proposed method can be applied to an on-line incremental adaptive learning for the prediction and control of nonlinear dynamical systems. Two benchmark case studies are used to demonstrate that the proposed HyFIS system is a superior neuro-fuzzy modelling technique.},
	number = {9},
	urldate = {2016-08-02},
	journal = {Neural Networks},
	author = {Kim, J. and Kasabov, N.},
	month = nov,
	year = {1999},
	keywords = {Adaptation, Fuzzy logic, Knowledge acquisition, Neural networks, Neuro-fuzzy systems, Parameter and structure learning, Time series},
	pages = {1301--1319},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\Q8D4ERDQ\\Kim and Kasabov - 1999 - HyFIS adaptive neuro-fuzzy inference systems and .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\ARDKAKT8\\S0893608099000672.html:text/html}
}

@article{boyd_distributed_2011,
	title = {Distributed {Optimization} and {Statistical} {Learning} via the {Alternating} {Direction} {Method} of {Multipliers}},
	volume = {3},
	issn = {1935-8237},
	abstract = {Many problems of recent interest in statistics and machine learning can be posed in the framework of convex optimization. Due to the explosion in size and complexity of modern datasets, it is increasingly important to be able to solve problems with a very large number of features or training examples. As a result, both the decentralized collection or storage of these datasets as well as accompanying distributed solution methods are either necessary or at least highly desirable. In this review, we argue that the alternating direction method of multipliers is well suited to distributed convex optimization, and in particular to large-scale problems arising in statistics, machine learning, and related areas. The method was developed in the 1970s, with roots in the 1950s, and is equivalent or closely related to many other algorithms, such as dual decomposition, the method of multipliers, Douglas–Rachford splitting, Spingarn's method of partial inverses, Dykstra's alternating projections, Bregman iterative algorithms for ℓ1 problems, proximal methods, and others. After briefly surveying the theory and history of the algorithm, we discuss applications to a wide variety of statistical and machine learning problems of recent interest, including the lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, and many others. We also discuss general distributed optimization, extensions to the nonconvex setting, and efficient implementation, including some details on distributed MPI and Hadoop MapReduce implementations.},
	number = {1},
	journal = {Foundations and Trends in Machine Learning},
	author = {Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
	year = {2011},
	pages = {1--122}
}

@article{tsetsos_using_2012,
	title = {Using {Time}-{Varying} {Evidence} to {Test} {Models} of {Decision} {Dynamics}: {Bounded} {Diffusion} vs. the {Leaky} {Competing} {Accumulator} {Model}},
	volume = {6},
	issn = {1662-453X},
	abstract = {When people make decisions, do they give equal weight to evidence arriving at different times? A recent study (Kiani et al., 2008) using brief motion pulses (superimposed on a random moving dot display) reported a primacy effect: pulses presented early in a motion observation period had a stronger impact than pulses presented later. This observation was interpreted as supporting the bounded diffusion (BD) model and ruling out models in which evidence accumulation is subject to leakage or decay of early-arriving information. We use motion pulses and other manipulations of the timing of the perceptual evidence in new experiments and simulations that support the leaky competing accumulator (LCA) model as an alternative to the BD model. While the LCA does include leakage, we show that it can exhibit primacy as a result of competition between alternatives (implemented via mutual inhibition), when the inhibition is strong relative to the leak. Our experiments replicate the primacy effect when participants must be prepared to respond quickly at the end of a motion observation period. With less time pressure, however, the primacy effect is much weaker. For 2 (out of 10) participants, a primacy bias observed in trials where the motion observation period is short becomes weaker or reverses (becoming a recency effect) as the observation period lengthens. Our simulation studies show that primacy is equally consistent with the LCA or with BD. The transition from primacy-to-recency can also be captured by the LCA but not by BD. Individual differences and relations between the LCA and other models are discussed.},
	journal = {Frontiers in neuroscience},
	author = {Tsetsos, Konstantinos and Gao, Juan and McClelland, James L and Usher, Marius},
	year = {2012},
	pages = {79}
}

@article{churchland_decision-making_2008,
	title = {Decision-making with multiple alternatives},
	volume = {11},
	issn = {1097-6256},
	abstract = {Simple perceptual tasks have laid the groundwork for understanding the neurobiology of decision-making. Here, we examined this foundation to explain how decision-making circuitry adjusts in the face of a more difficult task. We measured behavioral and physiological responses of monkeys on a two- and four-choice direction-discrimination decision task. For both tasks, firing rates in the lateral intraparietal area appeared to reflect the accumulation of evidence for or against each choice. Evidence accumulation began at a lower firing rate for the four-choice task, but reached a common level by the end of the decision process. The larger excursion suggests that the subjects required more evidence before making a choice. Furthermore, on both tasks, we observed a time-dependent rise in firing rates that may impose a deadline for deciding. These physiological observations constitute an effective strategy for handling increased task difficulty. The differences appear to explain subjects' accuracy and reaction times.},
	number = {6},
	journal = {Nature Neuroscience},
	author = {Churchland, Anne K. and Kiani, Roozbeh and Shadlen, Michael N},
	month = jun,
	year = {2008},
	keywords = {Action Potentials, Animals, Behavior, Animal, decision making, Discrimination (Psychology), Eye Movements, Haplorhini, Motion, Neurons, Parietal Lobe, Reaction Time, Regression Analysis, Spatial Behavior, Task Performance and Analysis},
	pages = {693--702}
}

@article{brown_learned_2005,
	title = {Learned predictions of error likelihood in the anterior cingulate cortex},
	volume = {307},
	issn = {1095-9203},
	abstract = {The anterior cingulate cortex (ACC) and the related medial wall play a critical role in recruiting cognitive control. Although ACC exhibits selective error and conflict responses, it has been unclear how these develop and become context-specific. With use of a modified stop-signal task, we show from integrated computational neural modeling and neuroimaging studies that ACC learns to predict error likelihood in a given context, even for trials in which there is no error or response conflict. These results support a more general error-likelihood theory of ACC function based on reinforcement learning, of which conflict and error detection are special cases.},
	number = {5712},
	journal = {Science},
	author = {Brown, Joshua W and Braver, Todd S},
	month = feb,
	year = {2005},
	pmid = {15718473},
	keywords = {Brain Mapping, Cognition, Computer Simulation, Conflict (Psychology), Cues, Dopamine, Frontal Lobe, Gyrus Cinguli, Humans, Learning, Magnetic Resonance Imaging, Models, Neurological, Neural Networks (Computer), Neurons, Probability Learning, Psychomotor Performance, Reinforcement (Psychology)},
	pages = {1118--1121}
}

@article{ljung_perspectives_2010,
	title = {Perspectives on system identification},
	volume = {34},
	abstract = {System identification is the art and science of building mathematical models of dynamic systems from observed input–output data. It can be seen as the interface between the real world of applications and the mathematical world of control theory and model abstractions. As such, it is an ubiquitous necessity for successful applications. System identification is a very large topic, with different techniques that depend on the character of the models to be estimated: linear, nonlinear, hybrid, nonparametric, etc. At the same time, the area can be characterized by a small number of leading principles, e.g. to look for sustainable descriptions by proper decisions in the triangle of model complexity, information contents in the data, and effective validation. The area has many facets and there are many approaches and methods. A tutorial or a survey in a few pages is not quite possible. Instead, this presentation aims at giving an overview of the “science” side, i.e. basic principles and results and at pointing to open problem areas in the practical, “art”, side of how to approach and solve a real problem.},
	number = {1},
	urldate = {2016-12-13},
	journal = {Annual Reviews in Control},
	author = {Ljung, Lennart},
	month = apr,
	year = {2010},
	keywords = {Estimation, Mathematical Models, Non-linear models, Statistical methods, System identification},
	pages = {1--12},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\ZM8TEDBU\\Ljung - 2010 - Perspectives on system identification.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\Z4FSB4I9\\S1367578810000027.html:text/html}
}

@article{bogacz_integration_2011,
	title = {Integration of {Reinforcement} {Learning} and {Optimal} {Decision}-{Making} {Theories} of the {Basal} {Ganglia}},
	volume = {23},
	issn = {0899-7667},
	abstract = {This article seeks to integrate two sets of theories describing action selection in the basal ganglia: reinforcement learning theories describing learning which actions to select to maximize reward and decision-making theories proposing that the basal ganglia selects actions on the basis of sensory evidence accumulated in the cortex. In particular, we present a model that integrates the actor-critic model of reinforcement learning and a model assuming that the cortico-basal-ganglia circuit implements a statistically optimal decision-making procedure. The values of corico-striatal weights required for optimal decision making in our model differ from those provided by standard reinforcement learning models. Nevertheless, we show that an actor-critic model converges to the weights required for optimal decision making when biologically realistic limits on synaptic weights are introduced. We also describe the model's predictions concerning reaction times and neural responses during learning, and we discuss directions required for further integration of reinforcement learning and optimal decision-making theories.},
	number = {4},
	urldate = {2013-12-05},
	journal = {Neural Computation},
	author = {Bogacz, Rafal and Larsen, Tobias},
	month = jan,
	year = {2011},
	pages = {817--851}
}

@article{grice_stimulus_1968,
	title = {Stimulus intensity and response evocation},
	volume = {75},
	number = {5},
	journal = {Psychological Review},
	author = {Grice, G. R.},
	month = sep,
	year = {1968},
	pmid = {4879423},
	keywords = {Adaptation, Psychological, Conditioning, Operant, Humans, Methods, Models, Psychological, Reaction Time, Time Factors},
	pages = {359--373}
}

@article{das_solving_1999,
	title = {Solving {Semi}-{Markov} {Decision} {Problems} {Using} {Average} {Reward} {Reinforcement} {Learning}},
	volume = {45},
	issn = {0025-1909},
	abstract = {A large class of problems of sequential decision making under uncertainty, of which the underlying probability structure is a Markov process, can be modeled as stochastic dynamic programs (referred to, in general, as Markov decision problems or MDPs). However, the computational complexity of the classical MDP algorithms, such as value iteration and policy iteration, is prohibitive and can grow intractably with the size of the problem and its related data. Furthermore, these techniques require for each action the one step transition probability and reward matrices, and obtaining these is often unrealistic for large and complex systems. Recently, there has been much interest in a simulation-based stochastic approximation framework called reinforcement learning (RL), for computing near optimal policies for MDPs. RL has been successfully applied to very large problems, such as elevator scheduling, and dynamic channel allocation of cellular telephone systems. In this paper, we extend RL to a more general class of decision tasks that are referred to as semi-Markov decision problems (SMDPs). In particular, we focus on SMDPs under the average-reward criterion. We present a new model-free RL algorithm called SMART (Semi-Markov Average Reward Technique). We present a detailed study of this algorithm on a combinatorially large problem of determining the optimal preventive maintenance schedule of a production inventory system. Numerical results from both the theoretical model and the RL algorithm are presented and compared.},
	number = {4},
	urldate = {2013-11-19},
	journal = {Management Science},
	author = {Das, Tapas K. and Gosavi, Abhijit and Mahadevan, Sridhar and Marchalleck, Nicholas},
	month = apr,
	year = {1999},
	pages = {560--574},
	file = {JSTOR Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\EX2W37PU\\Das et al. - 1999 - Solving Semi-Markov Decision Problems Using Averag.pdf:application/pdf}
}

@book{karatzas_brownian_1991,
	address = {New York},
	edition = {2nd edition},
	title = {Brownian {Motion} and {Stochastic} {Calculus}},
	isbn = {978-0-387-97655-6},
	abstract = {A graduate-course text, written for readers familiar with measure-theoretic probability and discrete-time processes, wishing to explore stochastic processes in continuous time. The vehicle chosen for this exposition is Brownian motion, which is presented as the canonical example of both a martingale and a Markov process with continuous paths. In this context, the theory of stochastic integration and stochastic calculus is developed, illustrated by results concerning representations of martingales and change of measure on Wiener space, which in turn permit a presentation of recent advances in financial economics. The book contains a detailed discussion of weak and strong solutions of stochastic differential equations and a study of local time for semimartingales, with special emphasis on the theory of Brownian local time. The whole is backed by a large number of problems and exercises.},
	publisher = {Springer},
	author = {Karatzas, Ioannis and Shreve, Steven},
	year = {1991}
}

@article{niv_tonic_2007,
	title = {Tonic dopamine: opportunity costs and the control of response vigor},
	volume = {191},
	issn = {0033-3158},
	shorttitle = {Tonic dopamine},
	abstract = {RATIONALE: Dopamine neurotransmission has long been known to exert a powerful influence over the vigor, strength, or rate of responding. However, there exists no clear understanding of the computational foundation for this effect; predominant accounts of dopamine's computational function focus on a role for phasic dopamine in controlling the discrete selection between different actions and have nothing to say about response vigor or indeed the free-operant tasks in which it is typically measured.
OBJECTIVES: We seek to accommodate free-operant behavioral tasks within the realm of models of optimal control and thereby capture how dopaminergic and motivational manipulations affect response vigor.
METHODS: We construct an average reward reinforcement learning model in which subjects choose both which action to perform and also the latency with which to perform it. Optimal control balances the costs of acting quickly against the benefits of getting reward earlier and thereby chooses a best response latency.
RESULTS: In this framework, the long-run average rate of reward plays a key role as an opportunity cost and mediates motivational influences on rates and vigor of responding. We review evidence suggesting that the average reward rate is reported by tonic levels of dopamine putatively in the nucleus accumbens.
CONCLUSIONS: Our extension of reinforcement learning models to free-operant tasks unites psychologically and computationally inspired ideas about the role of tonic dopamine in striatum, explaining from a normative point of view why higher levels of dopamine might be associated with more vigorous responding.},
	number = {3},
	journal = {Psychopharmacology},
	author = {Niv, Yael and Daw, Nathaniel D and Joel, Daphna and Dayan, Peter},
	month = apr,
	year = {2007},
	keywords = {Animals, Brain, Choice Behavior, Conditioning, Operant, Dopamine, Models, Psychological, Motivation, Neurotransmitter Agents, Rats, Reaction Time, Reinforcement (Psychology), Reinforcement Schedule, Reward},
	pages = {507--520}
}

@article{abundo_double-barrier_2013,
	title = {The double-barrier inverse first-passage problem for {Wiener} process with random starting point},
	volume = {83},
	issn = {0167-7152},
	abstract = {We consider the double-barrier inverse first-passage time (IFPT) problem for Wiener process X ( t ) , starting from a random position η . Let a \&lt; b such that P ( a \&lt; η \&lt; b ) = 1 , and F an assigned distribution function. The problem consists of finding the distribution of η such that the first-exit time of X ( t ) from the interval ( a , b ) has distribution F . Besides results for the Brownian motion with drift, we obtain some extensions to more general one-dimensional diffusions and we show how to find an approximate solution to the IFPT problem in the case of time varying barriers.},
	number = {1},
	urldate = {2013-07-08},
	journal = {Statistics \& Probability Letters},
	author = {Abundo, Mario},
	month = jan,
	year = {2013},
	keywords = {Diffusion, First-passage time, Inverse first-passage problem},
	pages = {168--176},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\N7CJTHAQ\\Abundo - 2013 - The double-barrier inverse first-passage problem f.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\B7MRVT8V\\S0167715212003434.html:text/html}
}

@article{ratcliff_estimating_2002,
	title = {Estimating parameters of the diffusion model: {Approaches} to dealing with contaminant reaction times and parameter variability},
	volume = {9},
	issn = {1069-9384},
	shorttitle = {Estimating parameters of the diffusion model},
	abstract = {Three methods for fitting the diffusion model () to experimental data are examined. Sets of simulated data were generated with known parameter values, and from fits of the model, we found that the maximum likelihood method was better than the chi-square and weighted least squares methods by criteria of bias in the parameters relative to the parameter values used to generate the data and standard deviations in the parameter estimates. The standard deviations in the parameter values can be used as measures of the variability in parameter estimates from fits to experimental data. We introduced contaminant reaction times and variability into the other components of processing besides the decision process and found that the maximum likelihood and chi-square methods failed, sometimes dramatically. But the weighted least squares method was robust to these two factors. We then present results from modifications of the maximum likelihood and chi-square methods, in which these factors are explicitly modeled, and show that the parameter values of the diffusion model are recovered well. We argue that explicit modeling is an important method for addressing contaminants and variability in nondecision processes and that it can be applied in any theoretical approach to modeling reaction time.},
	number = {3},
	urldate = {2013-07-08},
	journal = {Psychonomic bulletin \& review},
	author = {Ratcliff, Roger and Tuerlinckx, Francis},
	month = sep,
	year = {2002},
	pmid = {12412886},
	pmcid = {PMC2474747},
	pages = {438--481},
	file = {PubMed Central Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\HHDXD23K\\Ratcliff and Tuerlinckx - 2002 - Estimating parameters of the diffusion model Appr.pdf:application/pdf}
}

@book{bertsekas_neuro-dynamic_1996,
	address = {Belmont, Mass.},
	title = {Neuro-dynamic programming},
	isbn = {1-886529-10-8 978-1-886529-10-6},
	publisher = {Athena Scientific},
	author = {Bertsekas, Dimitri P and Tsitsiklis, John N},
	year = {1996}
}

@article{frank_mechanisms_2012,
	title = {Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1: computational analysis},
	volume = {22},
	issn = {1460-2199},
	shorttitle = {Mechanisms of hierarchical reinforcement learning in corticostriatal circuits 1},
	abstract = {Growing evidence suggests that the prefrontal cortex (PFC) is organized hierarchically, with more anterior regions having increasingly abstract representations. How does this organization support hierarchical cognitive control and the rapid discovery of abstract action rules? We present computational models at different levels of description. A neural circuit model simulates interacting corticostriatal circuits organized hierarchically. In each circuit, the basal ganglia gate frontal actions, with some striatal units gating the inputs to PFC and others gating the outputs to influence response selection. Learning at all of these levels is accomplished via dopaminergic reward prediction error signals in each corticostriatal circuit. This functionality allows the system to exhibit conditional if-then hypothesis testing and to learn rapidly in environments with hierarchical structure. We also develop a hybrid Bayesian-reinforcement learning mixture of experts (MoE) model, which can estimate the most likely hypothesis state of individual participants based on their observed sequence of choices and rewards. This model yields accurate probabilistic estimates about which hypotheses are attended by manipulating attentional states in the generative neural model and recovering them with the MoE model. This 2-pronged modeling approach leads to multiple quantitative predictions that are tested with functional magnetic resonance imaging in the companion paper.},
	number = {3},
	journal = {Cerebral cortex (New York, N.Y.: 1991)},
	author = {Frank, Michael J and Badre, David},
	month = mar,
	year = {2012},
	pmid = {21693490},
	keywords = {Computer Simulation, Corpus Striatum, Humans, Learning, Models, Neurological, Neural Pathways, Neurons, Prefrontal Cortex, Reinforcement (Psychology)},
	pages = {509--526}
}

@article{cooper_contention_2000,
	title = {Contention scheduling and the control of routine activities},
	volume = {17},
	issn = {0264-3294},
	abstract = {The control of routine action is a complex process subject both to minor lapses in normals and to more severe breakdown following certain forms of neurological damage. A number of recent empirical studies (e.g. Humphreys \& Ford, 1998; Schwartz et al., 1991, 1995, 1998) have examined the details of breakdown in certain classes of patient, and attempted to relate the findings to existing psychological theory. This paper complements those studies by presenting a computational model of the selection of routine actions based on competitive activation within a hierarchically organised network of action schemas (cf. Norman \& Shallice, 1980, 1986). Simulations are reported which demonstrate that the model is capable of organised sequential action selection in a complex naturalistic domain. It is further demonstrated that, after lesioning, the model exhibits behaviour qualitatively equivalent to that observed by Schwartz et al., in their action disorganisation syndrome patients.},
	language = {eng},
	number = {4},
	journal = {Cognitive neuropsychology},
	author = {Cooper, R P and Shallice, T},
	month = jun,
	year = {2000},
	pmid = {20945185},
	pages = {297--338}
}

@article{hallac_network_2017,
	title = {Network {Inference} via the {Time}-{Varying} {Graphical} {Lasso}},
	abstract = {Many important problems can be modeled as a system of interconnected entities, where each entity is recording time-dependent observations or measurements. In order to spot trends, detect anomalies, and interpret the temporal dynamics of such data, it is essential to understand the relationships between the different entities and how these relationships evolve over time. In this paper, we introduce the time-varying graphical lasso (TVGL), a method of inferring time-varying networks from raw time series data. We cast the problem in terms of estimating a sparse time-varying inverse covariance matrix, which reveals a dynamic network of interdependencies between the entities. Since dynamic network inference is a computationally expensive task, we derive a scalable message-passing algorithm based on the Alternating Direction Method of Multipliers (ADMM) to solve this problem in an efficient way. We also discuss several extensions, including a streaming algorithm to update the model and incorporate new observations in real time. Finally, we evaluate our TVGL algorithm on both real and synthetic datasets, obtaining interpretable results and outperforming state-of-the-art baselines in terms of both accuracy and scalability.},
	journal = {arXiv:1703.01958 [cs, math]},
	author = {Hallac, David and Park, Youngsuk and Boyd, Stephen and Leskovec, Jure},
	month = mar,
	year = {2017},
	keywords = {Computer Science - Learning, Computer Science - Social and Information Networks, Mathematics - Optimization and Control},
	file = {arXiv\:1703.01958 PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\TT2RFQG5\\Hallac et al. - 2017 - Network Inference via the Time-Varying Graphical L.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\CHGPSGI2\\1703.html:text/html}
}

@article{bogacz_basal_2007,
	title = {The {Basal} {Ganglia} and {Cortex} {Implement} {Optimal} {Decision} {Making} {Between} {Alternative} {Actions}},
	volume = {19},
	issn = {0899-7667},
	url = {http://dx.doi.org/10.1162/neco.2007.19.2.442},
	abstract = {Neurophysiological studies have identified a number of brain regions critically involved in solving the problem of action selection or decision making. In the case of highly practiced tasks, these regions include cortical areas hypothesized to integrate evidence supporting alternative actions and the basal ganglia, hypothesized to act as a central switch in gating behavioral requests. However, despite our relatively detailed knowledge of basal ganglia biology and its connectivity with the cortex and numerical simulation studies demonstrating selective function, no formal theoretical framework exists that supplies an algorithmic description of these circuits. This article shows how many aspects of the anatomy and physiology of the circuit involving the cortex and basal ganglia are exactly those required to implement the computation defined by an asymptotically optimal statistical test for decision making: the multihypothesis sequential probability ratio test (MSPRT). The resulting model of basal ganglia provides a new framework for understanding the computation in the basal ganglia during decision making in highly practiced tasks. The predictions of the theory concerning the properties of particular neuronal populations are validated in existing experimental data. Further, we show that this neurobiologically grounded implementation of MSPRT outperforms other candidates for neural decision making, that it is structurally and parametrically robust, and that it can accommodate cortical mechanisms for decision making in a way that complements those in basal ganglia.},
	number = {2},
	urldate = {2013-12-05},
	journal = {Neural Computation},
	author = {Bogacz, Rafal and Gurney, Kevin},
	month = jan,
	year = {2007},
	pages = {442--477}
}

@book{fuster_prefrontal_1997,
	title = {The prefrontal cortex: anatomy, physiology, and neuropsychology of the frontal lobe},
	shorttitle = {The prefrontal cortex},
	language = {en},
	publisher = {Lippincott-Raven},
	author = {Fuster, J M},
	month = may,
	year = {1997},
	keywords = {Cerebral Cortex, Frontal Lobe - anatomy \& histology, Frontal Lobe/ anatomy \& histology, Frontal Lobe - physiology, Frontal lobes, Medical / Neurology, Medical / Neuroscience, Neuropsychology, Prefrontal Cortex, Social Science / Anthropology / Physical}
}

@article{smith_slowness_1995,
	title = {Slowness and age: speed-accuracy mechanisms},
	volume = {10},
	issn = {0882-7974},
	shorttitle = {Slowness and age},
	abstract = {Young and older adults' mechanisms of trial-by-trial control of accuracy and choice reaction times (RTs) were compared in 2,000 trials. With equal mean error rates, the older group's correct and error RT were longer, and their within-subject distribution was a linear function of the younger group's. Conditional accuracy functions (CAFs) were very similar in location and shape, with both groups achieving 95\% accuracy at the same RT. Combining RT distributions with CAFs showed that the older group did not track their limits as often as the younger group, and they were more careful, having fewer very fast (near random) responses, more average speed responses in long error-free runs, and more slowing following an error. All participants were faster before an error and slower immediately after, but the older participants had coarser RT control. To compensate for this, the older participants produced slower responding to avoid the very fast, high-error part of the CAF.},
	language = {eng},
	number = {2},
	journal = {Psychology and Aging},
	author = {Smith, G. A. and Brewer, N.},
	month = jun,
	year = {1995},
	pmid = {7662183},
	keywords = {Adolescent, Adult, Aged, Aging, Attention, Female, Humans, Male, Middle Aged, Psychomotor Performance, Reaction Time, Reference Values},
	pages = {238--247}
}

@article{ditterich_stochastic_2006,
	title = {Stochastic models of decisions about motion direction: behavior and physiology},
	volume = {19},
	shorttitle = {Stochastic models of decisions about motion direction},
	abstract = {Roitman and Shadlen [Roitman J. D., \& Shadlen M. N. (2002). Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task. Journal of Neuroscience, 22, 9475-9489] have published a non-human primate study on visual decision making. They collected both behavioral and neurophysiological data and provided evidence that the data are qualitatively consistent with a mechanism based on accumulating sensory evidence up to a decision threshold. I have previously demonstrated that a time-variant diffusion model can account quite well quantitatively for both the behavioral and the neural data. In this manuscript I discuss how well the data constrains different components and parameters of the computational process. I also discuss the biological plausibility of the model parameters. I will demonstrate that a relatively large class of models, both with and without temporal integration and both stationary and time-variant could account for the behavioral data. Both the single cell recordings from the parietal cortex and previously published data from the extrastriate visual cortex provide additional constraints. Overall, the data favor a diffusion model with time-variant gain and leaky integrators. The integration time constant, however, turns out not to be well-constrained by the data.},
	number = {8},
	journal = {Neural networks},
	author = {Ditterich, Jochen},
	month = oct,
	year = {2006},
	keywords = {Action Potentials, Animals, Behavior, Behavior, Animal, decision making, Discrimination (Psychology), Humans, Models, Biological, Models, Neurological, Motion, Motion Perception, Neurons, Reaction Time, Stochastic Processes, Time Factors, Visual Cortex},
	pages = {981--1012}
}

@article{smith_integrated_2009,
	title = {An integrated theory of attention and decision making in visual signal detection},
	volume = {116},
	issn = {0033-295X},
	abstract = {The simplest attentional task, detecting a cued stimulus in an otherwise empty visual field, produces complex patterns of performance. Attentional cues interact with backward masks and with spatial uncertainty, and there is a dissociation in the effects of these variables on accuracy and on response time. A computational theory of performance in this task is described. The theory links visual encoding, masking, spatial attention, visual short-term memory (VSTM), and perceptual decision making in an integrated dynamic framework. The theory assumes that decisions are made by a diffusion process driven by a neurally plausible, shunting VSTM. The VSTM trace encodes the transient outputs of early visual filters in a durable form that is preserved for the time needed to make a decision. Attention increases the efficiency of VSTM encoding, either by increasing the rate of trace formation or by reducing the delay before trace formation begins. The theory provides a detailed, quantitative account of attentional effects in spatial cuing tasks at the level of response accuracy and the response time distributions.},
	number = {2},
	journal = {Psychological Review},
	author = {Smith, Philip L. and Ratcliff, Roger},
	month = apr,
	year = {2009},
	keywords = {Attention, Cues, decision making, Humans, Psychological Theory, Reaction Time, Signal Detection, Psychological, Visual Perception},
	pages = {283--317}
}

@article{gu_continuous_2016,
	title = {Continuous {Deep} {Q}-{Learning} with {Model}-based {Acceleration}},
	abstract = {Model-free reinforcement learning has been successfully applied to a range of challenging problems, and has recently been extended to handle large neural network policies and value functions. However, the sample complexity of model-free algorithms, particularly when using high-dimensional function approximators, tends to limit their applicability to physical systems. In this paper, we explore algorithms and representations to reduce the sample complexity of deep reinforcement learning for continuous control tasks. We propose two complementary techniques for improving the efficiency of such algorithms. First, we derive a continuous variant of the Q-learning algorithm, which we call normalized adantage functions (NAF), as an alternative to the more commonly used policy gradient and actor-critic methods. NAF representation allows us to apply Q-learning with experience replay to continuous tasks, and substantially improves performance on a set of simulated robotic control tasks. To further improve the efficiency of our approach, we explore the use of learned models for accelerating model-free reinforcement learning. We show that iteratively refitted local linear models are especially effective for this, and demonstrate substantially faster learning on domains where such models are applicable.},
	urldate = {2016-12-13},
	journal = {arXiv:1603.00748 [cs]},
	author = {Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
	month = mar,
	year = {2016},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Learning, Computer Science - Robotics, Computer Science - Systems and Control},
	file = {arXiv\:1603.00748 PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\KV6ABU7S\\Gu et al. - 2016 - Continuous Deep Q-Learning with Model-based Accele.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\JTXI3PPN\\1603.html:text/html}
}

@phdthesis{daw_reinforcement_2003,
	type = {Unpublished doctoral dissertation},
	title = {Reinforcement learning models of the dopamine system and their behavioral implications},
	school = {Carnegie Mellon University},
	author = {Daw, Nathaniel D},
	year = {2003}
}

@article{wahlstrom_learning_2014,
	title = {Learning deep dynamical models from image pixels},
	abstract = {Modeling dynamical systems is important in many disciplines, e.g., control, robotics, or neurotechnology. Commonly the state of these systems is not directly observed, but only available through noisy and potentially high-dimensional observations. In these cases, system identification, i.e., finding the measurement mapping and the transition mapping (system dynamics) in latent space can be challenging. For linear system dynamics and measurement mappings efficient solutions for system identification are available. However, in practical applications, the linearity assumptions does not hold, requiring non-linear system identification techniques. If additionally the observations are high-dimensional (e.g., images), non-linear system identification is inherently hard. To address the problem of non-linear system identification from high-dimensional observations, we combine recent advances in deep learning and system identification. In particular, we jointly learn a low-dimensional embedding of the observation by means of deep auto-encoders and a predictive transition model in this low-dimensional space. We demonstrate that our model enables learning good predictive models of dynamical systems from pixel information only.},
	urldate = {2016-12-12},
	journal = {arXiv:1410.7550 [cs, stat]},
	author = {Wahlström, Niklas and Schön, Thomas B. and Deisenroth, Marc Peter},
	month = oct,
	year = {2014},
	keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Systems and Control, Statistics - Machine Learning},
	annote = {Comment: 10 pages, 11 figures},
	file = {arXiv\:1410.7550 PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\9NSJEH3X\\Wahlström et al. - 2014 - Learning deep dynamical models from image pixels.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\9AQIDPD2\\1410.html:text/html}
}

@article{agrawal_learning_2016,
	title = {Learning to {Poke} by {Poking}: {Experiential} {Learning} of {Intuitive} {Physics}},
	shorttitle = {Learning to {Poke} by {Poking}},
	abstract = {We investigate an experiential learning paradigm for acquiring an internal model of intuitive physics. Our model is evaluated on a real-world robotic manipulation task that requires displacing objects to target locations by poking. The robot gathered over 400 hours of experience by executing more than 50K pokes on different objects. We propose a novel approach based on deep neural networks for modeling the dynamics of robot's interactions directly from images, by jointly estimating forward and inverse models of dynamics. The inverse model objective provides supervision to construct informative visual features, which the forward model can then predict and in turn regularize the feature space for the inverse model. The interplay between these two objectives creates useful, accurate models that can then be used for multi-step decision making. This formulation has the additional benefit that it is possible to learn forward models in an abstract feature space and thus alleviate the need of predicting pixels. Our experiments show that this joint modeling approach outperforms alternative methods. We also demonstrate that active data collection using the learned model further improves performance.},
	urldate = {2016-12-13},
	journal = {arXiv:1606.07419 [cs]},
	author = {Agrawal, Pulkit and Nair, Ashvin and Abbeel, Pieter and Malik, Jitendra and Levine, Sergey},
	month = jun,
	year = {2016},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	file = {arXiv\:1606.07419 PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\FTNVPSIQ\\Agrawal et al. - 2016 - Learning to Poke by Poking Experiential Learning .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\KPZPM5H3\\1606.html:text/html}
}

@misc{stanley_3_2017,
	title = {3 {Million} {Instacart} {Orders}, {Open} {Sourced}},
	url = {https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2},
	author = {Stanley, Jeremy},
	year = {2017}
}

@article{cooper_structured_2006,
	title = {Structured representations in the control of behavior cannot be so easily dismissed: {A} reply to {Botvinick} and {Plaut} (2006)},
	volume = {113},
	copyright = {(c) 2012 APA, all rights reserved},
	issn = {1939-1471(Electronic);0033-295X(Print)},
	shorttitle = {Structured representations in the control of behavior cannot be so easily dismissed},
	abstract = {M. Botvinick and D. C. Plaut (see record 2006-12689-009) argued that many of the criticisms of their earlier simple recurrent network (SRN) model of routine sequential action raised by R. P. Cooper and T. Shallice (see record 2006-12689-008) were criticisms of the specific implementation rather than criticisms of the underlying theory. Cooper and Shallice (2006) reject this assessment and raise concerns with several implementational adjustments that Botvinick and Plaut made to address their criticisms of the SRN account. Moreover, Botvinick and Plaut are questioned for not addressing potential interactions between their suggested implementational changes. Cooper and Shallice also reconsider the implications of the role of the training set in shaping the SRN model's normal and error-prone behavior, the role of goals in their original interactive activation network model and routine behavior more generally, and the relation between the putative routine and nonroutine action control systems within the 2 models.},
	number = {4},
	journal = {Psychological Review},
	author = {Cooper, R P and Shallice, T},
	year = {2006},
	keywords = {computational modeling, control of routine behavior, localist versus distributed representations, neuropsychological impairments, procedural memory, sequential action, simple recurrent networks},
	pages = {929--931}
}

@article{maddox_base-rate_1998,
	title = {Base-rate and payoff effects in multidimensional perceptual categorization},
	volume = {24},
	issn = {0278-7393},
	abstract = {The optimality of multidimensional perceptual categorization performance with unequal base rates and payoffs was examined. In Experiment 1, observers learned simultaneously the category structures and base rates or payoffs. Observers showed conservative cutoff placement when payoffs were unequal and extreme cutoff placement when base rates were unequal. In Experiment 2, observers were trained on the category structures before the base-rate or payoff manipulation. Simultaneous base-rate and payoff manipulations tested the hypothesis that base-rate information and payoff information are combined independently. Observers showed (a) small suboptimalities in base-rate and payoff estimation, (b) no qualitative differences across base-rate and payoff conditions, and (c) support for the hypothesis that base-rate and payoff information is combined independently. Implications for current theories of base-rate and payoff learning are discussed.},
	number = {6},
	journal = {Journal of Experimental Psychology. Learning, Memory, and Cognition},
	author = {Maddox, W. T. and Bohil, C. J.},
	month = nov,
	year = {1998},
	keywords = {Adult, Attention, Concept Formation, Decision Support Techniques, Discrimination Learning, Humans, Motivation, Orientation, Pattern Recognition, Visual, Probability Learning},
	pages = {1459--1482}
}

@article{wagenmakers_diffusion_2008,
	title = {A diffusion model account of criterion shifts in the lexical decision task},
	volume = {58},
	issn = {0749-596X},
	abstract = {Performance in the lexical decision task is highly dependent on decision criteria. These criteria can be influenced by speed versus accuracy instructions and word/nonword proportions. Experiment 1 showed that error responses speed up relative to correct responses under instructions to respond quickly. Experiment 2 showed that responses to less probable stimuli are slower and less accurate than responses to more probable stimuli. The data from both experiments support the diffusion model for lexical decision [Ratcliff, R., Gomez, P., \&amp; McKoon, G. (2004a). A diffusion model account of the lexical decision task. Psychological Review, 111, 159–182]. At the same time, the data provide evidence against the popular deadline model for lexical decision. The deadline model assumes that “nonword” responses are given only after the “word” response has timed out—consequently, the deadline model cannot account for the data from experimental conditions in which “nonword” responses are systematically faster than “word” responses.},
	number = {1},
	urldate = {2014-01-19},
	journal = {Journal of Memory and Language},
	author = {Wagenmakers, Eric-Jan and Ratcliff, Roger and Gomez, Pablo and McKoon, Gail},
	month = jan,
	year = {2008},
	keywords = {Deadline model, Diffusion model, DRC, Lexical decision, MROM, Response criteria},
	pages = {140--159}
}

@article{botvinick_doing_2004,
	title = {Doing without schema hierarchies: a recurrent connectionist approach to normal and impaired routine sequential action},
	volume = {111},
	issn = {0033-295X},
	shorttitle = {Doing without schema hierarchies},
	abstract = {In everyday tasks, selecting actions in the proper sequence requires a continuously updated representation of temporal context. Previous models have addressed this problem by positing a hierarchy of processing units, mirroring the roughly hierarchical structure of naturalistic tasks themselves. The present study considers an alternative framework, in which the representation of context depends on recurrent connections within a network mapping from environmental inputs to actions. The ability of this approach to account for human performance was evaluated by applying it, through simulation, to a specific everyday task. The resulting model learned to deal flexibly with a complex set of sequencing constraints, encoding contextual information at multiple time scales within a single, distributed internal representation. Degrading this representation led to errors resembling those observed both in everyday behavior and in apraxia. Analysis of the model's function yielded numerous predictions relevant to both normal and apraxic performance.},
	language = {eng},
	number = {2},
	journal = {Psychological review},
	author = {Botvinick, Matthew and Plaut, David C},
	month = apr,
	year = {2004},
	pmid = {15065915},
	keywords = {Cognition, Humans, Learning, Neural Networks (Computer), Noise, Recurrence},
	pages = {395--429}
}

@incollection{lashley_problem_1951,
	title = {The problem of serial order in behavior},
	booktitle = {Cerebral {Mechanisms} in {Behavior}: the {Hixon} {Symposium}},
	publisher = {Wiley},
	author = {Lashley, Karl},
	year = {1951},
	pages = {112--136}
}

@book{mckinney_python_2012,
	title = {Python for {Data} {Analysis}: {Data} {Wrangling} with {Pandas}, {NumPy}, and {IPython}},
	shorttitle = {Python for {Data} {Analysis}},
	abstract = {Python for Data Analysis is concerned with the nuts and bolts of manipulating, processing, cleaning, and crunching data in Python. It is also a practical, modern introduction to scientific computing in Python, tailored for data-intensive applications. This is a book about the parts of the Python language and libraries you’ll need to effectively solve a broad set of data analysis problems. This book is not an exposition on analytical methods using Python as the implementation language.Written by Wes McKinney, the main author of the pandas library, this hands-on book is packed with practical cases studies. It’s ideal for analysts new to Python and for Python programmers new to scientific computing.Use the IPython interactive shell as your primary development environmentLearn basic and advanced NumPy (Numerical Python) featuresGet started with data analysis tools in the pandas libraryUse high-performance tools to load, clean, transform, merge, and reshape dataCreate scatter plots and static or interactive visualizations with matplotlibApply the pandas groupby facility to slice, dice, and summarize datasetsMeasure data by points in time, whether it’s specific instances, fixed periods, or intervalsLearn how to solve problems in web analytics, social sciences, finance, and economics, through detailed examples},
	publisher = {"O'Reilly Media, Inc."},
	author = {McKinney, Wes},
	month = oct,
	year = {2012},
	keywords = {Computers / Data Processing, Computers / General, Computers / Programming Languages / Python}
}

@article{townsend_serial_1976,
	title = {Serial and within-stage independent parallel model equivalence on the minimum completion time},
	volume = {14},
	issn = {0022-2496},
	abstract = {A set of functional equations is investigated that, when satisfied, yields equivalence on the minimum completion time between serial models and parallel models having the property of within-stage independence. Within these classes of models, it is shown that any parallel model is equivalent to a serial model, but not any serial model is equivalent to a parallel model. The necessary and sufficient conditions for a serial model to have an equivalent parallel counterpart are observed and then two sufficient conditions on the survivor functions that produce this result are exhibited. A number of examples satisfying the various theorems are discussed and a special case leading to an extension of a property of exponential distributions is derived.},
	number = {3},
	urldate = {2014-12-02},
	journal = {Journal of Mathematical Psychology},
	author = {Townsend, James T.},
	month = dec,
	year = {1976},
	pages = {219--238},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\96QBENTA\\Townsend - 1976 - Serial and within-stage independent parallel model.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\DIFTI66E\\0022249676900031.html:text/html}
}

@article{ratcliff_theory_1978,
	title = {A theory of memory retrieval},
	volume = {85},
	copyright = {(c) 2012 APA, all rights reserved},
	issn = {1939-1471(Electronic);0033-295X(Print)},
	abstract = {Develops a theory of memory retrieval and shows that it applies over a range of experimental paradigms. Access to memory traces is viewed in terms of a resonance metaphor. The probe item evokes the search set on the basis of probe–memory item relatedness, just as a ringing tuning fork evokes sympathetic vibrations in other tuning forks. Evidence is accumulated in parallel from each probe–memory item comparison, and each comparison is modeled by a continuous random walk process. In item recognition, the decision process is self-terminating on matching comparisons and exhaustive on nonmatching comparisons. The mathematical model produces predictions about accuracy, mean reaction time, error latency, and reaction time distributions that are in good accord with data from 2 experiments conducted with 6 undergraduates. The theory is applied to 4 item recognition paradigms (Sternberg, prememorized list, study–test, and continuous) and to speed–accuracy paradigms; results are found to provide a basis for comparison of these paradigms. It is noted that neural network models can be interfaced to the retrieval theory with little difficulty and that semantic memory models may benefit from such a retrieval scheme.},
	number = {2},
	journal = {Psychological Review},
	author = {Ratcliff, Roger},
	year = {1978},
	keywords = {theory of memory retrieval \& application over range of experimental paradigms},
	pages = {59--108}
}

@article{rao_decision_2010,
	title = {Decision {Making} {Under} {Uncertainty}: {A} {Neural} {Model} {Based} on {Partially} {Observable} {Markov} {Decision} {Processes}},
	volume = {4},
	issn = {1662-5188},
	shorttitle = {Decision {Making} {Under} {Uncertainty}},
	abstract = {A fundamental problem faced by animals is learning to select actions based on noisy sensory information and incomplete knowledge of the world. It has been suggested that the brain engages in Bayesian inference during perception but how such probabilistic representations are used to select actions has remained unclear. Here we propose a neural model of action selection and decision making based on the theory of partially observable Markov decision processes (POMDPs). Actions are selected based not on a single “optimal” estimate of state but on the posterior distribution over states (the “belief” state). We show how such a model provides a unified framework for explaining experimental results in decision making that involve both information gathering and overt actions. The model utilizes temporal difference (TD) learning for maximizing expected reward. The resulting neural architecture posits an active role for the neocortex in belief computation while ascribing a role to the basal ganglia in belief representation, value computation, and action selection. When applied to the random dots motion discrimination task, model neurons representing belief exhibit responses similar to those of LIP neurons in primate neocortex. The appropriate threshold for switching from information gathering to overt actions emerges naturally during reward maximization. Additionally, the time course of reward prediction error in the model shares similarities with dopaminergic responses in the basal ganglia during the random dots task. For tasks with a deadline, the model learns a decision making strategy that changes with elapsed time, predicting a collapsing decision threshold consistent with some experimental studies. The model provides a new framework for understanding neural decision making and suggests an important role for interactions between the neocortex and the basal ganglia in learning the mapping between probabilistic sensory representations and actions that maximize rewards.},
	urldate = {2013-12-05},
	journal = {Frontiers in Computational Neuroscience},
	author = {Rao, Rajesh P. N.},
	month = nov,
	year = {2010}
}

@article{forstmann_cortico-striatal_2010,
	title = {Cortico-striatal connections predict control over speed and accuracy in perceptual decision making},
	volume = {107},
	abstract = {When people make decisions they often face opposing demands for response speed and response accuracy, a process likely mediated by response thresholds. According to the striatal hypothesis, people decrease response thresholds by increasing activation from cortex to striatum, releasing the brain from inhibition. According to the STN hypothesis, people decrease response thresholds by decreasing activation from cortex to subthalamic nucleus (STN); a decrease in STN activity is likewise thought to release the brain from inhibition and result in responses that are fast but error-prone. To test these hypotheses—both of which may be true—we conducted two experiments on perceptual decision making in which we used cues to vary the demands for speed vs. accuracy. In both experiments, behavioral data and mathematical model analyses confirmed that instruction from the cue selectively affected the setting of response thresholds. In the first experiment we used ultra-high-resolution 7T structural MRI to locate the STN precisely. We then used 3T structural MRI and probabilistic tractography to quantify the connectivity between the relevant brain areas. The results showed that participants who flexibly change response thresholds (as quantified by the mathematical model) have strong structural connections between presupplementary motor area and striatum. This result was confirmed in an independent second experiment. In general, these findings show that individual differences in elementary cognitive tasks are partly driven by structural differences in brain connectivity. Specifically, these findings support a cortico-striatal control account of how the brain implements adaptive switches between cautious and risky behavior.},
	number = {36},
	urldate = {2014-01-19},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Forstmann, Birte U. and Anwander, Alfred and Schäfer, Andreas and Neumann, Jane and Brown, Scott and Wagenmakers, Eric-Jan and Bogacz, Rafal and Turner, Robert},
	month = sep,
	year = {2010},
	keywords = {Basal Ganglia, response time model, speed–accuracy tradeoff, structural connectivity, Subthalamic Nucleus},
	pages = {15916--15920}
}

@article{wald_optimum_1948,
	title = {Optimum {Character} of the {Sequential} {Probability} {Ratio} {Test}},
	volume = {19},
	copyright = {Copyright © 1948 Institute of Mathematical Statistics},
	issn = {0003-4851},
	abstract = {Let S0 be any sequential probability ratio test for deciding between two simple alternatives H0 and H1, and S1 another test for the same purpose. We define (i, j = 0, 1): αi(Sj) = probability, under Sj, of rejecting Hi when it is true; Ei j (n) = expected number of observations to reach a decision under test Sj when the hypothesis Hi is true. (It is assumed that E1 i (n) exists.) In this paper it is proved that, if \${\textbackslash}alpha\_i(S\_1) {\textbackslash}leq {\textbackslash}alpha\_i(S\_0){\textbackslash}quad(i = 0,1)\$ , it follows that \$E\_i{\textasciicircum}0 (n) {\textbackslash}leq E\_i{\textasciicircum}1 (n){\textbackslash}quad(i = 0, 1)\$ . This means that of all tests with the same power the sequential probability ratio test requires on the average fewest observations. This result had been conjectured earlier ([1], [2]).},
	number = {3},
	urldate = {2014-10-22},
	journal = {The Annals of Mathematical Statistics},
	author = {Wald, A. and Wolfowitz, J.},
	month = sep,
	year = {1948},
	pages = {326--339}
}

@article{abundo_limit_2006,
	title = {Limit at {Zero} of the {First}-{Passage} {Time} {Density} and the {Inverse} {Problem} for {One}-{Dimensional} {Diffusions}},
	volume = {24},
	issn = {0736-2994},
	abstract = {Abstract We study the limit at zero of the first-passage time density of a one-dimensional diffusion process over a moving boundary and we also deal with the inverse first-passage time problem, which consists of determining the boundary shape when the first-passage density is known. Our results generalize the analogous ones already known for Brownian motion. We illustrate some examples for which the results are obtained analytically and by a numerical procedure.},
	number = {6},
	urldate = {2013-07-08},
	journal = {Stochastic Analysis and Applications},
	author = {Abundo, Mario},
	year = {2006},
	pages = {1119--1145},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\XBSQDB8U\\Abundo - 2006 - Limit at Zero of the First-Passage Time Density an.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\44CJGS49\\07362990600958804.html:text/html}
}

@inproceedings{frazier_sequential_2008,
	title = {Sequential hypothesis testing under stochastic deadlines},
	abstract = {Most models of decision-making in neuroscience assume an infinite horizon, which yields an optimal solution that integrates evidence up to a fixed decision threshold; however, under most experimental as well as naturalistic behavioral settings, the decision has to be made before some finite deadline, which is often experienced as a stochastic quantity, either due to variable external constraints or internal timing uncertainty. In this work, we formulate this problem as sequential hypothesis testing under a stochastic horizon. We use dynamic programming tools to show that, for a large class of deadline distributions, the Bayes-optimal solution requires integrating evidence up to a threshold that declines monotonically over time. We use numerical simulations to illustrate the optimal policy in the special cases of a fixed deadline and one that is drawn from a gamma distribution. 1},
	booktitle = {Advances in neural information processing systems},
	author = {Frazier, Peter I. and Yu, Angela J.},
	year = {2008},
	pages = {465--472},
	file = {Citeseer - Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\CHV5KNCR\\Frazier and Yu - 2008 - Sequential hypothesis testing under stochastic dea.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\ZG2HNHVF\\summary.html:text/html}
}

@article{nee_prefrontal_2013,
	title = {Prefrontal {Cortex} {Organization}: {Dissociating} {Effects} of {Temporal} {Abstraction}, {Relational} {Abstraction}, and {Integration} with {fMRI}},
	issn = {1460-2199},
	shorttitle = {Prefrontal {Cortex} {Organization}},
	abstract = {The functions of the prefrontal cortex (PFC) underlie higher-level cognition. Varying proposals suggest that the PFC is organized along a rostral-caudal gradient of abstraction with more abstract representations/processes associated with more rostral areas. However, the operational definition of abstraction is unclear. Here, we contrasted 2 prominent theories of abstraction-temporal and relational-using fMRI. We further examined whether integrating abstract rules-a function common to each theory-recruited the PFC independently of other abstraction effects. While robust effects of relational abstraction were present in the PFC, temporal abstraction effects were absent. Instead, we found activations specific to the integration of relational rules in areas previously shown to be associated with temporal abstraction. We suggest that previous effects of temporal abstraction were due to confounds with integration demands. We propose an integration framework to understand the functions of the PFC that resolves discrepancies in prior data.},
	language = {ENG},
	journal = {Cerebral cortex (New York, N.Y.: 1991)},
	author = {Nee, Derek Evan and Jahn, Andrew and Brown, Joshua W},
	month = apr,
	year = {2013},
	pmid = {23563962}
}

@phdthesis{cheng_analysis_2005,
	address = {Pittsburgh, PA},
	title = {Analysis and {Numerical} {Solution} of an {Inverse} {First} {Passage} {Problem} from {Risk}},
	school = {University of Pittsburgh},
	author = {Cheng, L},
	year = {2005}
}

@article{pike_stochastic_1966,
	title = {Stochastic models of choice behaviour: response probabilities and latencies of finite {Markov} chain systems},
	volume = {19},
	issn = {0007-1102},
	shorttitle = {Stochastic models of choice behaviour},
	language = {eng},
	number = {1},
	journal = {The British journal of mathematical and statistical psychology},
	author = {Pike, A R},
	month = may,
	year = {1966},
	pmid = {5939142},
	keywords = {decision making, Models, Theoretical, Probability, Statistics as Topic},
	pages = {15--32}
}

@article{glascher_states_2010,
	title = {States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning},
	volume = {66},
	issn = {1097-4199},
	shorttitle = {States versus rewards},
	abstract = {Reinforcement learning (RL) uses sequential experience with situations ("states") and outcomes to assess actions. Whereas model-free RL uses this experience directly, in the form of a reward prediction error (RPE), model-based RL uses it indirectly, building a model of the state transition and outcome structure of the environment, and evaluating actions by searching this model. A state prediction error (SPE) plays a central role, reporting discrepancies between the current model and the observed state transitions. Using functional magnetic resonance imaging in humans solving a probabilistic Markov decision task, we found the neural signature of an SPE in the intraparietal sulcus and lateral prefrontal cortex, in addition to the previously well-characterized RPE in the ventral striatum. This finding supports the existence of two unique forms of learning signal in humans, which may form the basis of distinct computational strategies for guiding behavior.},
	number = {4},
	journal = {Neuron},
	author = {Gläscher, Jan and Daw, Nathaniel D and Dayan, Peter and O'Doherty, John P},
	month = may,
	year = {2010},
	keywords = {Adolescent, Adult, Choice Behavior, Female, Forecasting, Humans, Learning, Male, Models, Neurological, Psychomotor Performance, Reinforcement (Psychology), Research Design, Reward, Young Adult},
	pages = {585--595}
}

@article{roe_multialternative_2001,
	title = {Multialternative decision field theory: {A} dynamic connectionst model of decision making.},
	volume = {108},
	shorttitle = {Multialternative decision field theory},
	number = {2},
	urldate = {2016-07-09},
	journal = {Psychological review},
	author = {Roe, Robert M. and Busemeyer, Jermone R. and Townsend, James T.},
	year = {2001},
	pages = {370},
	file = {[PDF] from ohio-state.edu:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\9E8EZR3S\\Roe et al. - 2001 - Multialternative decision field theory A dynamic .pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\SZQKT7WG\\370.html:text/html}
}

@article{cooper_hierarchical_2006,
	title = {Hierarchical schemas and goals in the control of sequential behavior},
	volume = {113},
	issn = {0033-295X},
	abstract = {Traditional accounts of sequential behavior assume that schemas and goals play a causal role in the control of behavior. In contrast, M. Botvinick and D. C. Plaut argued that, at least in routine behavior, schemas and goals are epiphenomenal. The authors evaluate the Botvinick and Plaut account by contrasting the simple recurrent network model of Botvinick and Plaut with their own more traditional hierarchically structured interactive activation model (R. P. Cooper \& T. Shallice, 2000). The authors present a range of arguments and additional simulations that demonstrate theoretical and empirical difficulties for both Botvinick and Plaut's model and their theoretical position. The authors conclude that explicit hierarchically organized and causally efficacious schema and goal representations are required to provide an adequate account of the flexibility of sequential behavior.},
	language = {eng},
	number = {4},
	journal = {Psychological review},
	author = {Cooper, R P and Shallice, T},
	month = oct,
	year = {2006},
	pmid = {17014307},
	keywords = {Cognition, Goals, Humans, Learning, Neuropsychology},
	pages = {887--916; discussion 917--931}
}

@article{britten_analysis_1992,
	title = {The analysis of visual motion: a comparison of neuronal and psychophysical performance},
	volume = {12},
	issn = {0270-6474, 1529-2401},
	shorttitle = {The analysis of visual motion},
	abstract = {We compared the ability of psychophysical observers and single cortical neurons to discriminate weak motion signals in a stochastic visual display. All data were obtained from rhesus monkeys trained to perform a direction discrimination task near psychophysical threshold. The conditions for such a comparison were ideal in that both psychophysical and physiological data were obtained in the same animals, on the same sets of trials, and using the same visual display. In addition, the psychophysical task was tailored in each experiment to the physiological properties of the neuron under study; the visual display was matched to each neuron's preference for size, speed, and direction of motion. Under these conditions, the sensitivity of most MT neurons was very similar to the psychophysical sensitivity of the animal observers. In fact, the responses of single neurons typically provided a satisfactory account of both absolute psychophysical threshold and the shape of the psychometric function relating performance to the strength of the motion signal. Thus, psychophysical decisions in our task are likely to be based upon a relatively small number of neural signals. These signals could be carried by a small number of neurons if the responses of the pooled neurons are statistically independent. Alternatively, the signals may be carried by a much larger pool of neurons if their responses are partially intercorrelated.},
	number = {12},
	urldate = {2016-06-06},
	journal = {The Journal of Neuroscience},
	author = {Britten, K. H. and Shadlen, Michael N and Newsome, W. T. and Movshon, J. A.},
	month = dec,
	year = {1992},
	pages = {4745--4765},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\KC2PHBJ3\\Britten et al. - 1992 - The analysis of visual motion a comparison of neu.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\TFQ5BDMK\\Britten et al. - 1992 - The analysis of visual motion a comparison of neu.html:text/html}
}

@article{laming_choice_1979,
	title = {Choice reaction performance following an error},
	volume = {43},
	issn = {0001-6918},
	abstract = {Some data are presented showing the changes in choice-reaction time (CRT) and the probability of error (PE) on the five trials following an error in a two-choice experiment. The magnitudes of the increase in RT and the decrease in PE are different according as the error-trial stimulus is re-presented or the alternative stimulus is preservec. In addition, RT is quicker to recover its equilibrium value than is PE.

This pattern of changes implicates two distinct adjustments to the underlying decision process following an error: (i) a selective outward adjustment of the boundary at which the error was uttered, and (ii) a delay, with respect to presentation of the reaction stimulus, of the epoch at which the subject begins sampling information from the stimulus display. When these ideas are concatenated with the sequential probability-ratio-test model for CRT, a theoretical relation can be derived between the difference in mean RT for an error and for the same response given correctly, on the one hand, and the decrease in PE on the trial following an error, given that the alternate stimulus is presented, on the other. This relation is satisfied by the data.},
	number = {3},
	urldate = {2016-05-12},
	journal = {Acta Psychologica},
	author = {Laming, Donald},
	year = {1979},
	pages = {199--224},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\79FX2VB8\\Laming - 1979 - Choice reaction performance following an error.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\R79AJJZ9\\000169187990026X.html:text/html}
}

@article{kruschke_bayesian_2013,
	title = {Bayesian estimation supersedes the t test},
	volume = {142},
	copyright = {(c) 2016 APA, all rights reserved},
	issn = {1939-2222 0096-3445},
	abstract = {Bayesian estimation for 2 groups provides complete distributions of credible values for the effect size, group means and their difference, standard deviations and their difference, and the normality of the data. The method handles outliers. The decision rule can accept the null value (unlike traditional t tests) when certainty in the estimate is high (unlike Bayesian model comparison using Bayes factors). The method also yields precise estimates of statistical power for various research goals. The software and programs are free and run on Macintosh, Windows, and Linux platforms.},
	number = {2},
	journal = {Journal of Experimental Psychology: General},
	author = {Kruschke, John K.},
	year = {2013},
	keywords = {*Effect Size (Statistical), *Standard Deviation, *Statistical Estimation, *T Test, Computer Software, Confidence Limits (Statistics)},
	pages = {573--603}
}

@article{zhang_bounded_2010,
	title = {Bounded {Ornstein}–{Uhlenbeck} models for two-choice time controlled tasks},
	volume = {54},
	issn = {0022-2496},
	url = {http://www.sciencedirect.com/science/article/pii/S0022249610000374},
	abstract = {The Ornstein–Uhlenbeck (O–U) model has been successfully applied to describe the response accuracy and response time in 2-alternative choice tasks. This paper analyses properties and performance of variants of the O–U model with absorbing and reflecting boundary conditions that limit the range of possible values of the integration variable. The paper focuses on choice tasks with pre-determined response time. The type of boundary and the growth/decay parameter of the O–U model jointly determine how the choice is influenced by the sensory input presented at different times throughout the trial. It is shown that the O–U models with two types of boundary are closely related and can achieve the same performance under certain parameter values. The value of the growth/decay parameter that maximizes the accuracy of the model has been identified. It is shown that when the boundaries are introduced, the O–U model may achieve higher accuracy than the diffusion model. This suggests that given the limited range of the firing rates of integrator neurons, the neural decision circuits could achieve higher accuracy employing leaky rather than linear integration in certain tasks. We also propose experiments that could distinguish between different models of choice in tasks with pre-determined response time.},
	number = {3},
	urldate = {2013-07-12},
	journal = {Journal of Mathematical Psychology},
	author = {Zhang, Jiaxiang and Bogacz, Rafal},
	month = jun,
	year = {2010},
	keywords = {Absorbing boundaries, Choice, Decision, Ornstein–Uhlenbeck model, Reflecting boundaries},
	pages = {322--333},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\UMG6JT6X\\Zhang and Bogacz - 2010 - Bounded Ornstein–Uhlenbeck models for two-choice t.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\33WW6JZR\\S0022249610000374.html:text/html}
}

@misc{center_for_history_and_new_media_zotero_nodate,
	title = {Zotero {Quick} {Start} {Guide}},
	url = {http://zotero.org/support/quick_start_guide},
	author = {{Center for History and New Media}},
	annote = {Welcome to Zotero!View the Quick Start Guide to learn how to begin collecting, managing, citing, and sharing your research sources.Thanks for installing Zotero.}
}

@article{botvinick_hierarchically_2009,
	title = {Hierarchically organized behavior and its neural foundations: a reinforcement learning perspective},
	volume = {113},
	issn = {1873-7838},
	shorttitle = {Hierarchically organized behavior and its neural foundations},
	abstract = {Research on human and animal behavior has long emphasized its hierarchical structure-the divisibility of ongoing behavior into discrete tasks, which are comprised of subtask sequences, which in turn are built of simple actions. The hierarchical structure of behavior has also been of enduring interest within neuroscience, where it has been widely considered to reflect prefrontal cortical functions. In this paper, we reexamine behavioral hierarchy and its neural substrates from the point of view of recent developments in computational reinforcement learning. Specifically, we consider a set of approaches known collectively as hierarchical reinforcement learning, which extend the reinforcement learning paradigm by allowing the learning agent to aggregate actions into reusable subroutines or skills. A close look at the components of hierarchical reinforcement learning suggests how they might map onto neural structures, in particular regions within the dorsolateral and orbital prefrontal cortex. It also suggests specific ways in which hierarchical reinforcement learning might provide a complement to existing psychological models of hierarchically structured behavior. A particularly important question that hierarchical reinforcement learning brings to the fore is that of how learning identifies new action routines that are likely to provide useful building blocks in solving a wide range of future problems. Here and at many other points, hierarchical reinforcement learning offers an appealing framework for investigating the computational and neural underpinnings of hierarchically structured behavior.},
	number = {3},
	journal = {Cognition},
	author = {Botvinick, Matthew and Niv, Yael and Barto, Andrew C},
	month = dec,
	year = {2009},
	pmid = {18926527},
	keywords = {Animals, Humans, Models, Psychological, Nerve Net, Prefrontal Cortex, Problem Solving, Reinforcement (Psychology)},
	pages = {262--280}
}

@article{brown_evaluating_2006,
	title = {Evaluating methods for approximating stochastic differential equations},
	volume = {50},
	issn = {0022-2496},
	abstract = {Models of decision making and response time (RT) are often formulated using stochastic differential equations (SDEs). Researchers often investigate these models using a simple Monte Carlo method based on Euler’s method for solving ordinary differential equations. The accuracy of Euler’s method is investigated and compared to the performance of more complex simulation methods. The more complex methods for solving SDEs yielded no improvement in accuracy over the Euler method. However, the matrix method proposed by  yielded significant improvements. The accuracy of all methods depended critically on the size of the approximating time step. The large (∼10 ms) step sizes often used by psychological researchers resulted in large and systematic errors in evaluating RT distributions.},
	number = {4},
	urldate = {2015-01-05},
	journal = {Journal of mathematical psychology},
	author = {Brown, Scott D. and Ratcliff, Roger and Smith, Philip L.},
	month = aug,
	year = {2006},
	pages = {402--410},
	file = {PubMed Central Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\58ZPUGUG\\Brown et al. - 2006 - Evaluating methods for approximating stochastic di.pdf:application/pdf}
}

@article{solway_goal-directed_2012,
	title = {Goal-directed decision making as probabilistic inference: {A} computational framework and potential neural correlates},
	volume = {119},
	issn = {0033-295X},
	shorttitle = {Goal-directed decision making as probabilistic inference},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3767755/},
	abstract = {Recent work has given rise to the view that reward-based decision making is governed by two key controllers: a habit system, which stores stimulus-response associations shaped by past reward, and a goal-oriented system that selects actions based on their anticipated outcomes. The current literature provides a rich body of computational theory addressing habit formation, centering on temporal-difference learning mechanisms. Less progress has been made toward formalizing the processes involved in goal-directed decision making. We draw on recent work in cognitive neuroscience, animal conditioning, cognitive and developmental psychology and machine learning, to outline a new theory of goal-directed decision making. Our basic proposal is that the brain, within an identifiable network of cortical and subcortical structures, implements a probabilistic generative model of reward, and that goal-directed decision making is effected through Bayesian inversion of this model. We present a set of simulations implementing the account, which address benchmark behavioral and neuroscientific findings, and which give rise to a set of testable predictions. We also discuss the relationship between the proposed framework and other models of decision making, including recent models of perceptual choice, to which our theory bears a direct connection.},
	number = {1},
	urldate = {2014-04-15},
	journal = {Psychological review},
	author = {Solway, Alec and Botvinick, Mathew},
	month = jan,
	year = {2012},
	pages = {120--154},
	file = {PubMed Central Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\AIQDCVHX\\Solway and Botvinick - 2012 - Goal-directed decision making as probabilistic inf.pdf:application/pdf}
}

@article{badre_cognitive_2008,
	title = {Cognitive control, hierarchy, and the rostro-caudal organization of the frontal lobes},
	volume = {12},
	issn = {1364-6613},
	abstract = {Cognitive control supports flexible behavior by selecting actions that are consistent with our goals and appropriate for our environment. The prefrontal cortex (PFC) has an established role in cognitive control, and research on the functional organization of PFC promises to contribute to our understanding of the architecture of control. A recently popular hypothesis is that the rostro-caudal axis of PFC supports a control hierarchy whereby posterior-to-anterior PFC mediates progressively abstract, higher-order control. This review discusses evidence for a rostro-caudal gradient of function in PFC and the theories proposed to account for these results, including domain generality in working memory, relational complexity, the temporal organization of behavior and abstract representational hierarchy. Distinctions among these frameworks are considered as a basis for future research.},
	language = {eng},
	number = {5},
	journal = {Trends in cognitive sciences},
	author = {Badre, David},
	month = may,
	year = {2008},
	pmid = {18403252},
	keywords = {Cognition, Frontal Lobe, Humans, Learning, Magnetic Resonance Imaging, Memory, Prefrontal Cortex, Psychomotor Performance, Reaction Time, Visual Perception},
	pages = {193--200}
}

@article{roitman_response_2002,
	title = {Response of {Neurons} in the {Lateral} {Intraparietal} {Area} during a {Combined} {Visual} {Discrimination} {Reaction} {Time} {Task}},
	volume = {22},
	abstract = {Decisions about the visual world can take time to form, especially when information is unreliable. We studied the neural correlate of gradual decision formation by recording activity from the lateral intraparietal cortex (area LIP) of rhesus monkeys during a combined motion-discrimination reaction-time task. Monkeys reported the direction of random-dot motion by making an eye movement to one of two peripheral choice targets, one of which was within the response field of the neuron. We varied the difficulty of the task and measured both the accuracy of direction discrimination and the time required to reach a decision. Both the accuracy and speed of decisions increased as a function of motion strength. During the period of decision formation, the epoch between onset of visual motion and the initiation of the eye movement response, LIP neurons underwent ramp-like changes in their discharge rate that predicted the monkey's decision. A steeper rise in spike rate was associated with stronger stimulus motion and shorter reaction times. The observations suggest that neurons in LIP integrate time-varying signals that originate in the extrastriate visual cortex, accumulating evidence for or against a specific behavioral response. A threshold level of LIP activity appears to mark the completion of the decision process and to govern the tradeoff between accuracy and speed of perception.},
	number = {21},
	urldate = {2015-01-02},
	journal = {The Journal of Neuroscience},
	author = {Roitman, Jamie D and Shadlen, Michael N},
	month = nov,
	year = {2002},
	keywords = {Decision, Electrophysiology, lateral intraparietal area (LIP), Psychophysics, random-dot motion, Reaction Time, vision},
	pages = {9475--9489},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\REHWNWCQ\\Roitman and Shadlen - 2002 - Response of Neurons in the Lateral Intraparietal A.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\SBATCNE7\\9475.html:text/html}
}

@article{assael_data-efficient_2015,
	title = {Data-{Efficient} {Learning} of {Feedback} {Policies} from {Image} {Pixels} using {Deep} {Dynamical} {Models}},
	abstract = {Data-efficient reinforcement learning (RL) in continuous state-action spaces using very high-dimensional observations remains a key challenge in developing fully autonomous systems. We consider a particularly important instance of this challenge, the pixels-to-torques problem, where an RL agent learns a closed-loop control policy ("torques") from pixel information only. We introduce a data-efficient, model-based reinforcement learning algorithm that learns such a closed-loop policy directly from pixel information. The key ingredient is a deep dynamical model for learning a low-dimensional feature embedding of images jointly with a predictive model in this low-dimensional feature space. Joint learning is crucial for long-term predictions, which lie at the core of the adaptive nonlinear model predictive control strategy that we use for closed-loop control. Compared to state-of-the-art RL methods for continuous states and actions, our approach learns quickly, scales to high-dimensional state spaces, is lightweight and an important step toward fully autonomous end-to-end learning from pixels to torques.},
	urldate = {2016-12-13},
	journal = {arXiv:1510.02173 [cs, stat]},
	author = {Assael, John-Alexander M. and Wahlström, Niklas and Schön, Thomas B. and Deisenroth, Marc Peter},
	month = oct,
	year = {2015},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Statistics - Machine Learning},
	file = {arXiv\:1510.02173 PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\ENDFI689\\Assael et al. - 2015 - Data-Efficient Learning of Feedback Policies from .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\C4D5DKM5\\1510.html:text/html}
}

@article{karsilar_speed_2014,
	title = {Speed accuracy trade-off under response deadlines},
	volume = {8},
	abstract = {Perceptual decision making has been successfully modeled as a process of evidence accumulation up to a threshold. In order to maximize the rewards earned for correct responses in tasks with response deadlines, participants should collapse decision thresholds dynamically during each trial so that a decision is reached before the deadline. This strategy ensures on-time responding, though at the cost of reduced accuracy, since slower decisions are based on lower thresholds and less net evidence later in a trial (compared to a constant threshold). Frazier and Yu (2008) showed that the normative rate of threshold reduction depends on deadline delays and on participants' uncertainty about these delays. Participants should start collapsing decision thresholds earlier when making decisions under shorter deadlines (for a given level of timing uncertainty) or when timing uncertainty is higher (for a given deadline). We tested these predictions using human participants in a random dot motion discrimination task. Each participant was tested in free-response, short deadline (800 ms), and long deadline conditions (1000 ms). Contrary to optimal-performance predictions, the resulting empirical function relating accuracy to response time (RT) in deadline conditions did not decline to chance level near the deadline; nor did the slight decline we typically observed relate to measures of endogenous timing uncertainty. Further, although this function did decline slightly with increasing RT, the decline was explainable by the best-fitting parameterization of Ratcliff's diffusion model (Ratcliff, 1978), whose parameters are constant within trials. Our findings suggest that at the very least, typical decision durations are too short for participants to adapt decision parameters within trials.},
	urldate = {2016-06-14},
	journal = {Decision Neuroscience},
	author = {Karsilar, Hakan and Simen, Patrick and Papadakis, Samantha and Balcı, Fuat},
	year = {2014},
	keywords = {decision making, optimality, response deadlines, speed-accuracy, timing uncertainty},
	pages = {248}
}

@book{laganiere_opencv_2011,
	address = {Birmingham, UK},
	title = {{OpenCV} 2 {Computer} {Vision} {Application} {Programming} {Cookbook}},
	isbn = {978-1-84951-324-1},
	publisher = {Packt Publishing},
	author = {Laganière, Robert},
	month = may,
	year = {2011}
}

@book{miller_plans_1960,
	title = {Plans and the structure of behavior},
	isbn = {978-0-03-010075-8},
	abstract = {Images and plans; The unit of analysis; The simulation of psychological processes; Values, intentions, and the execution of plans; Instincts; Motor skills and habits; The integration of plans; Relinquishing the plan; Nondynamic aspects of personality; Plans for remembering; Plans for speaking; Plans for searching and solving; The formation of plans; Some neuropsychological speculations.},
	language = {en},
	publisher = {Holt},
	author = {Miller, George Armitage and Galanter, E and Pribram, K H},
	year = {1960}
}

@book{haykin_neural_1998,
	address = {Upper Saddle River, NJ, USA},
	edition = {2nd},
	title = {Neural {Networks}: {A} {Comprehensive} {Foundation}},
	isbn = {978-0-13-273350-2},
	shorttitle = {Neural {Networks}},
	abstract = {From the Publisher:NEW TO THIS EDITION   NEW—New chapters now cover such areas as:  Support vector machines. Reinforcement learning/neurodynamic programming. Dynamically driven recurrent networks. NEW-End—of-chapter problems revised, improved and expanded in number.  FEATURES   Extensive, state-of-the-art coverage exposes the reader to the many facets of neural networks and helps them appreciate the technology's capabilities and potential applications. Detailed analysis of back-propagation learning and multi-layer perceptrons. Explores the intricacies of the learning process—an essential component for understanding neural networks. Considers recurrent networks, such as Hopfield networks, Boltzmann machines, and meanfield theory machines, as well as modular networks, temporal processing, and neurodynamics. Integrates computer experiments throughout, giving the opportunity to see how neural networks are designed and perform in practice. Reinforces key concepts with chapter objectives, problems, worked examples, a bibliography, photographs, illustrations, and a thorough glossary. Includes a detailed and extensive bibliography for easy reference. Computer-oriented experiments distributed throughout the book Uses Matlab SE version 5.},
	publisher = {Prentice Hall PTR},
	author = {Haykin, Simon},
	year = {1998}
}

@article{beer_dynamical_2000,
	title = {Dynamical approaches to cognitive science},
	volume = {4},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661399014400},
	abstract = {Dynamical ideas are beginning to have a major impact on cognitive science, from foundational debates to daily practice. In this article, I review three contrasting examples of work in this area that address the lexical and grammatical structure of language, Piaget’s classic ‘A-not-B’ error, and active categorical perception in an embodied, situated agent. From these three examples, I then attempt to articulate the major differences between dynamical approaches and more traditional symbolic and connectionist approaches. Although the three models reviewed here vary considerably in their details, they share a focus on the unfolding trajectory of a system’s state and the internal and external forces that shape this trajectory, rather than the representational content of its constituent states or the underlying physical mechanisms that instantiate the dynamics. In some work, this dynamical viewpoint is augmented with a situated and embodied perspective on cognition, forming a promising unified theoretical framework for cognitive science broadly construed.},
	number = {3},
	urldate = {2014-04-23},
	journal = {Trends in Cognitive Sciences},
	author = {Beer, Randall D.},
	month = mar,
	year = {2000},
	keywords = {A-not-B error, Categorical perception, Dynamical systems, Embodiment, Language understanding, Situated action},
	pages = {91--99},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\BG5CVSNE\\Beer - 2000 - Dynamical approaches to cognitive science.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\93DNTH2A\\S1364661399014400.html:text/html}
}

@article{niv_normative_2006,
	title = {A normative perspective on motivation},
	volume = {10},
	issn = {1364-6613},
	abstract = {Understanding the effects of motivation on instrumental action selection, and specifically on its two main forms, goal-directed and habitual control, is fundamental to the study of decision making. Motivational states have been shown to 'direct' goal-directed behavior rather straightforwardly towards more valuable outcomes. However, how motivational states can influence outcome-insensitive habitual behavior is more mysterious. We adopt a normative perspective, assuming that animals seek to maximize the utilities they achieve, and viewing motivation as a mapping from outcomes to utilities. We suggest that habitual action selection can direct responding properly only in motivational states which pertained during behavioral training. However, in novel states, we propose that outcome-independent, global effects of the utilities can 'energize' habitual actions.},
	number = {8},
	journal = {Trends in cognitive sciences},
	author = {Niv, Yael and Joel, Daphna and Dayan, Peter},
	month = aug,
	year = {2006},
	keywords = {Animals, decision making, Goals, Habituation, Psychophysiologic, Humans, Models, Psychological, Motivation, Reinforcement (Psychology)},
	pages = {375--381}
}

@article{zhang_time-varying_2014,
	title = {Time-varying boundaries for diffusion models of decision making and response time},
	volume = {5},
	abstract = {Diffusion models are widely-used and successful accounts of the time course of two-choice decision making. Most diffusion models assume constant boundaries, which are the threshold levels of evidence that must be sampled from a stimulus to reach a decision. We summarize theoretical results from statistics that relate distributions of decisions and response times to diffusion models with time-varying boundaries. We then develop a computational method for finding time-varying boundaries from empirical data, and apply our new method to two problems. The first problem involves finding the time-varying boundaries that make diffusion models equivalent to the alternative sequential sampling class of accumulator models. The second problem involves finding the time-varying boundaries, at the individual level, that best fit empirical data for perceptual stimuli that provide equal evidence for both decision alternatives. We discuss the theoretical and modeling implications of using time-varying boundaries in diffusion models, as well as the limitations and potential of our approach to their inference.},
	urldate = {2014-12-09},
	journal = {Quantitative Psychology and Measurement},
	author = {Zhang, Shunan and Lee, Michael D. and Vandekerckhove, Joachim and Maris, Gunter and Wagenmakers, Eric-Jan},
	year = {2014},
	keywords = {accumulator model, collapsing bounds, First-passage time, model equivalence, sequential sampling},
	pages = {1364},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\HF9NMJQ3\\Zhang et al. - 2014 - Time-varying boundaries for diffusion models of de.pdf:application/pdf}
}

@article{brainard_psychophysics_1997,
	title = {The {Psychophysics} {Toolbox}},
	issn = {0169-1015},
	abstract = {The Psychophysics Toolbox is a software package that supports visual psychophysics. Its routines provide an interface between a high-level interpreted language (MATLAB on the Macintosh) and the video display hardware. A set of example programs is included with the Toolbox distribution.},
	urldate = {2016-03-08},
	journal = {Spatial Vision},
	author = {Brainard, David},
	year = {1997},
	pages = {433--436}
}

@article{reynolds_function_2012,
	title = {The function and organization of lateral prefrontal cortex: a test of competing hypotheses},
	volume = {7},
	issn = {1932-6203},
	shorttitle = {The function and organization of lateral prefrontal cortex},
	abstract = {The present experiment tested three hypotheses regarding the function and organization of lateral prefrontal cortex (PFC). The first account (the information cascade hypothesis) suggests that the anterior-posterior organization of lateral PFC is based on the timing with which cue stimuli reduce uncertainty in the action selection process. The second account (the levels-of-abstraction hypothesis) suggests that the anterior-posterior organization of lateral PFC is based on the degree of abstraction of the task goals. The current study began by investigating these two hypotheses, and identified several areas of lateral PFC that were predicted to be active by both the information cascade and levels-of-abstraction accounts. However, the pattern of activation across experimental conditions was inconsistent with both theoretical accounts. Specifically, an anterior area of mid-dorsolateral PFC exhibited sensitivity to experimental conditions that, according to both accounts, should have selectively engaged only posterior areas of PFC. We therefore investigated a third possible account (the adaptive context maintenance hypothesis) that postulates that both posterior and anterior regions of PFC are reliably engaged in task conditions requiring active maintenance of contextual information, with the temporal dynamics of activity in these regions flexibly tracking the duration of maintenance demands. Activity patterns in lateral PFC were consistent with this third hypothesis: regions across lateral PFC exhibited transient activation when contextual information had to be updated and maintained in a trial-by-trial manner, but sustained activation when contextual information had to be maintained over a series of trials. These findings prompt a reconceptualization of current views regarding the anterior-posterior organization of lateral PFC, but do support other findings regarding the active maintenance role of lateral PFC in sequential working memory paradigms.},
	language = {eng},
	number = {2},
	journal = {PloS one},
	author = {Reynolds, Jeremy R and O'Reilly, Randall C and Cohen, Jonathan D and Braver, Todd S},
	year = {2012},
	pmid = {22355309},
	keywords = {Adult, Behavior, Brain Mapping, Female, Functional Neuroimaging, Humans, Magnetic Resonance Imaging, Male, Memory, Short-Term, Prefrontal Cortex, Reaction Time, Young Adult},
	pages = {e30284}
}

@article{mcclelland_letting_2010,
	title = {Letting structure emerge: connectionist and dynamical systems approaches to cognition},
	volume = {14},
	issn = {1364-6613},
	shorttitle = {Letting structure emerge},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661310001245},
	doi = {10.1016/j.tics.2010.06.002},
	abstract = {Connectionist and dynamical systems approaches explain human thought, language and behavior in terms of the emergent consequences of a large number of simple noncognitive processes. We view the entities that serve as the basis for structured probabilistic approaches as abstractions that are occasionally useful but often misleading: they have no real basis in the actual processes that give rise to linguistic and cognitive abilities or to the development of these abilities. Although structured probabilistic approaches can be useful in determining what would be optimal under certain assumptions, we propose that connectionist, dynamical systems, and related approaches, which focus on explaining the mechanisms that give rise to cognition, will be essential in achieving a full understanding of cognition and development.},
	number = {8},
	urldate = {2014-04-23},
	journal = {Trends in Cognitive Sciences},
	author = {McClelland, James L and Botvinick, Matthew M. and Noelle, David C. and Plaut, David C. and Rogers, Timothy T. and Seidenberg, Mark S. and Smith, Linda B.},
	month = aug,
	year = {2010},
	pages = {348--356},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\UHWU2K2I\\McClelland et al. - 2010 - Letting structure emerge connectionist and dynami.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\DXXHEQI4\\S1364661310001245.html:text/html}
}

@article{king_statistical_2016,
	title = {Statistical {Inference} for {Partially} {Observed} {Markov} {Processes} via the {R} {Package} pomp},
	volume = {069},
	abstract = {Partially observed Markov process (POMP) models, also known as hidden Markov models or state space models, are ubiquitous tools for time series analysis. The R package pomp provides a very flexible framework for Monte Carlo statistical investigations using nonlinear, non-Gaussian POMP models. A range of modern statistical methods for POMP models have been implemented in this framework including sequential Monte Carlo, iterated filtering, particle Markov chain Monte Carlo, approximate Bayesian computation, maximum synthetic likelihood estimation, nonlinear forecasting, and trajectory matching. In this paper, we demonstrate the application of these methodologies using some simple toy problems. We also illustrate the specification of more complex POMP models, using a nonlinear epidemiological model with a discrete population, seasonality, and extra-demographic stochasticity. We discuss the specification of user-defined models and the development of additional methods within the programming environment provided by pomp.},
	number = {i12},
	journal = {Journal of Statistical Software},
	author = {King, Aaron A. and Nguyen, Dao and Ionides, Edward L.},
	year = {2016},
	file = {RePEc PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\PBXW9W85\\King et al. - 2016 - Statistical Inference for Partially Observed Marko.pdf:application/pdf;RePEc Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\C5I9EV6C\\v_3a069_3ai12.html:text/html}
}

@article{ratcliff_modeling_1998,
	title = {Modeling {Response} {Times} for {Two}-{Choice} {Decisions}},
	volume = {9},
	abstract = {The diffusion model for two-choice real-time decisions is applied to four psychophysical tasks. The model reveals how stimulus information guides decisions and shows how the information is processed through time to yield sometimes correct and sometimes incorrect decisions. Rapid two-choice decisions yield multiple empirical measures: response times for correct and error responses, the probabilities of correct and error responses, and a variety of interactions between accuracy and response time that depend on instructions and task difficulty. The diffusion model can explain all these aspects of the data for the four experiments we present. The model correctly accounts for error response times, something previous models have failed to do. Variability within the decision process explains how errors are made, and variability across trials correctly predicts when errors are faster than correct responses and when they are slower.},
	number = {5},
	urldate = {2013-07-10},
	journal = {Psychological Science},
	author = {Ratcliff, Roger and Rouder, Jeffrey N.},
	month = sep,
	year = {1998},
	pages = {347--356},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\PCQB4GJM\\Ratcliff and Rouder - 1998 - Modeling Response Times for Two-Choice Decisions.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\3MVAQG78\\347.html:text/html}
}

@book{feller_introduction_1968,
	address = {New York, NY},
	title = {An {Introduction} to {Probability} {Theory} and {Its} {Applications}},
	volume = {1},
	abstract = {Introduction: the nature of probability theory · the sample space · elements of combinatorial analysis · fluctuations in coin tossing and random walks · combination of events · conditional probability · stochastic independence · the binomial and poisson distributions · the normal approximation to the binomial distribution · unlimited sequences of bernoulli trials · random variables · expectation · laws of large numbers · integral valued variables · generating functions · compound distributions · branching processes · recurrent events · renewal theory · random walk and ruin problems · markov chains · algebraic treatment of finite markov chains · the simplest time dependent stochastic processes},
	publisher = {John Wiley \& Sons},
	author = {Feller, William},
	year = {1968}
}

@article{simen_reward_2009,
	title = {Reward rate optimization in two-alternative decision making: empirical tests of theoretical predictions},
	volume = {35},
	issn = {1939-1277},
	shorttitle = {Reward rate optimization in two-alternative decision making},
	abstract = {The drift-diffusion model (DDM) implements an optimal decision procedure for stationary, 2-alternative forced-choice tasks. The height of a decision threshold applied to accumulating information on each trial determines a speed-accuracy tradeoff (SAT) for the DDM, thereby accounting for a ubiquitous feature of human performance in speeded response tasks. However, little is known about how participants settle on particular tradeoffs. One possibility is that they select SATs that maximize a subjective rate of reward earned for performance. For the DDM, there exist unique, reward-rate-maximizing values for its threshold and starting point parameters in free-response tasks that reward correct responses (R. Bogacz, E. Brown, J. Moehlis, P. Holmes, \& J. D. Cohen, 2006). These optimal values vary as a function of response-stimulus interval, prior stimulus probability, and relative reward magnitude for correct responses. We tested the resulting quantitative predictions regarding response time, accuracy, and response bias under these task manipulations and found that grouped data conformed well to the predictions of an optimally parameterized DDM.},
	number = {6},
	journal = {Journal of experimental psychology. Human perception and performance},
	author = {Simen, Patrick and Contreras, David and Buck, Cara and Hu, Peter and Holmes, Philip and Cohen, Jonathan D},
	month = dec,
	year = {2009},
	keywords = {decision making, Differential Threshold, Humans, Models, Psychological, Probability Learning, Psychomotor Performance, Reaction Time, Reinforcement Schedule, Reward},
	pages = {1865--1897}
}

@article{busemeyer_psychological_1988,
	title = {Psychological models of deferred decision making},
	volume = {32},
	issn = {0022-2496},
	abstract = {In a two-state deferred decision making task one of two mutually exclusive states of nature is responsible for generating a sequence of independent, identically distributed, and costly observations. After purchasing each observation, the decision maker must either (a) stop purchasing costly observations and make a terminal choice favoring one of the two states, or (b) continue purchasing at least one more observation. We describe a new method, called pattern analysis, for distinguishing alternative models of deferred decision making. Seven different psychological models are evaluated including the optimal stopping rule, fixed sampling, random walk, fixed forgetting, horse race or accumulator, runs, and hybrid stopping rules. Violations of basic properties implied by each of these seven models are reported. The most promising psychological model was a myopic stopping rule, which prescribes purchasing observations until the expected loss of making a terminal decision after purchasing n observations is less than or equal to the sum of the costs of purchasing n + 1 observations.},
	number = {2},
	urldate = {2014-11-17},
	journal = {Journal of Mathematical Psychology},
	author = {Busemeyer, Jerome R and Rapoport, Amnon},
	month = jun,
	year = {1988},
	pages = {91--134},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\EBT34JAR\\Busemeyer and Rapoport - 1988 - Psychological models of deferred decision making.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\33ETI99J\\0022249688900429.html:text/html}
}

@article{ratcliff_dual_2007,
	title = {Dual diffusion model for single-cell recording data from the superior colliculus in a brightness-discrimination task},
	volume = {97},
	abstract = {Monkeys made saccades to one of two peripheral targets based on the brightness of a central stimulus. Task difficulty was manipulated by varying the ratio of stimulus black-and-white pixels. Correct response probability for two monkeys varied directly with difficulty. Deep layer SC neurons exhibited robust presaccadic activity the magnitude of which was unaffected by task difficulty when the stimulus specified a saccade toward a target within the neuron's response field. Activity after stimuli specifying saccades to targets outside the response field was affected by task difficulty, increasing as the task became more difficult. A quantitative model derived from studies of human decision-making was fit to the behavioral data. The model assumes that information from the stimulus drives two independent diffusion processes. Simulated paths from the model were compared with neuron activity, assuming that firing rate is linearly related to position in the accumulation process. The firing rate data show delayed availability of discriminative information for fast, intermediate, and slow decisions when activity is aligned on the stimulus and very small differences in discriminative information when aligned on the saccade. The model produces exactly these patterns of results. The accumulation process is highly variable, allowing the process both to make errors, as is the case for the behavioral performance, and also to account for the firing rate results. Thus the dual diffusion model provides a quantitative account for both the behavior in a simple decision-making task as well as the patterns of activity in competing populations of neurons.},
	number = {2},
	journal = {Journal of Neurophysiology},
	author = {Ratcliff, Roger and Hasegawa, Yukako T. and Hasegawa, Ryohei P. and Smith, Philip L. and Segraves, Mark A.},
	month = feb,
	year = {2007},
	keywords = {Animals, Discrimination (Psychology), Electrophysiology, Female, Fixation, Ocular, Macaca mulatta, Models, Neurological, Neurons, Photic Stimulation, Psychomotor Performance, Saccades, Stereotaxic Techniques, Superior Colliculi},
	pages = {1756--1774}
}

@article{botvinick_hierarchical_2012,
	title = {Hierarchical reinforcement learning and decision making},
	volume = {22},
	issn = {1873-6882},
	abstract = {The hierarchical structure of human and animal behavior has been of critical interest in neuroscience for many years. Yet understanding the neural processes that give rise to such structure remains an open challenge. In recent research, a new perspective on hierarchical behavior has begun to take shape, inspired by ideas from machine learning, and in particular the framework of hierarchical reinforcement learning. Hierarchical reinforcement learning builds on traditional reinforcement learning mechanisms, extending them to accommodate temporally extended behaviors or subroutines. The resulting computational paradigm has begun to influence both theoretical and empirical work in neuroscience, conceptually aligning the study of hierarchical behavior with research on other aspects of learning and decision making, and giving rise to some thought-provoking new findings.},
	language = {eng},
	number = {6},
	journal = {Current opinion in neurobiology},
	author = {Botvinick, Matthew},
	month = dec,
	year = {2012},
	pmid = {22695048},
	keywords = {Animals, Artificial Intelligence, decision making, Hierarchy, Social, Humans, Models, Psychological, Reinforcement (Psychology)},
	pages = {956--962}
}

@article{vickers_dynamic_2000,
	title = {Dynamic {Models} of {Simple} {Judgments}: {II}. {Properties} of a {Self}-{Organizing} {PAGAN} ({Parallel}, {Adaptive}, {Generalized} {Accumulator} {Network}) {Model} for {Multi}-{Choice} {Tasks}},
	volume = {4},
	shorttitle = {Dynamic {Models} of {Simple} {Judgments}},
	abstract = {This is the second of two papers comparing connectionist and traditional stochastic latency mechanisms with respect to their ability to account for simple judgments. In the first, we reviewed evidence for a self-regulating accumulator module for two- and three-category discrimination. In this paper, we examine established neural network models that have been applied to predicting response time measures, and discuss their representational and adaptational limitations. We go on to describe and evaluate the network implementation of a Parallel Adaptive Generalized Accumulator Network (PAGAN), based on the interconnection of a number of self-regulating, generalized accumulator modules. The enhancement of PAGAN through the incorporation of distributed connectionist representation is briefly discussed.},
	number = {1},
	urldate = {2016-12-27},
	journal = {Nonlinear Dynamics, Psychology, and Life Sciences},
	author = {Vickers, Douglas and Lee, Michael D.},
	month = jan,
	year = {2000},
	pages = {1--31},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\XI92PXHX\\Vickers and Lee - 2000 - Dynamic Models of Simple Judgments II. Properties.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\KQUXN62T\\A1009571011764.html:text/html}
}

@book{marr_vision:_1982,
	address = {New York, NY},
	title = {Vision: {A} computational investigation into the human representation and processing of visual information},
	shorttitle = {Vision},
	publisher = {Henry Holt and Co.},
	author = {Marr, David},
	year = {1982}
}

@article{smith_accumulator_1988,
	title = {The accumulator model of two-choice discrimination},
	number = {2},
	journal = {Journal of Mathematical Psychology},
	author = {Smith, Philip L. and Vickers, Douglas},
	year = {1988},
	pages = {135--168}
}

@article{balci_acquisition_2011,
	title = {Acquisition of decision making criteria: reward rate ultimately beats accuracy},
	volume = {73},
	issn = {1943-393X},
	shorttitle = {Acquisition of decision making criteria},
	abstract = {Speed-accuracy trade-offs strongly influence the rate of reward that can be earned in many decision-making tasks. Previous reports suggest that human participants often adopt suboptimal speed-accuracy trade-offs in single session, two-alternative forced-choice tasks. We investigated whether humans acquired optimal speed-accuracy trade-offs when extensively trained with multiple signal qualities. When performance was characterized in terms of decision time and accuracy, our participants eventually performed nearly optimally in the case of higher signal qualities. Rather than adopting decision criteria that were individually optimal for each signal quality, participants adopted a single threshold that was nearly optimal for most signal qualities. However, setting a single threshold for different coherence conditions resulted in only negligible decrements in the maximum possible reward rate. Finally, we tested two hypotheses regarding the possible sources of suboptimal performance: (1) favoring accuracy over reward rate and (2) misestimating the reward rate due to timing uncertainty. Our findings provide support for both hypotheses, but also for the hypothesis that participants can learn to approach optimality. We find specifically that an accuracy bias dominates early performance, but diminishes greatly with practice. The residual discrepancy between optimal and observed performance can be explained by an adaptive response to uncertainty in time estimation.},
	number = {2},
	journal = {Attention, perception \& psychophysics},
	author = {Balci, Fuat and Simen, Patrick and Niyogi, Ritwik and Saxe, Andrew and Hughes, Jessica A and Holmes, Philip and Cohen, Jonathan D},
	month = feb,
	year = {2011},
	keywords = {Adolescent, Adult, Attention, decision making, Discrimination (Psychology), Female, Humans, Male, Motion Perception, Motivation, Pattern Recognition, Visual, Practice (Psychology), Probability Learning, Psychophysics, Reaction Time, Reward, Uncertainty, Young Adult},
	pages = {640--657}
}

@article{botvinick_such_2006,
	title = {Such stuff as habits are made on: {A} reply to {Cooper} and {Shallice} (2006)},
	volume = {113},
	copyright = {(c) 2012 APA, all rights reserved},
	issn = {1939-1471(Electronic);0033-295X(Print)},
	shorttitle = {Such stuff as habits are made on},
	abstract = {The representations and mechanisms guiding everyday routine sequential action remain incompletely understood. In recent work, the authors proposed a computational model of routine sequential behavior that took the form of a recurrent neural network (M. Botvinick \& D. C. Plaut, 2004; see record 2004-12248-005). Subsequently, R. P. Cooper and T. Shallice (2006; see record 2006-12689-008) put forth a detailed critique of that work, contrasting it with their own account, which assumes a strict hierarchical processing system (R. P. Cooper \& T. Shallice, 2000; see record 2000-03986-001). The authors respond here to the main points of R. P. Cooper and T. Shallice's (2006) critique. Although careful and constructive, the arguments offered by R. P. Cooper and T. Shallice (2006) mistook several superficial implementational issues for fundamental theoretical ones, underestimated the computational power of recurrent networks as a class, and in some ways mischaracterized the relationship between the accounts they compare. In responding to these points, the authors articulate several key theoretical choices facing models of routine sequential behavior.},
	number = {4},
	journal = {Psychological Review},
	author = {Botvinick, Matthew and Plaut, David C.},
	year = {2006},
	keywords = {computational modeling, control of routine behavior, localist versus distributed representations, neuropsychological impairments, procedural memory, sequential action, simple recurrent networks},
	pages = {917--927}
}

@article{voskuilen_comparing_2016,
	title = {Comparing fixed and collapsing boundary versions of the diffusion model},
	volume = {73},
	issn = {0022-2496},
	abstract = {Optimality studies and studies of decision-making in monkeys have been used to support a model in which the decision boundaries used to evaluate evidence collapse over time. This article investigates whether a diffusion model with collapsing boundaries provides a better account of human data than a model with fixed boundaries. We compared the models using data from four new numerosity discrimination experiments and two previously published motion discrimination experiments. When model selection was based on BIC values, the fixed boundary model was preferred over the collapsing boundary model for all of the experiments. When model selection was carried out using a parametric bootstrap cross-fitting method (PBCM), which takes into account the flexibility of the alternative models and the ability of one model to account for data from another model, data from 5 of 6 experiments favored either fixed boundaries or boundaries with only negligible collapse. We found that the collapsing boundary model produces response times distributions with the same shape as those produced by the fixed boundary model and that its parameters were not well-identified and were difficult to recover from data. Furthermore, the estimated boundaries of the best-fitting collapsing boundary model were relatively flat and very similar to those of the fixed-boundary model. Overall, a diffusion model with decision boundaries that converge over time does not provide an improvement over the standard diffusion model for our tasks with human data.},
	urldate = {2016-06-17},
	journal = {Journal of Mathematical Psychology},
	author = {Voskuilen, Chelsea and Ratcliff, Roger and Smith, Philip L.},
	year = {2016},
	keywords = {Collapsing boundaries, Diffusion model, Model selection, Response time models},
	pages = {59--79},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\SGV67FJC\\Voskuilen et al. - 2016 - Comparing fixed and collapsing boundary versions o.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\ZZSB78EM\\S0022249616300189.html:text/html}
}

@book{passino_fuzzy_1997,
	address = {Boston, MA, USA},
	edition = {1st},
	title = {Fuzzy {Control}},
	isbn = {978-0-201-18074-9},
	abstract = {From the Publisher:Fuzzy control is emerging as a practical alternative to conventional methods of solving challenging control problems. Written by two authors who have been involved in creating theoretical foundations for the field and who have helped assess the value of this new technology relative to conventional approaches, Fuzzy Control is filled with a wealth of examples and case studies on design and implementation. Computer code and MATLAB files can be downloaded for solving the book's examples and problems and can be easily modified to implement the reader's own fuzzy controllers or estimators. Drawing on their extensive experience working with industry on implementations, Kevin Passino and Stephen Yurkovich have written an excellent hands-on introduction for professionals and educators interested in learning or teaching fuzzy control.},
	publisher = {Addison-Wesley Longman Publishing Co., Inc.},
	author = {Passino, Kevin M. and Yurkovich, Stephen},
	year = {1997}
}

@article{teodorescu_disentangling_2013,
	title = {Disentangling decision models: {From} independence to competition},
	volume = {120},
	shorttitle = {Disentangling decision models},
	abstract = {A multitude of models have been proposed to account for the neural mechanism of value integration and decision making in speeded decision tasks. While most of these models account for existing data, they largely disagree on a fundamental characteristic of the choice mechanism: independent versus different types of competitive processing. Five models, an independent race model, 2 types of input competition models (normalized race and feed-forward inhibition [FFI]) and 2 types of response competition models (max-minus-next [MMN] diffusion and leaky competing accumulators [LCA]) were compared in 3 combined computational and experimental studies. In each study, difficulty was manipulated in a way that produced qualitatively distinct predictions from the different classes of models. When parameters were constrained by the experimental conditions to avoid mimicking, simulations demonstrated that independent models predict speedups in response time with increased difficulty, while response competition models predict the opposite. Predictions of input-competition models vary between specific models and experimental conditions. Taken together, the combined computational and empirical findings provide support for the notion that decisional processes are intrinsically competitive and that this competition is likely to kick in at a late (response), rather than early (input), processing stage.},
	number = {1},
	journal = {Psychological Review},
	author = {Teodorescu, Andrei R and Usher, Marius},
	year = {2013},
	keywords = {*Competition, *Decision Making, *Models, Choice Behavior},
	pages = {1--38}
}

@article{gold_neural_2007,
	title = {The neural basis of decision making},
	volume = {30},
	issn = {0147-006X},
	abstract = {The study of decision making spans such varied fields as neuroscience, psychology, economics, statistics, political science, and computer science. Despite this diversity of applications, most decisions share common elements including deliberation and commitment. Here we evaluate recent progress in understanding how these basic elements of decision formation are implemented in the brain. We focus on simple decisions that can be studied in the laboratory but emphasize general principles likely to extend to other settings.},
	journal = {Annual review of neuroscience},
	author = {Gold, Joshua I and Shadlen, Michael N},
	year = {2007},
	pmid = {17600525},
	keywords = {Animals, Brain, Cognition, decision making, Humans, Models, Neurological, Movement, Perception, Psychomotor Performance, Psychophysics, Volition},
	pages = {535--574}
}

@article{chen_existence_2011,
	title = {Existence and uniqueness of solutions to the inverse boundary crossing problem for diffusions},
	volume = {21},
	issn = {1050-5164},
	abstract = {We study the inverse boundary crossing problem for diffusions. Given a diffusion process Xt, and a survival distribution p on [0, ∞), we demonstrate that there exists a boundary b(t) such that p(t) = ℙ[τ {\textgreater} t], where τ is the first hitting time of Xt to the boundary b(t). The approach taken is analytic, based on solving a parabolic variational inequality to find b. Existence and uniqueness of the solution to this variational inequality were proven in earlier work. In this paper, we demonstrate that the resulting boundary b does indeed have p as its boundary crossing distribution. Since little is known regarding the regularity of b arising from the variational inequality, this requires a detailed study of the problem of computing the boundary crossing distribution of Xt to a rough boundary. Results regarding the formulation of this problem in terms of weak solutions to the corresponding Kolmogorov forward equation are presented.},
	language = {EN},
	number = {5},
	urldate = {2013-07-08},
	journal = {The Annals of Applied Probability},
	author = {Chen, Xinfu and Cheng, L and Chadam, John and Saunders, David},
	year = {2011},
	note = {Zentralblatt MATH identifier: 05994507; Mathematical Reviews number (MathSciNet): MR2884048},
	pages = {1663--1693}
}

@book{hull_principles_1943,
	address = {New York},
	title = {Principles of {Behavior}: {An} {Introduction} to {Behavior} {Theory}},
	shorttitle = {Principles of {Behavior}},
	publisher = {Appleton- Century},
	author = {Hull, Clark Leonard},
	year = {1943}
}

@article{finn_deep_2015,
	title = {Deep {Spatial} {Autoencoders} for {Visuomotor} {Learning}},
	url = {http://arxiv.org/abs/1509.06113},
	abstract = {Reinforcement learning provides a powerful and flexible framework for automated acquisition of robotic motion skills. However, applying reinforcement learning requires a sufficiently detailed representation of the state, including the configuration of task-relevant objects. We present an approach that automates state-space construction by learning a state representation directly from camera images. Our method uses a deep spatial autoencoder to acquire a set of feature points that describe the environment for the current task, such as the positions of objects, and then learns a motion skill with these feature points using an efficient reinforcement learning method based on local linear models. The resulting controller reacts continuously to the learned feature points, allowing the robot to dynamically manipulate objects in the world with closed-loop control. We demonstrate our method with a PR2 robot on tasks that include pushing a free-standing toy block, picking up a bag of rice using a spatula, and hanging a loop of rope on a hook at various positions. In each task, our method automatically learns to track task-relevant objects and manipulate their configuration with the robot's arm.},
	urldate = {2016-12-10},
	journal = {arXiv:1509.06113 [cs]},
	author = {Finn, Chelsea and Tan, Xin Yu and Duan, Yan and Darrell, Trevor and Levine, Sergey and Abbeel, Pieter},
	month = sep,
	year = {2015},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Robotics},
	annote = {Comment: Published in the International Conference on Robotics and Automation (ICRA)}
}

@article{williams_simple_1992,
	title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
	volume = {8},
	abstract = {This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms.},
	number = {3-4},
	urldate = {2016-05-06},
	journal = {Machine Learning},
	author = {Williams, Ronald J.},
	month = may,
	year = {1992},
	keywords = {Artificial Intelligence (incl. Robotics), Automation and Robotics, Computing Methodologies, connectionist networks, gradient descent, Language Translation and Linguistics, mathematical analysis, Reinforcement learning, Simulation and Modeling},
	pages = {229--256},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\UCPXXXJE\\Williams - 1992 - Simple statistical gradient-following algorithms f.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\EBK5V4TK\\Williams - 1992 - Simple statistical gradient-following algorithms f.html:text/html}
}

@article{sutton_between_1999,
	title = {Between {MDPs} and {Semi}-{MDPs}: {A} {Framework} for {Temporal} {Abstraction} in {Reinforcement} {Learning}},
	volume = {112},
	shorttitle = {Between {MDPs} and {Semi}-{MDPs}},
	abstract = {Learning, planning, and representing knowledge at multiple levels  of temporal abstraction are key, longstanding challenges for AI. In  this paper we consider how these challenges can be addressed within  the mathematical framework of reinforcement learning and Markov  decision processes (MDPs). We extend the usual notion of action in  this framework to include options---closed-loop policies for taking action  over a period of time. Examples of options include picking up an  object, going to lunch, and traveling to a distant city, as well as primitive  actions such as muscle twitches and joint torques. Overall, we  show that options enable temporally abstract knowledge and action  to be included in the reinforcement learning framework in a natural  and general way. In particular, we show that options may be used  interchangeably with primitive actions in planning methods such as  dynamic programming and in learning methods such as Q-learning.},
	journal = {Artificial Intelligence},
	author = {Sutton, Richard and Precup, Doina and Singh, Satinder},
	year = {1999},
	pages = {181--211},
	file = {Citeseer - Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\GDHBJT6J\\Sutton et al. - 1999 - Between MDPs and Semi-MDPs A Framework for Tempor.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\H8NF9KP7\\summary.html:text/html}
}

@article{cisek_decisions_2009,
	title = {Decisions in {Changing} {Conditions}: {The} {Urgency}-{Gating} {Model}},
	volume = {29},
	abstract = {Several widely accepted models of decision making suggest that, during simple decision tasks, neural activity builds up until a threshold is reached and a decision is made. These models explain error rates and reaction time distributions in a variety of tasks and are supported by neurophysiological studies showing that neural activity in several cortical and subcortical regions gradually builds up at a rate related to task difficulty and reaches a relatively constant level of discharge at a time that predicts movement initiation. The mechanism responsible for this buildup is believed to be related to the temporal integration of sequential samples of sensory information. However, an alternative mechanism that may explain the neural and behavioral data is one in which the buildup of activity is instead attributable to a growing signal related to the urgency to respond, which multiplicatively modulates updated estimates of sensory evidence. These models are difficult to distinguish when, as in previous studies, subjects are presented with constant sensory evidence throughout each trial. To distinguish the models, we presented human subjects with a task in which evidence changed over the course of each trial. Our results are more consistent with “urgency gating” than with temporal integration of sensory samples and suggest a simple mechanism for implementing trade-offs between the speed and accuracy of decisions.},
	number = {37},
	journal = {The Journal of Neuroscience},
	author = {Cisek, Paul and Puskas, Geneviève Aude and El-Murr, Stephany},
	month = sep,
	year = {2009},
	pages = {11560--11571},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\XEZA2HJ8\\Cisek et al. - 2009 - Decisions in Changing Conditions The Urgency-Gati.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\82KFCBEA\\11560.html:text/html}
}

@article{voss_fast_2008,
	title = {A fast numerical algorithm for the estimation of diffusion model parameters},
	volume = {52},
	issn = {0022-2496},
	abstract = {In this paper, we describe a new algorithmic approach for parameter estimation in Ratcliff's [(1978). A theory of memory retrieval. Psychological Review, 85 (2), 59–108] diffusion model. This problem, especially if inter-trial variabilities of parameters are included in the model, is computationally very expensive; the parameter estimation procedure often takes a long time even with today's high-speed computers. The algorithm described here makes the calculation of the cumulative distribution functions for predicted process durations computationally much less expensive. This improvement is achieved by solving the Kolmogorov backward equation numerically instead of employing the previously used closed form solution. Additionally, the algorithm can determine the optimum fit for one of the model parameters (the starting point z) directly, thereby reducing the dimension of the parameter search space by one. The resulting method is shown to be notably faster than the standard (closed-form solution) method for parameter estimation.},
	number = {1},
	urldate = {2013-08-30},
	journal = {Journal of Mathematical Psychology},
	author = {Voss, Andreas and Voss, Jochen},
	month = feb,
	year = {2008},
	keywords = {Diffusion model, fast-dm, Parameter estimation, Partial differential equation, PDE},
	pages = {1--9},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\8PDVPW39\\Voss and Voss - 2008 - A fast numerical algorithm for the estimation of d.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\GTNMZIA2\\S0022249607000685.html:text/html}
}

@book{kruschke_doing_2014,
	address = {Boston},
	edition = {2 edition},
	title = {Doing {Bayesian} {Data} {Analysis}, {Second} {Edition}: {A} {Tutorial} with {R}, {JAGS}, and {Stan}},
	shorttitle = {Doing {Bayesian} {Data} {Analysis}, {Second} {Edition}},
	abstract = {There is an explosion of interest in Bayesian statistics, primarily because recently created computational methods have finally made Bayesian analysis obtainable to a wide audience. Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan provides an accessible approach to Bayesian data analysis, as material is explained clearly with concrete examples. The book begins with the basics, including essential concepts of probability and random sampling, and gradually progresses to advanced hierarchical modeling methods for realistic data. Included are step-by-step instructions on how to conduct Bayesian data analyses in the popular and free software R and WinBugs. This book is intended for first-year graduate students or advanced undergraduates. It provides a bridge between undergraduate training and modern Bayesian methods for data analysis, which is becoming the accepted research standard. Knowledge of algebra and basic calculus is a prerequisite. New to this Edition (partial list): There are all new programs in JAGS and Stan. The new programs are designed to be much easier to use than the scripts in the first edition. In particular, there are now compact high-level scripts that make it easy to run the programs on your own data sets. This new programming was a major undertaking by itself.The introductory Chapter 2, regarding the basic ideas of how Bayesian inference re-allocates credibility across possibilities, is completely rewritten and greatly expanded.There are completely new chapters on the programming languages R (Ch. 3), JAGS (Ch. 8), and Stan (Ch. 14). The lengthy new chapter on R includes explanations of data files and structures such as lists and data frames, along with several utility functions. (It also has a new poem that I am particularly pleased with.) The new chapter on JAGS includes explanation of the RunJAGS package which executes JAGS on parallel computer cores. The new chapter on Stan provides a novel explanation of the concepts of Hamiltonian Monte Carlo. The chapter on Stan also explains conceptual differences in program flow between it and JAGS.Chapter 5 on Bayes’ rule is greatly revised, with a new emphasis on how Bayes’ rule re-allocates credibility across parameter values from prior to posterior. The material on model comparison has been removed from all the early chapters and integrated into a compact presentation in Chapter 10.What were two separate chapters on the Metropolis algorithm and Gibbs sampling have been consolidated into a single chapter on MCMC methods (as Chapter 7). There is extensive new material on MCMC convergence diagnostics in Chapters 7 and 8. There are explanations of autocorrelation and effective sample size. There is also exploration of the stability of the estimates of the HDI limits. New computer programs display the diagnostics, as well.Chapter 9 on hierarchical models includes extensive new and unique material on the crucial concept of shrinkage, along with new examples.All the material on model comparison, which was spread across various chapters in the first edition, in now consolidated into a single focused chapter (Ch. 10) that emphasizes its conceptualization as a case of hierarchical modeling.Chapter 11 on null hypothesis significance testing is extensively revised. It has new material for introducing the concept of sampling distribution. It has new illustrations of sampling distributions for various stopping rules, and for multiple tests.Chapter 12, regarding Bayesian approaches to null value assessment, has new material about the region of practical equivalence (ROPE), new examples of accepting the null value by Bayes factors, and new explanation of the Bayes factor in terms of the Savage-Dickey method.Chapter 13, regarding statistical power and sample size, has an extensive new section on sequential testing, and making the research goal be precision of estimation instead of rejecting or accepting a particular value.Chapter 15, which introduces the generalized linear model, is fully revised, with more complete tables showing combinations of predicted and predictor variable types.Chapter 16, regarding estimation of means, now includes extensive discussion of comparing two groups, along with explicit estimates of effect size.Chapter 17, regarding regression on a single metric predictor, now includes extensive examples of robust regression in JAGS and Stan. New examples of hierarchical regression, including quadratic trend, graphically illustrate shrinkage in estimates of individual slopes and curvatures. The use of weighted data is also illustrated.Chapter 18, on multiple linear regression, includes a new section on Bayesian variable selection, in which various candidate predictors are probabilistically included in the regression model.Chapter 19, on one-factor ANOVA-like analysis, has all new examples, including a completely worked out example analogous to analysis of covariance (ANCOVA), and a new example involving heterogeneous variances.Chapter 20, on multi-factor ANOVA-like analysis, has all new examples, including a completely worked out example of a split-plot design that involves a combination of a within-subjects factor and a between-subjects factor.Chapter 21, on logistic regression, is expanded to include examples of robust logistic regression, and examples with nominal predictors.There is a completely new chapter (Ch. 22) on multinomial logistic regression. This chapter fills in a case of the generalized linear model (namely, a nominal predicted variable) that was missing from the first edition.Chapter 23, regarding ordinal data, is greatly expanded. New examples illustrate single-group and two-group analyses, and demonstrate how interpretations differ from treating ordinal data as if they were metric.There is a new section (25.4) that explains how to model censored data in JAGS.Many exercises are new or revised.Accessible, including the basics of essential concepts of probability and random samplingExamples with R programming language and JAGS softwareComprehensive coverage of all scenarios addressed by non-Bayesian textbooks: t-tests, analysis of variance (ANOVA) and comparisons in ANOVA, multiple regression, and chi-square (contingency table analysis)Coverage of experiment planningR and JAGS computer programming code on websiteExercises have explicit purposes and guidelines for accomplishment Provides step-by-step instructions on how to conduct Bayesian data analyses in the popular and free software R and WinBugs},
	publisher = {Academic Press},
	author = {Kruschke, John},
	month = nov,
	year = {2014}
}

@article{finn_deep_2016,
	title = {Deep {Visual} {Foresight} for {Planning} {Robot} {Motion}},
	abstract = {A key challenge in scaling up robot learning to many skills and environments is removing the need for human supervision, so that robots can collect their own data and improve their own performance without being limited by the cost of requesting human feedback. Model-based reinforcement learning holds the promise of enabling an agent to learn to predict the effects of its actions, which could provide flexible predictive models for a wide range of tasks and environments, without detailed human supervision. We develop a method for combining deep action-conditioned video prediction models with model-predictive control that uses entirely unlabeled training data. Our approach does not require a calibrated camera, an instrumented training set-up, nor precise sensing and actuation. Our results show that our method enables a real robot to perform nonprehensile manipulation -- pushing objects -- and can handle novel objects not seen during training.},
	urldate = {2016-12-12},
	journal = {arXiv:1610.00696 [cs]},
	author = {Finn, Chelsea and Levine, Sergey},
	month = oct,
	year = {2016},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Robotics},
	annote = {Comment: Supplementary video: https://sites.google.com/site/robotforesight/},
	file = {arXiv\:1610.00696 PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\ZP7XKGAX\\Finn and Levine - 2016 - Deep Visual Foresight for Planning Robot Motion.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\BCDGT7M5\\1610.html:text/html}
}

@techreport{fudenberg_stochastic_2015,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Stochastic {Choice} and {Optimal} {Sequential} {Sampling}},
	abstract = {We model the joint distribution of choice probabilities and decision times in binary choice tasks as the solution to a problem of optimal sequential sampling, where the agent is uncertain of the utility of each action and pays a constant cost per unit time for gathering information. In the resulting optimal policy, the agent's choices are more likely to be correct when the agent chooses to decide quickly, provided that the agent's prior beliefs are correct. For this reason it better matches the observed correlation between decision time and choice probability than does the classical drift-diffusion model, where the agent is uncertain which of two actions is best but knows the utility difference between them.},
	number = {ID 2602927},
	urldate = {2016-02-29},
	institution = {Social Science Research Network},
	author = {Fudenberg, Drew and Strack, Philipp and Strzalecki, Tomasz},
	month = may,
	year = {2015},
	keywords = {Drew   Fudenberg, Philipp  Strack, SSRN, Stochastic Choice and Optimal Sequential Sampling, Tomasz  Strzalecki},
	file = {Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\ZDUNQK6K\\Fudenberg  et al. - 2015 - Stochastic Choice and Optimal Sequential Sampling.html:text/html}
}

@article{ratcliff_diffusion_2007,
	title = {The {Diffusion} {Decision} {Model}: {Theory} and {Data} for {Two}-{Choice} {Decision} {Tasks}},
	volume = {20},
	issn = {0899-7667},
	shorttitle = {The {Diffusion} {Decision} {Model}},
	url = {http://dx.doi.org/10.1162/neco.2008.12-06-420},
	abstract = {The diffusion decision model allows detailed explanations of behavior in two-choice discrimination tasks. In this article, the model is reviewed to show how it translates behavioral data—accuracy, mean response times, and response time distributions—into components of cognitive processing. Three experiments are used to illustrate experimental manipulations of three components: stimulus difficulty affects the quality of information on which a decision is based; instructions emphasizing either speed or accuracy affect the criterial amounts of information that a subject requires before initiating a response; and the relative proportions of the two stimuli affect biases in drift rate and starting point. The experiments also illustrate the strong constraints that ensure the model is empirically testable and potentially falsifiable. The broad range of applications of the model is also reviewed, including research in the domains of aging and neurophysiology.},
	number = {4},
	urldate = {2014-01-19},
	journal = {Neural Computation},
	author = {Ratcliff, Roger and McKoon, Gail},
	month = dec,
	year = {2007},
	pages = {873--922}
}

@article{usher_time_2001,
	title = {The time course of perceptual choice: the leaky, competing accumulator model},
	volume = {108},
	issn = {0033-295X},
	shorttitle = {The time course of perceptual choice},
	abstract = {The time course of perceptual choice is discussed in a model of gradual, leaky, stochastic, and competitive information accumulation in nonlinear decision units. Special cases of the model match a classical diffusion process, but leakage and competition work together to address several challenges to existing diffusion, random walk, and accumulator models. The model accounts for data from choice tasks using both time-controlled (e.g., response signal) and standard reaction time paradigms and its adequacy compares favorably with other approaches. A new paradigm that controls the time of arrival of information supporting different choice alternatives provides further support. The model captures choice behavior regardless of the number of alternatives, accounting for the log-linear relation between reaction time and number of alternatives (Hick's law) and explains a complex pattern of visual and contextual priming in visual word identification.},
	number = {3},
	journal = {Psychological review},
	author = {Usher, Marius and McClelland, James L},
	month = jul,
	year = {2001},
	keywords = {Choice Behavior, Humans, Models, Psychological, Neural Inhibition, Nonlinear Dynamics, Perception, Stochastic Processes, Time Factors, Visual Perception},
	pages = {550--592}
}

@article{tolman_cognitive_1948,
	title = {Cognitive maps in rats and men},
	volume = {55},
	issn = {0033-295X},
	number = {4},
	journal = {Psychological review},
	author = {Tolman, Edward Chace},
	month = jul,
	year = {1948},
	pages = {189--208}
}

@incollection{mikolov_distributed_2013,
	title = {Distributed {Representations} of {Words} and {Phrases} and their {Compositionality}},
	url = {http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 26},
	publisher = {Curran Associates, Inc.},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
	editor = {Burges, C. J. C. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K. Q.},
	year = {2013},
	pages = {3111--3119},
	file = {NIPS Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\QEZQUU7X\\Mikolov et al. - 2013 - Distributed Representations of Words and Phrases a.pdf:application/pdf;NIPS Snapshort:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\469XPCFM\\5021-distributed-representations-of-words-and-phrases-and-their-compositionality.html:text/html}
}

@article{ratcliff_comparison_2004,
	title = {A comparison of sequential sampling models for two-choice reaction time},
	volume = {111},
	issn = {0033-295X},
	abstract = {The authors evaluated 4 sequential sampling models for 2-choice decisions--the Wiener diffusion, Ornstein-Uhlenbeck (OU) diffusion, accumulator, and Poisson counter models--by fitting them to the response time (RT) distributions and accuracy data from 3 experiments. Each of the models was augmented with assumptions of variability across trials in the rate of accumulation of evidence from stimuli, the values of response criteria, and the value of base RT across trials. Although there was substantial model mimicry, empirical conditions were identified under which the models make discriminably different predictions. The best accounts of the data were provided by the Wiener diffusion model, the OU model with small-to-moderate decay, and the accumulator model with long-tailed (exponential) distributions of criteria, although the last was unable to produce error RTs shorter than correct RTs. The relationship between these models and 3 recent, neurally inspired models was also examined.},
	number = {2},
	journal = {Psychological review},
	author = {Ratcliff, Roger and Smith, Philip L.},
	month = apr,
	year = {2004},
	keywords = {Choice Behavior, Humans, Models, Statistical, Models, Theoretical, Reaction Time, Sampling Studies},
	pages = {333--367}
}

@article{schultz_neural_1997,
	title = {A {Neural} {Substrate} of {Prediction} and {Reward}},
	volume = {275},
	issn = {0036-8075, 1095-9203},
	abstract = {The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control.},
	number = {5306},
	urldate = {2013-06-28},
	journal = {Science},
	author = {Schultz, Wolfram and Dayan, Peter and Montague, P. Read},
	month = mar,
	year = {1997},
	pages = {1593--1599},
	file = {Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\S52QH7QW\\1593.html:text/html}
}

@book{bishop_pattern_2006,
	title = {Pattern {Recognition} and {Machine} {Learning}},
	abstract = {This is the first textbook on pattern recognition to present the Bayesian viewpoint. The book presents approximate inference algorithms that permit fast approximate answers in situations where exact answers are not feasible. It uses graphical models to describe probability distributions when no other books apply graphical models to machine learning. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory.},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	month = aug,
	year = {2006},
	keywords = {Computers / Computer Graphics, Computers / Computer Vision \& Pattern Recognition, Computers / Intelligence (AI) \& Semantics, Mathematics / Probability \& Statistics / General}
}

@article{stephan_bayesian_2009,
	title = {Bayesian model selection for group studies},
	volume = {46},
	issn = {1053-8119},
	abstract = {Bayesian model selection (BMS) is a powerful method for determining the most likely among a set of competing hypotheses about the mechanisms that generated observed data. BMS has recently found widespread application in neuroimaging, particularly in the context of dynamic causal modelling (DCM). However, so far, combining BMS results from several subjects has relied on simple (fixed effects) metrics, e.g. the group Bayes factor (GBF), that do not account for group heterogeneity or outliers. In this paper, we compare the GBF with two random effects methods for BMS at the between-subject or group level. These methods provide inference on model-space using a classical and Bayesian perspective respectively. First, a classical (frequentist) approach uses the log model evidence as a subject-specific summary statistic. This enables one to use analysis of variance to test for differences in log-evidences over models, relative to inter-subject differences. We then consider the same problem in Bayesian terms and describe a novel hierarchical model, which is optimised to furnish a probability density on the models themselves. This new variational Bayes method rests on treating the model as a random variable and estimating the parameters of a Dirichlet distribution which describes the probabilities for all models considered. These probabilities then define a multinomial distribution over model space, allowing one to compute how likely it is that a specific model generated the data of a randomly chosen subject as well as the exceedance probability of one model being more likely than any other model. Using empirical and synthetic data, we show that optimising a conditional density of the model probabilities, given the log-evidences for each model over subjects, is more informative and appropriate than both the GBF and frequentist tests of the log-evidences. In particular, we found that the hierarchical Bayesian approach is considerably more robust than either of the other approaches in the presence of outliers. We expect that this new random effects method will prove useful for a wide range of group studies, not only in the context of DCM, but also for other modelling endeavours, e.g. comparing different source reconstruction methods for EEG/MEG or selecting among competing computational models of learning and decision-making.},
	number = {4},
	urldate = {2016-05-20},
	journal = {NeuroImage},
	author = {Stephan, Klaas Enno and Penny, Will D. and Daunizeau, Jean and Moran, Rosalyn J. and Friston, Karl J.},
	month = jul,
	year = {2009},
	keywords = {Bayes factor, DCM, Dynamic causal modelling, EEG, fMRI, Hierarchical models, MEG, Model comparison, Model evidence, Random effects, Source reconstruction, Variational Bayes},
	pages = {1004--1017},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\S4QMNZNX\\Stephan et al. - 2009 - Bayesian model selection for group studies.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\FIIBMQAW\\S1053811909002638.html:text/html}
}

@article{smith_psychophysically_1995,
	title = {Psychophysically principled models of visual simple reaction time},
	volume = {102},
	copyright = {(c) 2012 APA, all rights reserved},
	abstract = {Visual psychophysics has shown that the perceptual representation of a stimulus has complex time-varying properties that depend on the response characteristics of the channel on which it is encoded. A fundamental expression of these properties is the distinction between sustained and transient processing channels. A theoretical and mathematical framework is introduced that allows such properties to be incorporated into fully stochastic models of simple reaction time (RT). These models, the multichannel leaky stochastic integrators, combine a linear filter model of stimulus encoding with an accumulative decision process and yield a stimulus representation described by a time-inhomogeneous Ornstein-Uhlenbeck diffusion process. Methods for obtaining RT distributions for these models are described, together with comparative fits to luminance-increment data obtained under conditions of channel pooling and channel independence.},
	number = {3},
	journal = {Psychological Review},
	author = {Smith, Philip L.},
	year = {1995},
	keywords = {*Cognitive Processes, *Psychophysics, *Reaction Time, *Stochastic Modeling, Visual Discrimination},
	pages = {567--593}
}

@article{tajima_optimal_2016,
	title = {Optimal policy for value-based decision-making},
	volume = {7},
	issn = {2041-1723},
	abstract = {Drift diffusion models (DDM) are fundamental to our understanding of perceptual decision-making. Here, the authors show that DDM can implement optimal choice strategies in value-based decisions but require sufficient knowledge of reward contingencies and collapsing decision boundaries with time.},
	urldate = {2017-01-04},
	journal = {Nature Communications},
	author = {Tajima, Satohiro and Drugowitsch, Jan and Pouget, Alexandre},
	month = aug,
	year = {2016},
	pages = {12400},
	file = {Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\JSR87IK8\\ncomms12400.html:text/html}
}

@article{koechlin_architecture_2003,
	title = {The architecture of cognitive control in the human prefrontal cortex},
	volume = {302},
	issn = {1095-9203},
	abstract = {The prefrontal cortex (PFC) subserves cognitive control: the ability to coordinate thoughts or actions in relation with internal goals. Its functional architecture, however, remains poorly understood. Using brain imaging in humans, we showed that the lateral PFC is organized as a cascade of executive processes from premotor to anterior PFC regions that control behavior according to stimuli, the present perceptual context, and the temporal episode in which stimuli occur, respectively. The results support an unified modular model of cognitive control that describes the overall functional organization of the human lateral PFC and has basic methodological and theoretical implications.},
	language = {eng},
	number = {5648},
	journal = {Science (New York, N.Y.)},
	author = {Koechlin, Etienne and Ody, Chrystèle and Kouneiher, Frédérique},
	month = nov,
	year = {2003},
	pmid = {14615530},
	keywords = {Adult, Brain Mapping, Cognition, Cues, Female, Frontal Lobe, Humans, Learning, Magnetic Resonance Imaging, Male, Memory, Mental Processes, Models, Neurological, Photic Stimulation, Prefrontal Cortex, Psychomotor Performance, Reaction Time},
	pages = {1181--1185}
}

@article{simon_neural_2011,
	title = {Neural correlates of forward planning in a spatial decision task in humans},
	volume = {31},
	issn = {1529-2401},
	abstract = {Although reinforcement learning (RL) theories have been influential in characterizing the mechanisms for reward-guided choice in the brain, the predominant temporal difference (TD) algorithm cannot explain many flexible or goal-directed actions that have been demonstrated behaviorally. We investigate such actions by contrasting an RL algorithm that is model based, in that it relies on learning a map or model of the task and planning within it, to traditional model-free TD learning. To distinguish these approaches in humans, we used functional magnetic resonance imaging in a continuous spatial navigation task, in which frequent changes to the layout of the maze forced subjects continually to relearn their favored routes, thereby exposing the RL mechanisms used. We sought evidence for the neural substrates of such mechanisms by comparing choice behavior and blood oxygen level-dependent (BOLD) signals to decision variables extracted from simulations of either algorithm. Both choices and value-related BOLD signals in striatum, although most often associated with TD learning, were better explained by the model-based theory. Furthermore, predecessor quantities for the model-based value computation were correlated with BOLD signals in the medial temporal lobe and frontal cortex. These results point to a significant extension of both the computational and anatomical substrates for RL in the brain.},
	number = {14},
	journal = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
	author = {Simon, Dylan Alexander and Daw, Nathaniel D.},
	month = apr,
	year = {2011},
	keywords = {Adolescent, Adult, Algorithms, Brain, Brain Mapping, Cues, decision making, Female, Humans, Image Processing, Computer-Assisted, Individuality, Likelihood Functions, Linear Models, Magnetic Resonance Imaging, Male, Models, Neurological, Neuropsychological Tests, Oxygen, Probability, Reinforcement (Psychology), Space Perception, Statistics as Topic, Young Adult},
	pages = {5526--5539}
}

@article{diuk_hierarchical_2013,
	title = {Hierarchical {Learning} {Induces} {Two} {Simultaneous}, {But} {Separable}, {Prediction} {Errors} in {Human} {Basal} {Ganglia}},
	volume = {33},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/33/13/5797},
	abstract = {Studies suggest that dopaminergic neurons report a unitary, global reward prediction error signal. However, learning in complex real-life tasks, in particular tasks that show hierarchical structure, requires multiple prediction errors that may coincide in time. We used functional neuroimaging to measure prediction error signals in humans performing such a hierarchical task involving simultaneous, uncorrelated prediction errors. Analysis of signals in a priori anatomical regions of interest in the ventral striatum and the ventral tegmental area indeed evidenced two simultaneous, but separable, prediction error signals corresponding to the two levels of hierarchy in the task. This result suggests that suitably designed tasks may reveal a more intricate pattern of firing in dopaminergic neurons. Moreover, the need for downstream separation of these signals implies possible limitations on the number of different task levels that we can learn about simultaneously.},
	number = {13},
	urldate = {2013-06-27},
	journal = {The Journal of Neuroscience},
	author = {Diuk, Carlos and Tsai, Karin and Wallis, Jonathan and Botvinick, Matthew and Niv, Yael},
	month = mar,
	year = {2013},
	pmid = {23536092},
	pages = {5797--5805},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\59K3T6MX\\Diuk et al. - 2013 - Hierarchical Learning Induces Two Simultaneous, Bu.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\TJ8IQP5Q\\5797.html:text/html}
}

@article{shadlen_neural_2001,
	title = {Neural {Basis} of a {Perceptual} {Decision} in the {Parietal} {Cortex} ({Area} {LIP}) of the {Rhesus} {Monkey}},
	volume = {86},
	copyright = {Copyright © 2001 The American Physiological Society},
	issn = {0022-3077, 1522-1598},
	abstract = {We recorded the activity of single neurons in the posterior parietal cortex (area LIP) of two rhesus monkeys while they discriminated the direction of motion in random-dot visual stimuli. The visual task was similar to a motion discrimination task that has been used in previous investigations of motion-sensitive regions of the extrastriate cortex. The monkeys were trained to decide whether the direction of motion was toward one of two choice targets that appeared on either side of the random-dot stimulus. At the end of the trial, the monkeys reported their direction judgment by making an eye movement to the appropriate target. We studied neurons in LIP that exhibited spatially selective persistent activity during delayed saccadic eye movement tasks. These neurons are thought to carry high-level signals appropriate for identifying salient visual targets and for guiding saccadic eye movements. We arranged the motion discrimination task so that one of the choice targets was in the LIP neuron's response field (RF) while the other target was positioned well away from the RF. During motion viewing, neurons in LIP altered their firing rate in a manner that predicted the saccadic eye movement that the monkey would make at the end of the trial. The activity thus predicted the monkey's judgment of motion direction. This predictive activity began early in the motion-viewing period and became increasingly reliable as the monkey viewed the random-dot motion. The neural activity predicted the monkey's direction judgment on both easy and difficult trials (strong and weak motion), whether or not the judgment was correct. In addition, the timing and magnitude of the response was affected by the strength of the motion signal in the stimulus. When the direction of motion was toward the RF, stronger motion led to larger neural responses earlier in the motion-viewing period. When motion was away from the RF, stronger motion led to greater suppression of ongoing activity. Thus the activity of single neurons in area LIP reflects both the direction of an impending gaze shift and the quality of the sensory information that instructs such a response. The time course of the neural response suggests that LIP accumulates sensory signals relevant to the selection of a target for an eye movement.},
	number = {4},
	urldate = {2016-06-06},
	journal = {Journal of Neurophysiology},
	author = {Shadlen, Michael N. and Newsome, William T.},
	month = oct,
	year = {2001},
	pmid = {11600651},
	pages = {1916--1936},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\FMNFME6A\\Shadlen and Newsome - 2001 - Neural Basis of a Perceptual Decision in the Parie.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\GDCW988H\\1916.html:text/html}
}

@article{link_sequential_1975,
	title = {A sequential theory of psychological discrimination},
	volume = {40},
	issn = {0033-3123, 1860-0980},
	abstract = {A theory of discrimination which assumes that subjects compare psychological values evoked by a stimulus to a subjective referent is proposed. Momentary differences between psychological values for the stimulus and the referent are accumulated over time until one or the other of two response thresholds is first exceeded. The theory is analyzed as a random walk bounded between two absorbing barriers. A general solution to response conditioned expected response times is computed and the important role played by the moment generating function (mgf) for increments to the random walk is examined. From considerations of the mgf it is shown that unlike other random walk models [Stone, 1960; Laming, 1968] the present theory does not imply that response conditioned mean correct and error times must be equal. For two fixed stimuli and a fixed referent it is shown that by controlling values of response thresholds, subjects can produce Receiver Operating Characteristics similar or identical to those predicted by Signal Detection Theory, High Threshold Theory, or Low Threshold Theory.},
	number = {1},
	urldate = {2014-01-19},
	journal = {Psychometrika},
	author = {Link, S. W. and Heath, R. A.},
	month = mar,
	year = {1975},
	keywords = {Assessment, Testing and Evaluation, Psychometrics, Statistical Theory and Methods, Statistics for Social Science, Behavorial Science, Education, Public Policy, and Law},
	pages = {77--105}
}

@article{khodadadi_learning_2014,
	title = {Learning to maximize reward rate: a model based on semi-{Markov} decision processes},
	volume = {8},
	shorttitle = {Learning to maximize reward rate},
	abstract = {When animals have to make a number of decisions during a limited time interval, they face a fundamental problem: how much time they should spend on each decision in order to achieve the maximum possible total outcome. Deliberating more on one decision usually leads to more outcome but less time will remain for other decisions. In the framework of sequential sampling models, the question is how animals learn to set their decision threshold such that the total expected outcome achieved during a limited time is maximized. The aim of this paper is to provide a theoretical framework for answering this question. To this end, we consider an experimental design in which each trial can come from one of the several possible “conditions.” A condition specifies the difficulty of the trial, the reward, the penalty and so on. We show that to maximize the expected reward during a limited time, the subject should set a separate value of decision threshold for each condition. We propose a model of learning the optimal value of decision thresholds based on the theory of semi-Markov decision processes (SMDP). In our model, the experimental environment is modeled as an SMDP with each “condition” being a “state” and the value of decision thresholds being the “actions” taken in those states. The problem of finding the optimal decision thresholds then is cast as the stochastic optimal control problem of taking actions in each state in the corresponding SMDP such that the average reward rate is maximized. Our model utilizes a biologically plausible learning algorithm to solve this problem. The simulation results show that at the beginning of learning the model choses high values of decision threshold which lead to sub-optimal performance. With experience, however, the model learns to lower the value of decision thresholds till finally it finds the optimal values.},
	urldate = {2014-05-30},
	journal = {Decision Neuroscience},
	author = {Khodadadi, Arash and Fakhari, Pegah and Busemeyer, Jerome R},
	year = {2014},
	keywords = {average reward rate maximization, decision threshold, diffusion process, Reinforcement learning, semi-Markov decision process, Sequential sampling models, speed-accuracy trade-off},
	pages = {101},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\ICUN96XP\\Khodadadi et al. - 2014 - Learning to maximize reward rate a model based on.pdf:application/pdf}
}

@article{wang_generating_1992,
	title = {Generating fuzzy rules by learning from examples},
	volume = {22},
	issn = {0018-9472},
	doi = {10.1109/1.199466},
	abstract = {A general method is developed to generate fuzzy rules from numerical data. The method consists of five steps: divide the input and output spaces of the given numerical data into fuzzy regions; generate fuzzy rules from the given data; assign a degree of each of the generated rules for the purpose of resolving conflicts among the generated rules; create a combined fuzzy rule base based on both the generated rules and linguistic rules of human experts; and determine a mapping from input space to output space based on the combined fuzzy rule base using a defuzzifying procedure. The mapping is proved to be capable of approximating any real continuous function on a compact set to arbitrary accuracy. Applications to truck backer-upper control and time series prediction problems are presented},
	number = {6},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics},
	author = {Wang, L. X. and Mendel, J. M.},
	month = nov,
	year = {1992},
	keywords = {Control systems, Control system synthesis, Fuzzy control, Fuzzy logic, fuzzy rule base, fuzzy rule generation, Humans, Image processing, input space, knowledge based systems, learning by example, learning from examples, linguistic rules, mapping, Mathematical model, Neural networks, Nonlinear control systems, output space, Process control, Signal processing, time series prediction, truck backer-upper control},
	pages = {1414--1427},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\TTDBXQQH\\articleDetails.html:text/html}
}

@article{dezfouli_actions_2013,
	title = {Actions, action sequences and habits: evidence that goal-directed and habitual action control are hierarchically organized},
	volume = {9},
	issn = {1553-7358},
	shorttitle = {Actions, action sequences and habits},
	abstract = {Behavioral evidence suggests that instrumental conditioning is governed by two forms of action control: a goal-directed and a habit learning process. Model-based reinforcement learning (RL) has been argued to underlie the goal-directed process; however, the way in which it interacts with habits and the structure of the habitual process has remained unclear. According to a flat architecture, the habitual process corresponds to model-free RL, and its interaction with the goal-directed process is coordinated by an external arbitration mechanism. Alternatively, the interaction between these systems has recently been argued to be hierarchical, such that the formation of action sequences underlies habit learning and a goal-directed process selects between goal-directed actions and habitual sequences of actions to reach the goal. Here we used a two-stage decision-making task to test predictions from these accounts. The hierarchical account predicts that, because they are tied to each other as an action sequence, selecting a habitual action in the first stage will be followed by a habitual action in the second stage, whereas the flat account predicts that the statuses of the first and second stage actions are independent of each other. We found, based on subjects' choices and reaction times, that human subjects combined single actions to build action sequences and that the formation of such action sequences was sufficient to explain habitual actions. Furthermore, based on Bayesian model comparison, a family of hierarchical RL models, assuming a hierarchical interaction between habit and goal-directed processes, provided a better fit of the subjects' behavior than a family of flat models. Although these findings do not rule out all possible model-free accounts of instrumental conditioning, they do show such accounts are not necessary to explain habitual actions and provide a new basis for understanding how goal-directed and habitual action control interact.},
	number = {12},
	journal = {PLoS computational biology},
	author = {Dezfouli, Amir and Balleine, Bernard W.},
	year = {2013},
	keywords = {Bayes Theorem, decision making, Goals, Humans, Motivation, Reaction Time},
	pages = {e1003364}
}

@article{townsend_accuracy-response_2012,
	title = {An accuracy-response time capacity assessment function that measures performance against standard parallel predictions},
	volume = {119},
	issn = {1939-1471},
	abstract = {Measures of human efficiency under increases in mental workload or attentional limitations are vital in studying human perception, cognition, and action. Assays of efficiency as workload changes have typically been confined to either reaction times (RTs) or accuracy alone. Within the realm of RTs, a nonparametric measure called the workload capacity coefficient has been employed in many studies (Townsend \& Nozawa, 1995). However, the contribution of correct versus incorrect responses has been unavailable in that context. A nonparametric statistic that is capable of simultaneously taking into account accuracy as well as RTs would be highly useful. This theoretical study develops such a tool for two important decisional stopping rules. Preliminary data from a simple visual identification study illustrate one potential application.},
	number = {3},
	journal = {Psychological Review},
	author = {Townsend, James T and Altieri, Nicholas},
	month = jul,
	year = {2012},
	keywords = {Attention, Cognition, Data Interpretation, Statistical, decision making, Efficiency, Humans, Models, Psychological, Photic Stimulation, Psychological Theory, Reaction Time, Statistics, Nonparametric, Stochastic Processes, Task Performance and Analysis, Workload},
	pages = {500--516}
}

@article{evans_people_2016,
	title = {People adopt optimal policies in simple decision-making, after practice and guidance},
	issn = {1069-9384, 1531-5320},
	abstract = {Organisms making repeated simple decisions are faced with a tradeoff between urgent and cautious strategies. While animals can adopt a statistically optimal policy for this tradeoff, findings about human decision-makers have been mixed. Some studies have shown that people can optimize this “speed–accuracy tradeoff”, while others have identified a systematic bias towards excessive caution. These issues have driven theoretical development and spurred debate about the nature of human decision-making. We investigated a potential resolution to the debate, based on two factors that routinely differ between human and animal studies of decision-making: the effects of practice, and of longer-term feedback. Our study replicated the finding that most people, by default, are overly cautious. When given both practice and detailed feedback, people moved rapidly towards the optimal policy, with many participants reaching optimality with less than 1 h of practice. Our findings have theoretical implications for cognitive and neural models of simple decision-making, as well as methodological implications.},
	urldate = {2017-03-28},
	journal = {Psychonomic Bulletin \& Review},
	author = {Evans, Nathan J. and Brown, Scott D.},
	month = aug,
	year = {2016},
	pages = {1--10},
	file = {Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\CG5ACMX4\\Evans and Brown - 2016 - People adopt optimal policies in simple decision-m.html:text/html}
}

@article{fuster_prefrontal_2001,
	title = {The prefrontal cortex--an update: time is of the essence},
	volume = {30},
	issn = {0896-6273},
	shorttitle = {The prefrontal cortex--an update},
	language = {eng},
	number = {2},
	journal = {Neuron},
	author = {Fuster, J M},
	month = may,
	year = {2001},
	pmid = {11394996},
	keywords = {Animals, Brain Mapping, Cerebral Cortex, Cognition, Humans, Memory, Models, Neurological, Neurons, Prefrontal Cortex},
	pages = {319--333}
}

@article{koechlin_information_2007,
	title = {An information theoretical approach to prefrontal executive function},
	volume = {11},
	issn = {1364-6613},
	abstract = {The prefrontal cortex subserves executive control--that is, the ability to select actions or thoughts in relation to internal goals. Here, we propose a theory that draws upon concepts from information theory to describe the architecture of executive control in the lateral prefrontal cortex. Supported by evidence from brain imaging in human subjects, the model proposes that action selection is guided by hierarchically ordered control signals, processed in a network of brain regions organized along the anterior-posterior axis of the lateral prefrontal cortex. The theory clarifies how executive control can operate as a unitary function, despite the requirement that information be integrated across multiple distinct, functionally specialized prefrontal regions.},
	language = {eng},
	number = {6},
	journal = {Trends in cognitive sciences},
	author = {Koechlin, Etienne and Summerfield, Christopher},
	month = jun,
	year = {2007},
	pmid = {17475536},
	keywords = {Attention, Brain Mapping, decision making, Diagnosis, Differential, Diagnostic Imaging, Dominance, Cerebral, Humans, Imaging, Three-Dimensional, Information Theory, Motor Cortex, Nerve Net, Neural Networks (Computer), Prefrontal Cortex, Problem Solving, Somatosensory Cortex, Thinking},
	pages = {229--235}
}

@article{ratcliff_diffusion_2002,
	title = {A diffusion model account of response time and accuracy in a brightness discrimination task: {Fitting} real data and failing to fit fake but plausible data},
	volume = {9},
	shorttitle = {A diffusion model account of response time and accuracy in a brightness discrimination task},
	abstract = {A brightness discrimination experiment was performed to examine how subjects decide whether a patch of pixels is “bright” or “dark,” and stimulus duration, brightness, and speed versus accuracy instructions were manipulated. The diffusion model (Ratcliff, 1978) was fit to the data, and it accounted for all the dependent variables: mean correct and error response times, the shapes of response time distributions for correct and error responses, and accuracy values. Speed-accuracy manipulations affected only boundary separation (response criteria settings) in the model. Drift rate (the rate of accumulation of evidence) in the diffusion model, which represents stimulus quality, increased as a function of stimulus duration and stimulus brightness but asymptoted as stimulus duration increased from 100 to 150 msec. To address the argument that the diffusion model can fit any pattern of data, simulated patterns of plausible data are presented that the model cannot fit.},
	number = {2},
	urldate = {2014-01-19},
	journal = {Psychonomic Bulletin \& Review},
	author = {Ratcliff, Roger},
	month = jun,
	year = {2002},
	keywords = {Cognitive Psychology},
	pages = {278--291}
}

@article{frank_dynamic_2005,
	title = {Dynamic dopamine modulation in the basal ganglia: a neurocomputational account of cognitive deficits in medicated and nonmedicated {Parkinsonism}},
	volume = {17},
	issn = {0898-929X},
	shorttitle = {Dynamic dopamine modulation in the basal ganglia},
	abstract = {Dopamine (DA) depletion in the basal ganglia (BG) of Parkinson's patients gives rise to both frontal-like and implicit learning impairments. Dopaminergic medication alleviates some cognitive deficits but impairs those that depend on intact areas of the BG, apparently due to DA ''overdose.'' These findings are difficult to accommodate with verbal theories of BG/DA function, owing to complexity of system dynamics: DA dynamically modulates function in the BG, which is itself a modulatory system. This article presents a neural network model that instantiates key biological properties and provides insight into the underlying role of DA in the BG during learning and execution of cognitive tasks. Specifically, the BG modulates the execution of ''actions'' (e.g., motor different parts of the frontal cortex. Phasic changes in DA, which occur during error feedback, dynamically modulate the BG threshold for facilitating/suppressing a cortical command in response to particular stimuli. Reduced dynamic range of DA explains Parkinson and DA overdose deficits with a single underlying dysfunction, despite overall differences in raw DA levels. Simulated Parkinsonism and medication effects provide a theoretical basis for behavioral data in probabilistic classification and reversal tasks. The model also provides novel testable predictions for neuropsychological and pharmacological studies, and motivates further investigation of BG/DA interactions with the prefrontal cortex in working memory.},
	number = {1},
	journal = {Journal of cognitive neuroscience},
	author = {Frank, Michael J},
	month = jan,
	year = {2005},
	keywords = {Basal Ganglia, Brain Chemistry, Cognition Disorders, Dopamine, Feedback, Humans, Models, Neurological, Neural Inhibition, Neural Networks (Computer), Nonlinear Dynamics, Parkinson Disease, Probability},
	pages = {51--72}
}

@article{kiani_bounded_2008,
	title = {Bounded integration in parietal cortex underlies decisions even when viewing duration is dictated by the environment},
	volume = {28},
	issn = {1529-2401},
	abstract = {Decisions about sensory stimuli are often based on an accumulation of evidence in time. When subjects control stimulus duration, the decision terminates when the accumulated evidence reaches a criterion level. Under many natural circumstances and in many laboratory settings, the environment, rather than the subject, controls the stimulus duration. In these settings, it is generally assumed that subjects commit to a choice at the end of the stimulus stream. Indeed, failure to benefit from the full stream of information is interpreted as a sign of imperfect accumulation or memory leak. Contrary to these assumptions, we show that monkeys performing a direction discrimination task commit to a choice when the accumulated evidence reaches a threshold level (or bound), sometimes long before the end of stimulus. This bounded accumulation of evidence is reflected in the activity of neurons in the lateral intraparietal cortex. Thus, the readout of visual cortex embraces a termination rule to limit processing even when potentially useful information is available.},
	language = {eng},
	number = {12},
	journal = {The Journal of neuroscience: the official journal of the Society for Neuroscience},
	author = {Kiani, Roozbeh and Hanks, Timothy D and Shadlen, Michael N},
	month = mar,
	year = {2008},
	pmid = {18354005},
	keywords = {Animals, Behavior, Animal, Choice Behavior, Discrimination (Psychology), Entropy, Environment, Eye Movements, Macaca mulatta, Male, Motion Perception, Neurons, Parietal Lobe, Reaction Time, Signal Detection, Psychological, Statistics as Topic, Time Factors},
	pages = {3017--3029}
}

@book{tolman_purposive_1932,
	address = {New York},
	title = {Purposive {Behavior} in {Animals} and {Men}},
	publisher = {University of California Press},
	author = {Tolman, Edward Chace},
	year = {1932}
}

@article{hawkins_revisiting_2015,
	title = {Revisiting the evidence for collapsing boundaries and urgency signals in perceptual decision-making},
	volume = {35},
	issn = {1529-2401},
	abstract = {For nearly 50 years, the dominant account of decision-making holds that noisy information is accumulated until a fixed threshold is crossed. This account has been tested extensively against behavioral and neurophysiological data for decisions about consumer goods, perceptual stimuli, eyewitness testimony, memories, and dozens of other paradigms, with no systematic misfit between model and data. Recently, the standard model has been challenged by alternative accounts that assume that less evidence is required to trigger a decision as time passes. Such "collapsing boundaries" or "urgency signals" have gained popularity in some theoretical accounts of neurophysiology. Nevertheless, evidence in favor of these models is mixed, with support coming from only a narrow range of decision paradigms compared with a long history of support from dozens of paradigms for the standard theory. We conducted the first large-scale analysis of data from humans and nonhuman primates across three distinct paradigms using powerful model-selection methods to compare evidence for fixed versus collapsing bounds. Overall, we identified evidence in favor of the standard model with fixed decision boundaries. We further found that evidence for static or dynamic response boundaries may depend on specific paradigms or procedures, such as the extent of task practice. We conclude that the difficulty of selecting between collapsing and fixed bounds models has received insufficient attention in previous research, calling into question some previous results.},
	number = {6},
	journal = {The Journal of Neuroscience},
	author = {Hawkins, Guy E. and Forstmann, Birte U. and Wagenmakers, Eric-Jan and Ratcliff, Roger and Brown, Scott D.},
	month = feb,
	year = {2015},
	keywords = {Algorithms, Animals, decision making, Decision-making, Diffusion model, Discrimination (Psychology), Female, human, Humans, Macaca mulatta, Male, Models, Neurological, Motion Perception, nonhuman primate, Photic Stimulation, Reaction Time, response time, Visual Perception, Young Adult},
	pages = {2476--2484}
}

@incollection{diuk_divide_nodate,
	title = {Divide and conquer: task decomposition and hierarchical reinforcement learning in human},
	booktitle = {Computational and {Robotic} {Models} of the {Hierarchical} {Organization} of {Behavior}},
	publisher = {Springer Verlag},
	author = {Diuk, Carlos and Schapiro, A and Cordova, A and Ribas-Fernandes, J J F and Niv, Yael and Botvinick, Matthew}
}

@article{capocelli_inverse_1972,
	title = {On the {Inverse} of the {First} {Passage} {Time} {Probability} {Problem}},
	volume = {9},
	issn = {0021-9002},
	abstract = {Since the pioneering work of Siegert (1951), the problem of determining the first passage time distribution for a preassigned continuous and time homogeneous Markov process described by a diffusion equation has been deeply analyzed and satisfactorily solved. Here we discuss the "inverse problem" - of applicative interest - consisting in deciding whether a given function can be considered as the first passage time probability density function for some continuous and homogeneous Markov diffusion process. A constructive criterion is proposed, and some examples are provided. One of these leads to a singular diffusion equation representing a dynamical model for the genesis of the lognormal distribution.},
	number = {2},
	urldate = {2013-07-05},
	journal = {Journal of Applied Probability},
	author = {Capocelli, R. M. and Ricciardi, L. M.},
	month = jun,
	year = {1972},
	pages = {270--287},
	file = {JSTOR Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\XEMPZI48\\Capocelli and Ricciardi - 1972 - On the Inverse of the First Passage Time Probabili.pdf:application/pdf}
}

@article{blodgett_effect_1929,
	title = {The effect of the introduction of reward upon the maze performance of rats},
	volume = {4},
	copyright = {(c) 2012 APA, all rights reserved},
	abstract = {"The purpose of this investigation was to study the efficiency of units of practice when unaccompanied by reward. The method devised was that of running two groups of rats through the maze: an experimental group which received no reward during the first part of learning, but which suddenly had reward introduced in the latter part of learning, and a control group which received reward throughout the whole of learning. The answer to the question as to the efficiency of non-reward units of practice was sought in a comparison of the learning curve of the experimental group (both before and after the introduction of reward) with that of the control group." Three mazes were used, two with ordinary blinds and one with blinds arranged so that the animal could go two ways as well as having as alternatives a long and a short path. "They prevented retracings from one section of the maze to another, they were noiseless, and they caused no excitement in the animals." There were 36 rats in each group. The results show that: "(1) Rats run under a non-reward condition learned much more slowly than rats run under a reward condition." "(2) Rats previously run under a non-reward condition, when suddenly rewarded made a great improvement." "(3) During the non-reward period, the rats were developing a latent learning of the maze which they were able to utilize as soon as reward was introduced." "(5) It was demonstrated by the use of the two-path maze that the latent learning which was developed under non-reward conditions and was made manifest as soon as reward was introduced was not the result of any very consistently greater frequency of the correct over the incorrect path during the non-reward period." Bibliography and discussions.},
	journal = {University of California Publications in Psychology},
	author = {Blodgett, H C},
	year = {1929},
	pages = {113--134},
	file = {APA PsycNET Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\DQ2I9N69\\index.html:text/html}
}

@article{koechlin_brocas_2006,
	title = {Broca's area and the hierarchical organization of human behavior},
	volume = {50},
	issn = {0896-6273},
	abstract = {The prefrontal cortex subserves executive control, i.e., the organization of action or thought in relation to internal goals. This brain region hosts a system of executive processes extending from premotor to the most anterior prefrontal regions that governs the temporal organization of behavior. Little is known, however, about the prefrontal executive system involved in the hierarchical organization of behavior. Here, we show using magnetic resonance imaging in humans that the posterior portion of the prefrontal cortex, including Broca's area and its homolog in the right hemisphere, contains a system of executive processes that control start and end states and the nesting of functional segments that combine in hierarchically organized action plans. Our results indicate that Broca's area and its right homolog process hierarchically structured behaviors regardless of their temporal organization, suggesting a fundamental segregation between prefrontal executive systems involved in the hierarchical and temporal organization of goal-directed behaviors.},
	language = {eng},
	number = {6},
	journal = {Neuron},
	author = {Koechlin, Etienne and Jubault, Thomas},
	month = jun,
	year = {2006},
	pmid = {16772176},
	keywords = {Adult, Behavior, Brain Mapping, Frontal Lobe, Humans, Models, Neurological, Psychomotor Performance, Reaction Time},
	pages = {963--974}
}

@book{cox_theory_1965,
	address = {London},
	title = {The theory of stochastic processes},
	publisher = {Methuen},
	author = {Cox, D. R and Miller, H. D},
	year = {1965}
}

@article{gershman_empirical_2016,
	title = {Empirical priors for reinforcement learning models},
	volume = {71},
	abstract = {Computational models of reinforcement learning have played an important role in understanding learning and decision making behavior, as well as the neural mechanisms underlying these behaviors. However, fitting the parameters of these models can be challenging: the parameters are not identifiable, estimates are unreliable, and the fitted models may not have good predictive validity. Prior distributions on the parameters can help regularize estimates and to some extent deal with these challenges, but picking a good prior is itself challenging. This paper presents empirical priors for reinforcement learning models, showing that priors estimated from a relatively large dataset are more identifiable, more reliable, and have better predictive validity compared to model-fitting with uniform priors.},
	urldate = {2016-05-20},
	journal = {Journal of Mathematical Psychology},
	author = {Gershman, Samuel J.},
	month = apr,
	year = {2016},
	keywords = {Bayesian statistics, Model comparison, Parameter estimation, Q-learning},
	pages = {1--6},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\CHBGD8AX\\Gershman - 2016 - Empirical priors for reinforcement learning models.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\TGNKAN2M\\Gershman - 2016 - Empirical priors for reinforcement learning models.html:text/html}
}

@article{eidels_nice_2011,
	title = {Nice {Guys} {Finish} {Fast} and {Bad} {Guys} {Finish} {Last}: {Facilitatory} vs. {Inhibitory} {Interaction} in {Parallel} {Systems}},
	volume = {55},
	issn = {0022-2496},
	shorttitle = {Nice {Guys} {Finish} {Fast} and {Bad} {Guys} {Finish} {Last}},
	abstract = {Systems Factorial Technology is a powerful framework for investigating the fundamental properties of human information processing such as architecture (i.e., serial or parallel processing) and capacity (how processing efficiency is affected by increased workload). The Survivor Interaction Contrast (SIC) and the Capacity Coefficient are effective measures in determining these underlying properties, based on response-time data. Each of the different architectures, under the assumption of independent processing, predicts a specific form of the SIC along with some range of capacity. In this study, we explored SIC predictions of discrete-state (Markov process) and continuous-state (Linear Dynamic) models that allow for certain types of cross-channel interaction. The interaction can be facilitatory or inhibitory: one channel can either facilitate, or slow down processing in its counterpart. Despite the relative generality of these models, the combination of the architecture-oriented plus the capacity oriented analyses provide for precise identification of the underlying system.},
	number = {2},
	journal = {Journal of Mathematical Psychology},
	author = {Eidels, Ami and Houpt, Joseph W and Altieri, Nicholas and Pei, Lei and Townsend, James T},
	month = apr,
	year = {2011},
	pages = {176--190}
}

@article{mahadevan_average_1996,
	title = {Average reward reinforcement learning: {Foundations}, algorithms, and empirical results},
	volume = {22},
	issn = {0885-6125, 1573-0565},
	abstract = {This paper presents a detailed study of average reward reinforcement learning, an undiscounted optimality framework that is more appropriate for cyclical tasks than the much better studied discounted framework. A wide spectrum of average reward algorithms are described, ranging from synchronous dynamic programming methods to several (provably convergent) asynchronous algorithms from optimal control and learning automata. A general sensitive discount optimality metric calledn-discount-optimality is introduced, and used to compare the various algorithms. The overview identifies a key similarity across several asynchronous algorithms that is crucial to their convergence, namely independent estimation of the average reward and the relative values. The overview also uncovers a surprising limitation shared by the different algorithms while several algorithms can provably generategain-optimal policies that maximize average reward, none of them can reliably filter these to producebias-optimal (orT-optimal) policies that also maximize the finite reward to absorbing goal states. This paper also presents a detailed empirical study of R-learning, an average reward reinforcement learning method, using two empirical testbeds: a stochastic grid world domain and a simulated robot environment. A detailed sensitivity analysis of R-learning is carried out to test its dependence on learning rates and exploration levels. The results suggest that R-learning is quite sensitive to exploration strategies and can fall into sub-optimal limit cycles. The performance of R-learning is also compared with that of Q-learning, the best studied discounted RL method. Here, the results suggest that R-learning can be fine-tuned to give better performance than Q-learning in both domains.},
	number = {1-3},
	urldate = {2014-11-18},
	journal = {Machine Learning},
	author = {Mahadevan, Sridhar},
	month = mar,
	year = {1996},
	keywords = {Artificial Intelligence (incl. Robotics), Automation and Robotics, Computer Science, general, Markov decision processes, Reinforcement learning},
	pages = {159--195},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\RIXD23IP\\Mahadevan - 1996 - Average reward reinforcement learning Foundations.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\KJPSK45G\\10.html:text/html}
}

@article{kahneman_prospect_1979,
	title = {Prospect {Theory}: {An} {Analysis} of {Decision} under {Risk}},
	volume = {47},
	shorttitle = {Prospect {Theory}},
	abstract = {This paper presents a critique of expected utility theory as a descriptive model of decision making under risk, and develops an alternative model, called prospect theory. Choices among risky prospects exhibit several pervasive effects that are inconsistent with the basic tenets of utility theory. In particular, people underweight outcomes that are merely probable in comparison with outcomes that are obtained with certainty. This tendency, called the certainty effect, contributes to risk aversion in choices involving sure gains and to risk seeking in choices involving sure losses. In addition, people generally discard components that are shared by all prospects under consideration. This tendency, called the isolation effect, leads to inconsistent preferences when the same choice is presented in different forms. An alternative theory of choice is developed, in which value is assigned to gains and losses rather than to final assets and in which probabilities are replaced by decision weights. The value function is normally concave for gains, commonly convex for losses, and is generally steeper for losses than for gains. Decision weights are generally lower than the corresponding probabilities, except in the range of low probabilities. Overweighting of low probabilities may contribute to the attractiveness of both insurance and gambling.},
	number = {2},
	urldate = {2016-04-13},
	journal = {Econometrica},
	author = {Kahneman, Daniel and Tversky, Amos},
	year = {1979},
	pages = {263--291}
}

@article{badre_mechanisms_2012,
	title = {Mechanisms of hierarchical reinforcement learning in cortico-striatal circuits 2: evidence from {fMRI}},
	volume = {22},
	issn = {1460-2199},
	shorttitle = {Mechanisms of hierarchical reinforcement learning in cortico-striatal circuits 2},
	abstract = {The frontal lobes may be organized hierarchically such that more rostral frontal regions modulate cognitive control operations in caudal regions. In our companion paper (Frank MJ, Badre D. 2011. Mechanisms of hierarchical reinforcement learning in corticostriatal circuits I: computational analysis. 22:509-526), we provide novel neural circuit and algorithmic models of hierarchical cognitive control in cortico-striatal circuits. Here, we test key model predictions using functional magnetic resonance imaging (fMRI). Our neural circuit model proposes that contextual representations in rostral frontal cortex influence the striatal gating of contextual representations in caudal frontal cortex. Reinforcement learning operates at each level, such that the system adaptively learns to gate higher order contextual information into rostral regions. Our algorithmic Bayesian "mixture of experts" model captures the key computations of this neural model and provides trial-by-trial estimates of the learner's latent hypothesis states. In the present paper, we used these quantitative estimates to reanalyze fMRI data from a hierarchical reinforcement learning task reported in Badre D, Kayser AS, D'Esposito M. 2010. Frontal cortex and the discovery of abstract action rules. Neuron. 66:315--326. Results validate key predictions of the models and provide evidence for an individual cortico-striatal circuit for reinforcement learning of hierarchical structure at a specific level of policy abstraction. These findings are initially consistent with the proposal that hierarchical control in frontal cortex may emerge from interactions among nested cortico-striatal circuits at different levels of abstraction.},
	number = {3},
	journal = {Cerebral cortex (New York, N.Y.: 1991)},
	author = {Badre, David and Frank, Michael J},
	month = mar,
	year = {2012},
	pmid = {21693491},
	keywords = {Brain Mapping, Cerebral Cortex, Clinical Trials as Topic, Corpus Striatum, Humans, Learning, Magnetic Resonance Imaging, Models, Neurological, Nerve Net, Neural Pathways, Reinforcement (Psychology)},
	pages = {527--536}
}

@article{smith_diffusion_2014,
	title = {The diffusion model is not a deterministic growth model: {Comment} on {Jones} and {Dzhafarov} (2014)},
	volume = {121},
	issn = {1939-1471},
	shorttitle = {The diffusion model is not a deterministic growth model},
	abstract = {Jones and Dzhafarov (2014) claim that several current models of speeded decision making in cognitive tasks, including the diffusion model, can be viewed as special cases of other general models or model classes. The general models can be made to match any set of response time (RT) distribution and accuracy data exactly by a suitable choice of parameters and so are unfalsifiable. The implication of their claim is that models like the diffusion model are empirically testable only by artificially restricting them to exclude unfalsifiable instances of the general model. We show that Jones and Dzhafarov's argument depends on enlarging the class of "diffusion" models to include models in which there is little or no diffusion. The unfalsifiable models are deterministic or near-deterministic growth models, from which the effects of within-trial variability have been removed or in which they are constrained to be negligible. These models attribute most or all of the variability in RT and accuracy to across-trial variability in the rate of evidence growth, which is permitted to be distributed arbitrarily and to vary freely across experimental conditions. In contrast, in the standard diffusion model, within-trial variability in evidence is the primary determinant of variability in RT. Across-trial variability, which determines the relative speed of correct responses and errors, is theoretically and empirically constrained. Jones and Dzhafarov's attempt to include the diffusion model in a class of models that also includes deterministic growth models misrepresents and trivializes it and conveys a misleading picture of cognitive decision-making research. (PsycINFO Database Record (c) 2014 APA, all rights reserved).},
	number = {4},
	journal = {Psychological Review},
	author = {Smith, Philip L. and Ratcliff, Roger and McKoon, Gail},
	month = oct,
	year = {2014},
	pages = {679--688}
}

@article{bogacz_neural_2010,
	title = {The neural basis of the speed-accuracy tradeoff},
	volume = {33},
	abstract = {In many situations, decision makers need to negotiate between the competing demands of response speed and response accuracy, a dilemma generally known as the speed-accuracy tradeoff (SAT). Despite the ubiquity of SAT, the question of how neural decision circuits implement SAT has received little attention up until a year ago. We review recent studies that show SAT is modulated in association and pre-motor areas rather than in sensory or primary motor areas. Furthermore, the studies suggest that emphasis on response speed increases the baseline firing rate of cortical integrator neurons. We also review current theories on how and where in the brain the SAT is controlled, and we end by proposing research directions that could distinguish between these theories.},
	number = {1},
	journal = {Trends in neurosciences},
	author = {Bogacz, Rafal and Wagenmakers, Eric-Jan and Forstmann, Birte U and Nieuwenhuis, Sander},
	month = jan,
	year = {2010},
	keywords = {Brain, Humans, Models, Neurological, Psychomotor Performance, Reaction Time},
	pages = {10--16}
}

@article{hawkins_optimal_2012,
	title = {An optimal adjustment procedure to minimize experiment time in decisions with multiple alternatives},
	volume = {19},
	issn = {1531-5320},
	abstract = {Decisions between multiple alternatives typically conform to Hick's Law: Mean response time increases log-linearly with the number of choice alternatives. We recently demonstrated context effects in Hick's Law, showing that patterns of response latency and choice accuracy were different for easy versus difficult blocks. The context effect explained previously observed discrepancies in error rate data and provided a new challenge for theoretical accounts of multialternative choice. In the present article, we propose a novel approach to modeling context effects that can be applied to any account that models the speed-accuracy trade-off. The core element of the approach is "optimality" in the way an experimental participant might define it: minimizing the total time spent in the experiment, without making too many errors. We show how this approach can be included in an existing Bayesian model of choice and highlight its ability to fit previous data as well as to predict novel empirical context effects. The model is shown to provide better quantitative fits than a more flexible heuristic account.},
	number = {2},
	journal = {Psychonomic Bulletin \& Review},
	author = {Hawkins, Guy E. and Brown, Scott D. and Steyvers, Mark and Wagenmakers, Eric-Jan},
	month = apr,
	year = {2012},
	keywords = {Bayes Theorem, decision making, Humans, Models, Psychological, Pattern Recognition, Visual, Photic Stimulation, Reaction Time, Time Factors},
	pages = {339--348}
}

@article{dickinson_actions_1985,
	title = {Actions and {Habits}: {The} {Development} of {Behavioural} {Autonomy}},
	volume = {308},
	issn = {0962-8436, 1471-2970},
	shorttitle = {Actions and {Habits}},
	number = {1135},
	urldate = {2014-04-15},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Dickinson, A},
	month = feb,
	year = {1985},
	pages = {67--78},
	file = {NASA ADS\: Actions and Habits\: The Development of Behavioural Autonomy:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\P3VRBKQU\\1985RSPTB.308...html:text/html}
}

@article{alexander_medial_2011,
	title = {Medial prefrontal cortex as an action-outcome predictor},
	volume = {14},
	copyright = {© 2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1097-6256},
	abstract = {The medial prefrontal cortex (mPFC) and especially anterior cingulate cortex is central to higher cognitive function and many clinical disorders, yet its basic function remains in dispute. Various competing theories of mPFC have treated effects of errors, conflict, error likelihood, volatility and reward, using findings from neuroimaging and neurophysiology in humans and monkeys. No single theory has been able to reconcile and account for the variety of findings. Here we show that a simple model based on standard learning rules can simulate and unify an unprecedented range of known effects in mPFC. The model reinterprets many known effects and suggests a new view of mPFC, as a region concerned with learning and predicting the likely outcomes of actions, whether good or bad. Cognitive control at the neural level is then seen as a result of evaluating the probable and actual outcomes of one's actions.},
	number = {10},
	urldate = {2013-07-23},
	journal = {Nature Neuroscience},
	author = {Alexander, William H. and Brown, Joshua W.},
	month = oct,
	year = {2011},
	pages = {1338--1344},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\QN695R5T\\Alexander and Brown - 2011 - Medial prefrontal cortex as an action-outcome pred.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\3KRV6N58\\nn.2921.html:text/html}
}

@book{slotine_applied_1991,
	address = {Englewood Cliffs, N.J},
	title = {Applied {Nonlinear} {Control}},
	isbn = {978-0-13-040890-7},
	abstract = {Covers in a progressive fashion a number of analysis tools and design techniques directly applicable to nonlinear control problems in high performance systems (in aerospace, robotics and automotive areas).},
	publisher = {Pearson},
	author = {Slotine, Jean-Jacques and Li, Weiping},
	year = {1991}
}

@article{montague_framework_1996,
	title = {A framework for mesencephalic dopamine systems based on predictive {Hebbian} learning},
	volume = {16},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/16/5/1936},
	abstract = {We develop a theoretical framework that shows how mesencephalic dopamine systems could distribute to their targets a signal that represents information about future expectations. In particular, we show how activity in the cerebral cortex can make predictions about future receipt of reward and how fluctuations in the activity levels of neurons in diffuse dopamine systems above and below baseline levels would represent errors in these predictions that are delivered to cortical and subcortical targets. We present a model for how such errors could be constructed in a real brain that is consistent with physiological results for a subset of dopaminergic neurons located in the ventral tegmental area and surrounding dopaminergic neurons. The theory also makes testable predictions about human choice behavior on a simple decision-making task. Furthermore, we show that, through a simple influence on synaptic plasticity, fluctuations in dopamine release can act to change the predictions in an appropriate manner.},
	number = {5},
	urldate = {2013-12-16},
	journal = {The Journal of Neuroscience},
	author = {Montague, P. Read and Dayan, Peter and Sejnowski, Terrence J.},
	month = mar,
	year = {1996},
	pages = {1936--1947}
}

@book{aggarwal_data_2015,
	title = {Data {Mining}: {The} {Textbook}},
	shorttitle = {Data {Mining}},
	abstract = {This textbook explores the different aspects of data mining from the fundamentals to the complex data types and their applications, capturing the wide diversity of problem domains for data mining issues. It goes beyond the traditional focus on data mining problems to introduce advanced data types such as text, time series, discrete sequences, spatial data, graph data, and social networks. Until now, no single book has addressed all these topics in a comprehensive and integrated way. The chapters of this book fall into one of three categories: Fundamental chapters: Data mining has four main problems, which correspond to clustering, classification, association pattern mining, and outlier analysis. These chapters comprehensively discuss a wide variety of methods for these problems. Domain chapters: These chapters discuss the specific methods used for different domains of data such as text data, time-series data, sequence data, graph data, and spatial data. Application chapters: These chapters study important applications such as stream mining, Web mining, ranking, recommendations, social networks, and privacy preservation. The domain chapters also have an applied flavor. Appropriate for both introductory and advanced data mining courses, Data Mining: The Textbook balances mathematical details and intuition. It contains the necessary mathematical details for professors and researchers, but it is presented in a simple and intuitive style to improve accessibility for students and industrial practitioners (including those with a limited mathematical background). Numerous illustrations, examples, and exercises are included, with an emphasis on semantically interpretable examples.Praise for Data Mining: The Textbook - “As I read through this book, I have already decided to use it in my classes. This is a book written by an outstanding researcher who has made fundamental contributions to data mining, in a way that is both accessible and up to date. The book is complete with theory and practical use cases. It’s a must-have for students and professors alike!" -- Qiang Yang, Chair of Computer Science and Engineering at Hong Kong University of Science and Technology"This is the most amazing and comprehensive text book on data mining. It covers not only the fundamental problems, such as clustering, classification, outliers and frequent patterns, and different data types, including text, time series, sequences, spatial data and graphs, but also various applications, such as recommenders, Web, social network and privacy. It is a great book for graduate students and researchers as well as practitioners." -- Philip S. Yu, UIC Distinguished Professor and Wexler Chair in Information Technology at University of Illinois at Chicago},
	publisher = {Springer},
	author = {Aggarwal, Charu C.},
	month = apr,
	year = {2015},
	keywords = {Computers / Computer Vision \& Pattern Recognition, Computers / Databases / Data Mining, Computers / Information Technology, Computers / Optical Data Processing}
}

@article{kingma_adam:_2014,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2016-12-11},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik and Ba, Jimmy},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Learning},
	annote = {Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015},
	file = {arXiv\:1412.6980 PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\J28SVPCN\\Kingma and Ba - 2014 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\7U5MHKJB\\1412.html:text/html}
}

@article{wickelgren_speed-accuracy_1977,
	title = {Speed-accuracy tradeoff and information processing dynamics},
	volume = {41},
	issn = {00016918},
	abstract = {For a long time, it has been known that one can tradeoff accuracy for speed in (presumably) any task. The range over which one can obtain substantial speed-accuracy tradeoff varies from 150 msec in some very simple perceptual tasks to 1,000 msec in some recognition memory tasks and presumably even longer in more complex cognitive tasks. Obtaining an entire speed-accuracy tradeoff function provides much greater knowledge concerning information processing dynamics than is obtained by a reaction- time experiment, which yields the equivalent of a single point on this function. For this and other reasons, speed-accuracy tradeoff studies are often preferable to reaction-time studies of the dynamics of perceptual, memory, and cognitive processes. Methods of obtaining speed-accuracy tradeoff functions include: instructions, payoffs, deadlines, bands, response signals (with blocked and mixed designs), and partitioning of reaction time. A combination of the mixed-design signal method supplemented by partitioning of reaction times appears to be the optimal method.},
	number = {1},
	urldate = {2014-01-19},
	journal = {Acta Psychologica},
	author = {Wickelgren, Wayne},
	month = feb,
	year = {1977},
	keywords = {Humans, speed-accuracy},
	pages = {67--85}
}

@article{buonocore_new_1987,
	title = {A {New} {Integral} {Equation} for the {Evaluation} of {First}-{Passage}-{Time} {Probability} {Densities}},
	volume = {19},
	copyright = {Copyright © 1987 Applied Probability Trust},
	issn = {0001-8678},
	abstract = {The first-passage-time p.d.f. through a time-dependent boundary for one-dimensional diffusion processes is proved to satisfy a new Volterra integral equation of the second kind involving two arbitrary continuous functions. Use of this equation is made to prove that for the Wiener and the Ornstein-Uhlenbeck processes the singularity of the kernel can be removed by a suitable choice of these functions. A simple and efficient numerical procedure for the solution of the integral equation is provided and its convergence is briefly discussed. Use of this equation is finally made to obtain closed-form expressions for first-passage-time p.d.f.'s in the case of various time-dependent boundaries.},
	number = {4},
	urldate = {2013-07-08},
	journal = {Advances in Applied Probability},
	author = {Buonocore, A. and Nobile, A. G. and Ricciardi, L. M.},
	month = dec,
	year = {1987},
	note = {ArticleType: research-article / Full publication date: Dec., 1987 / Copyright © 1987 Applied Probability Trust},
	pages = {784--800},
	file = {JSTOR Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\VIPRUU8M\\Buonocore et al. - 1987 - A New Integral Equation for the Evaluation of Firs.pdf:application/pdf}
}

@book{sutton_reinforcement_1998,
	address = {Cambridge, MA},
	title = {Reinforcement {Learning}: {An} {Introduction} ({Adaptive} {Computation} and {Machine} {Learning})},
	isbn = {0-262-19398-1},
	shorttitle = {Reinforcement {Learning}},
	abstract = {Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In \_Reinforcement Learning\_, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.},
	urldate = {2013-12-16},
	publisher = {MIT Press},
	author = {Sutton, Richard and Barto, Andrew G},
	month = mar,
	year = {1998},
	keywords = {book, dynamic, reinforcement, rl, theory}
}

@article{wahlstrom_pixels_2015,
	title = {From {Pixels} to {Torques}: {Policy} {Learning} with {Deep} {Dynamical} {Models}},
	shorttitle = {From {Pixels} to {Torques}},
	url = {http://arxiv.org/abs/1502.02251},
	abstract = {Data-efficient learning in continuous state-action spaces using very high-dimensional observations remains a key challenge in developing fully autonomous systems. In this paper, we consider one instance of this challenge, the pixels to torques problem, where an agent must learn a closed-loop control policy from pixel information only. We introduce a data-efficient, model-based reinforcement learning algorithm that learns such a closed-loop policy directly from pixel information. The key ingredient is a deep dynamical model that uses deep auto-encoders to learn a low-dimensional embedding of images jointly with a predictive model in this low-dimensional feature space. Joint learning ensures that not only static but also dynamic properties of the data are accounted for. This is crucial for long-term predictions, which lie at the core of the adaptive model predictive control strategy that we use for closed-loop control. Compared to state-of-the-art reinforcement learning methods for continuous states and actions, our approach learns quickly, scales to high-dimensional state spaces and is an important step toward fully autonomous learning from pixels to torques.},
	urldate = {2016-12-12},
	journal = {arXiv:1502.02251 [cs, stat]},
	author = {Wahlström, Niklas and Schön, Thomas B. and Deisenroth, Marc Peter},
	month = feb,
	year = {2015},
	note = {arXiv: 1502.02251},
	keywords = {Computer Science - Learning, Computer Science - Robotics, Computer Science - Systems and Control, Statistics - Machine Learning},
	annote = {Comment: 9 pages}
}

@article{brown_ballistic_2005,
	title = {A ballistic model of choice response time},
	volume = {112},
	issn = {0033-295X},
	abstract = {Almost all models of response time (RT) use a stochastic accumulation process. To account for the benchmark RT phenomena, researchers have found it necessary to include between-trial variability in the starting point and/or the rate of accumulation, both in linear (R. Ratcliff \& J. N. Rouder, 1998) and nonlinear (M. Usher \& J. L. McClelland, 2001) models. The authors show that a ballistic (deterministic within-trial) model using a simplified version of M. Usher and J. L. McClelland's (2001) nonlinear accumulation process with between-trial variability in accumulation rate and starting point is capable of accounting for the benchmark behavioral phenomena. The authors successfully fit their model to R. Ratcliff and J. N. Rouder's (1998) data, which exhibit many of the benchmark phenomena.},
	number = {1},
	journal = {Psychological review},
	author = {Brown, Scott D and Heathcote, Andrew},
	month = jan,
	year = {2005},
	keywords = {Choice Behavior, Humans, Models, Psychological, Reaction Time, Stochastic Processes},
	pages = {117--128}
}

@article{evert_statistics_2005,
	title = {The statistics of word cooccurrences : word pairs and collocations},
	copyright = {info:eu-repo/semantics/openAccess},
	shorttitle = {The statistics of word cooccurrences},
	abstract = {"You shall know a word by the company it keeps!"  With this slogan, J. R. Firth drew attention to a fact that language scholars had intuitively known for a long time: In natural language, words are not combined randomly into phrases and sentences, constrained only by the rules of syntax.  They have a tendency to appear in certain recurrent combinations. As there are many possible reasons for words to go together, a broad range of linguistic and extra-linguistic phenomena can be found among the recurrent combinations, making them a goldmine of information for linguistics, natural language processing and related fields.  There are compound nouns ("black box"), fixed and opaque idioms ("kick the bucket"), lexical selection ("a pride of lions", "heavy smoker") and formulaic expressions ("have a nice day").  They can often tell us something about the meaning of a word or even the concept behind the word (think of combinations like "dark night" and "bright day"), an idea that has inspired latent semantic analysis and similar vector space models of word meaning.
With modern computers it is easy to extract evidence for recurrent word pairs from huge text corpora, often aided by linguistic pre-processing and annotation (so that specific combinations, e.g. noun+verb can be targeted). However, the raw data - in the form of frequency counts for word pairs – are not always meaningful as a measure for the amount of "glue" between two words. Provided that both words are sufficiently frequent, their cooccurrences might be pure coincidence.  Therefore, a statistical interpretation of the frequency data is necessary, which determines the degree of statistical association between the words and whether there is enough evidence to rule out chance as a factor. For this purpose, association measures are applied, which assign a score to each word pair based on the observed frequency data.  The higher this score is, the stronger and more certain the association between the two words.
Even forty years ago, at the Symposium on Statistical Association Methods for Mechanized Documentation, there was a bewildering multitude of measures to choose from, but hardly any guidelines to help with the decision.  This situation hasn't changed very much over the last forty years.  We are still far away from a thorough understanding of association measures and there is not even a standard reference where one could look up precise definitions and related information.  My thesis aims to fill this gap.
The first, encyclopedic part of the thesis begins with a description of the formal and statistical prerequisites. Intended primarily as a reference for students and researchers, it also addresses the limits of the statistical models.  The following chapter presents a comprehensive repository of association measures, which are organised into thematic groups.  An explicit equation is given for each measure, using a consistent notation in terms of observed and expected frequencies.
The second, methodological part suggests new approaches to the study of association measures, with an emphasis on empirical results and intuitive understanding.  A cornerstone of this approach is a geometric interpretation of cooccurrence data and association measure.  Measures are visualised as surfaces in a three-dimensional "coordinate space".  The properties of each measure are determined by the geometric shapes of the respective surfaces.
Empirical results are obtained from evaluation studies, which test the performance of association measures in a collocation extraction task.  In addition to its relevance for real-life applications, a carefully designed evaluation can reveal important properties of the association measures. Unfortunately, it is becoming clear the evaluation results cannot easily be generalised.  For this reason it is desirable to carry out more evaluation experiments under different conditions.  In order to reduce the necessary amount of manual work, evaluation can be performed on random samples from a set of candidates.  Appropriate significance tests correct for the higher degree of uncertainty.
Finally, there is a third, computational aspect to the thesis.  It is accompanied by an open-source software toolkit, which was used to perform experiments and produce graphs for the thesis.  The unique feature of this software toolkit is that the current release includes all the data, scripts and explanations needed to replicate (almost) all the results found in the book.},
	urldate = {2017-07-22},
	author = {Evert, Stefan},
	year = {2005},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\SKGP52IM\\Evert - 2005 - The statistics of word cooccurrences  word pairs .pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\EBIRMHTF\\2573.html:text/html}
}

@article{pike_latency_1968,
	title = {Latency and relative frequency of response in psychophysical discrimination},
	volume = {21},
	issn = {0007-1102},
	number = {2},
	journal = {The British Journal of Mathematical and Statistical Psychology},
	author = {Pike, A. R.},
	month = nov,
	year = {1968},
	keywords = {Discrimination (Psychology), Models, Psychological, Probability, Reaction Time, Time Factors},
	pages = {161--182}
}

@article{drugowitsch_cost_2012,
	title = {The {Cost} of {Accumulating} {Evidence} in {Perceptual} {Decision} {Making}},
	volume = {32},
	issn = {0270-6474, 1529-2401},
	abstract = {Decision making often involves the accumulation of information over time, but acquiring information typically comes at a cost. Little is known about the cost incurred by animals and humans for acquiring additional information from sensory variables due, for instance, to attentional efforts. Through a novel integration of diffusion models and dynamic programming, we were able to estimate the cost of making additional observations per unit of time from two monkeys and six humans in a reaction time (RT) random-dot motion discrimination task. Surprisingly, we find that the cost is neither zero nor constant over time, but for the animals and humans features a brief period in which it is constant but increases thereafter. In addition, we show that our theory accurately matches the observed reaction time distributions for each stimulus condition, the time-dependent choice accuracy both conditional on stimulus strength and independent of it, and choice accuracy and mean reaction times as a function of stimulus strength. The theory also correctly predicts that urgency signals in the brain should be independent of the difficulty, or stimulus strength, at each trial.},
	number = {11},
	journal = {The Journal of Neuroscience},
	author = {Drugowitsch, Jan and Moreno-Bote, Rubén and Churchland, Anne K. and Shadlen, Michael N and Pouget, Alexandre},
	month = mar,
	year = {2012},
	pages = {3612--3628},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\Q58KXMWI\\Drugowitsch et al. - 2012 - The Cost of Accumulating Evidence in Perceptual De.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\CADXQZ5X\\3612.html:text/html}
}

@article{cheng_analysis_2006,
	title = {Analysis of an {Inverse} {First} {Passage} {Problem} from {Risk} {Management}},
	volume = {38},
	issn = {0036-1410, 1095-7154},
	number = {3},
	urldate = {2013-07-08},
	journal = {SIAM Journal on Mathematical Analysis},
	author = {Cheng, L and Chen, Xinfu and Chadam, John and Saunders, David},
	year = {2006},
	pages = {845--873},
	file = {Analysis of an Inverse First Passage Problem from Risk Management \: SIAM Journal on Mathematical Analysis\: Vol. 38, No. 3 (Society for Industrial and Applied Mathematics):C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\WQ3Z97XB\\050622651.html:text/html}
}

@article{oreilly_making_2006,
	title = {Making working memory work: a computational model of learning in the prefrontal cortex and basal ganglia},
	volume = {18},
	issn = {0899-7667},
	shorttitle = {Making working memory work},
	abstract = {The prefrontal cortex has long been thought to subserve both working memory (the holding of information online for processing) and executive functions (deciding how to manipulate working memory and perform processing). Although many computational models of working memory have been developed, the mechanistic basis of executive function remains elusive, often amounting to a homunculus. This article presents an attempt to deconstruct this homunculus through powerful learning mechanisms that allow a computational model of the prefrontal cortex to control both itself and other brain areas in a strategic, task-appropriate manner. These learning mechanisms are based on subcortical structures in the midbrain, basal ganglia, and amygdala, which together form an actor-critic architecture. The critic system learns which prefrontal representations are task relevant and trains the actor, which in turn provides a dynamic gating mechanism for controlling working memory updating. Computationally, the learning mechanism is designed to simultaneously solve the temporal and structural credit assignment problems. The model's performance compares favorably with standard backpropagation-based temporal learning mechanisms on the challenging 1-2-AX working memory task and other benchmark working memory tasks.},
	number = {2},
	journal = {Neural computation},
	author = {O'Reilly, Randall C and Frank, Michael J},
	month = feb,
	year = {2006},
	pmid = {16378516},
	keywords = {Algorithms, Basal Ganglia, Memory, Models, Neurological, Neural Networks (Computer), Prefrontal Cortex},
	pages = {283--328}
}

@article{ratcliff_connectionist_1999,
	title = {Connectionist and diffusion models of reaction time},
	volume = {106},
	issn = {0033-295X},
	abstract = {Two connectionist frameworks, GRAIN (J. L. McClelland, 1993) and brain-state-in-a-box (J. A. Anderson, 1991), and R. Ratcliff's (1978) diffusion model were evaluated using data from a signal detection task. Dependent variables included response probabilities, reaction times for correct and error responses, and shapes of reaction-time distributions. The diffusion model accounted for all aspects of the data, including error reaction times that had previously been a problem for all response-time models. The connectionist models accounted for many aspects of the data adequately, but each failed to a greater or lesser degree in important ways except for one model that was similar to the diffusion model. The findings advance the development of the diffusion model and show that the long tradition of reaction-time research and theory is a fertile domain for development and testing of connectionist assumptions about how decisions are generated over time.},
	language = {eng},
	number = {2},
	journal = {Psychological Review},
	author = {Ratcliff, Roger and Van Zandt, Trisha and McKoon, Gail},
	month = apr,
	year = {1999},
	pmid = {10378014},
	keywords = {Adult, Female, Humans, Male, Models, Psychological, Reaction Time, Signal Detection, Psychological, Statistics as Topic},
	pages = {261--300}
}

@phdthesis{niv_effects_2007,
	type = {Unpublished doctoral dissertation},
	title = {The effects of motivation on habitual instrumental behavior},
	school = {The Hebrew University of Jerusalem},
	author = {Niv, Yael},
	year = {2007}
}

@article{lepora_threshold_2016,
	title = {Threshold {Learning} for {Optimal} {Decision} {Making}},
	urldate = {2017-03-28},
	journal = {Advances in Neural Information Processing Systems},
	author = {Lepora, Nathan F},
	year = {2016},
	pages = {3763--3771}
}

@article{marley_horse_1992,
	title = {The “horse race” random utility model for choice probabilities and reaction times, and its competing risks interpretation},
	volume = {36},
	issn = {0022-2496},
	number = {1},
	journal = {Journal of Mathematical Psychology},
	author = {Marley, A. A. J. and Colonius, Hans},
	month = mar,
	year = {1992},
	pages = {1--20}
}

@article{abrahamse_control_2013,
	title = {Control of automated behavior: insights from the discrete sequence production task},
	volume = {7},
	issn = {1662-5161},
	shorttitle = {Control of automated behavior},
	abstract = {Work with the discrete sequence production (DSP) task has provided a substantial literature on discrete sequencing skill over the last decades. The purpose of the current article is to provide a comprehensive overview of this literature and of the theoretical progress that it has prompted. We start with a description of the DSP task and the phenomena that are typically observed with it. Then we propose a cognitive model, the dual processor model (DPM), which explains performance of (skilled) discrete key-press sequences. Key features of this model are the distinction between a cognitive processor and a motor system (i.e., motor buffer and motor processor), the interplay between these two processing systems, and the possibility to execute familiar sequences in two different execution modes. We further discuss how this model relates to several related sequence skill research paradigms and models, and we outline outstanding questions for future research throughout the paper. We conclude by sketching a tentative neural implementation of the DPM.},
	urldate = {2013-11-05},
	journal = {Frontiers in Human Neuroscience},
	author = {Abrahamse, Elger L. and Ruitenberg, Marit F. L. and de Kleine, Elian and Verwey, Willem B.},
	month = mar,
	year = {2013},
	pmid = {23515430},
	pmcid = {PMC3601300},
	file = {PubMed Central Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\PVFHZE9E\\Abrahamse et al. - 2013 - Control of automated behavior insights from the d.pdf:application/pdf}
}

@article{busemeyer_decision_1993,
	title = {Decision field theory: a dynamic-cognitive approach to decision making in an uncertain environment},
	volume = {100},
	issn = {0033-295X},
	shorttitle = {Decision field theory},
	abstract = {Decision field theory provides for a mathematical foundation leading to a dynamic, stochastic theory of decision behavior in an uncertain environment. This theory is used to explain (a) violations of stochastic dominance, (b) violations of strong stochastic transitivity, (c) violations of independence between alternatives, (d) serial position effects on preference, (e) speed-accuracy trade-off effects in decision making, (f) the inverse relation between choice probability and decision time, (g) changes in the direction of preference under time pressure, (h) slower decision times for avoidance as compared with approach conflicts, and (i) preference reversals between choice and selling price measures of preference. The proposed theory is compared with 4 other theories of decision making under uncertainty.},
	number = {3},
	journal = {Psychological review},
	author = {Busemeyer, Jerome R and Townsend, James T},
	month = jul,
	year = {1993},
	keywords = {decision making, Female, Humans, Male, Models, Theoretical, Stochastic Processes},
	pages = {432--459}
}

@article{finn_deep_2016-1,
	title = {Deep {Visual} {Foresight} for {Planning} {Robot} {Motion}},
	url = {http://arxiv.org/abs/1610.00696},
	abstract = {A key challenge in scaling up robot learning to many skills and environments is removing the need for human supervision, so that robots can collect their own data and improve their own performance without being limited by the cost of requesting human feedback. Model-based reinforcement learning holds the promise of enabling an agent to learn to predict the effects of its actions, which could provide flexible predictive models for a wide range of tasks and environments, without detailed human supervision. We develop a method for combining deep action-conditioned video prediction models with model-predictive control that uses entirely unlabeled training data. Our approach does not require a calibrated camera, an instrumented training set-up, nor precise sensing and actuation. Our results show that our method enables a real robot to perform nonprehensile manipulation -- pushing objects -- and can handle novel objects not seen during training.},
	urldate = {2016-12-11},
	journal = {arXiv:1610.00696 [cs]},
	author = {Finn, Chelsea and Levine, Sergey},
	month = oct,
	year = {2016},
	note = {arXiv: 1610.00696},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Robotics},
	annote = {Comment: Supplementary video: https://sites.google.com/site/robotforesight/},
	file = {arXiv\:1610.00696 PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\VAWZIZ6X\\Finn and Levine - 2016 - Deep Visual Foresight for Planning Robot Motion.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\WQSW9ZCF\\1610.html:text/html}
}

@article{fuster_upper_2004,
	title = {Upper processing stages of the perception-action cycle},
	volume = {8},
	issn = {1364-6613},
	abstract = {The neural substrate for behavioral, cognitive and linguistic actions is hierarchically organized in the cortex of the frontal lobe. In their methodologically impeccable study, Koechlin et al. reveal the neural dynamics of the frontal hierarchy in behavioral action. Progressively higher areas control the performance of actions requiring the integration of progressively more complex and temporally dispersed information. The study substantiates the crucial role of the prefrontal cortex in the temporal organization of behavior.},
	language = {eng},
	number = {4},
	journal = {Trends in cognitive sciences},
	author = {Fuster, J M},
	month = apr,
	year = {2004},
	pmid = {15551481},
	keywords = {Animals, Behavior, Humans, Memory, Mental Processes, Motor Skills, Nerve Net, Perception, Prefrontal Cortex, Reaction Time},
	pages = {143--145}
}

@incollection{barto_adaptive_1995,
	address = {Cambridge, MA},
	title = {Adaptive {Critics} and the {Basal} {Ganglia}},
	abstract = {Recent years have seen a remarkable expansion of knowledge about the anatomical organization of the part of the brain known as the basal ganglia, the signal processing that occurs in these structures, and the many relations both to molecular mechanisms and to cognitive functions. This book brings together the biology and computational features of the basal ganglia and their related cortical areas along with select examples of how this knowledge can be integrated into neural network models.Organized in four parts—fundamentals, motor functions and working memories, reward mechanisms, and cognitive and memory operations—the chapters present a unique admixture of theory, cognitive psychology, anatomy, and both cellular- and systems- level physiology written by experts in each of these areas. The editors have provided commentaries as a helpful guide to each part.Many new discoveries about the biology of the basal ganglia are summarized, and their impact on the computational role of the forebrain in the planning and control of complex motor behaviors discussed. The various findings point toward an unexpected role for the basal ganglia in the contextual analysis of the environment and in the adaptive use of this information for the planning and execution of intelligent behaviors. Parallels are explored between these findings and new connectionist approaches to difficult control problems in robotics and engineering.Contributors:James L. Adams, P. Apicella, Michael Arbib, Dana H. Ballard, Andrew G. Barto, J. Brian Burns, Christopher I. Connolly, Peter F. Dominey, Richard P. Dum, John Gabrieli, M. Garcia-Munoz, Patricia S. Goldman-Rakic, Ann M. Graybiel, P. M. Groves, Mary M. Hayhoe, J. R. Hollerman, George Houghton, James C. Houk, Stephen Jackson, Minoru Kimura, A. B. Kirillov, Rolf Kotter, J. C. Linder, T. Ljungberg, M. S. Manley, M. E. Martone, J. Mirenowicz, C. D. Myre, Jeff Pelz, Nathalie Picard, R. Romo, S. F. Sawyer, E. Scarnati, Wolfram Schultz, Peter L. Strick, Charles J. Wilson, Jeff Wickens, Donald J. Woodward, S. J. Young.},
	booktitle = {Models of information processing in the basal ganglia},
	publisher = {MIT Press},
	author = {Barto, Andrew G},
	editor = {Houk, J and Davis, Joel L. and Beiser, David G.},
	year = {1995},
	keywords = {Medical / Neurology, Medical / Neuroscience, Science / General},
	pages = {215--232}
}

@article{balleine_neural_2005,
	title = {Neural bases of food-seeking: {Affect}, arousal and reward in corticostriatolimbic circuits},
	volume = {86},
	issn = {00319384},
	shorttitle = {Neural bases of food-seeking},
	url = {http://europepmc.org/abstract/MED/16257019/reload=0;jsessionid=pX0fBRna4UooFEgNMA26.22},
	number = {5},
	urldate = {2014-04-15},
	journal = {Physiology \& Behavior},
	author = {Balleine, B},
	month = dec,
	year = {2005},
	pages = {717--730},
	file = {Neural bases of food-seeking\: affect, arousal and reward in corticostriatolimbic circuits. - Abstract - Europe PubMed Central:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\QZE6GPIW\\reload=0\;jsessionid=pX0fBRna4UooFEgNMA26.html:text/html}
}

@article{doya_complementary_2000,
	title = {Complementary roles of basal ganglia and cerebellum in learning and motor control},
	volume = {10},
	issn = {0959-4388},
	abstract = {The classical notion that the basal ganglia and the cerebellum are dedicated to motor control has been challenged by the accumulation of evidence revealing their involvement in non-motor, cognitive functions. From a computational viewpoint, it has been suggested that the cerebellum, the basal ganglia, and the cerebral cortex are specialized for different types of learning: namely, supervised learning, reinforcement learning and unsupervised learning, respectively. This idea of learning-oriented specialization is helpful in understanding the complementary roles of the basal ganglia and the cerebellum in motor control and cognitive functions.},
	number = {6},
	journal = {Current opinion in neurobiology},
	author = {Doya, Kenji},
	month = dec,
	year = {2000},
	keywords = {Animals, Basal Ganglia, Cerebellum, Humans, Learning, Motor Neurons, Movement},
	pages = {732--739}
}

@article{nosofsky_attention_1986,
	title = {Attention, similarity, and the identification-categorization relationship},
	volume = {115},
	copyright = {(c) 2012 APA, all rights reserved},
	issn = {1939-2222(Electronic);0096-3445(Print)},
	abstract = {A unified quantitative approach to modeling Ss' identification and categorization of multidimensional perceptual stimuli is proposed and tested. Two Ss identified and categorized the same set of perceptually confusable stimuli varying on separable dimensions. The identification data were modeled using R. N. Shepard's (see record 1959-05134-001) multidimensional scaling-choice framework, which was then extended to model the Ss' categorization performance. The categorization model, which generalizes the context theory of classification developed by D. L. Medin and M. M. Schaffer (see record 1979-12633-001), assumes that Ss store category exemplars in memory. Classification decisions are based on the similarity of stimuli to the stored exemplars. It is assumed that the same multidimensional perceptual representation underlies performance in both the identification and categorization paradigms. However, because of the influence of selective attention, similarity relationships change systematically across the 2 paradigms. Findings provide some support for the hypothesis that Ss distribute attention among component dimensions so as to optimize categorization performance and that Ss may have augmented their category representations with inferred exemplars. Results demonstrate that excellent predictions of categorization performance can be made given knowledge of performance in an identification paradigm. (51 ref)},
	number = {1},
	journal = {Journal of Experimental Psychology: General},
	author = {Nosofsky, Robert M.},
	year = {1986},
	keywords = {*Classification (Cognitive Process), *Selective Attention, *Stimulus Similarity, Models},
	pages = {39--57}
}

@article{law_reinforcement_2009,
	title = {Reinforcement learning can account for associative and perceptual learning on a visual-decision task},
	volume = {12},
	issn = {1546-1726},
	abstract = {We recently showed that improved perceptual performance on a visual motion direction-discrimination task corresponds to changes in how an unmodified sensory representation in the brain is interpreted to form a decision that guides behavior. Here we found that these changes can be accounted for using a reinforcement-learning rule to shape functional connectivity between the sensory and decision neurons. We modeled performance on the basis of the readout of simulated responses of direction-selective sensory neurons in the middle temporal area (MT) of monkey cortex. A reward prediction error guided changes in connections between these sensory neurons and the decision process, first establishing the association between motion direction and response direction, and then gradually improving perceptual sensitivity by selectively strengthening the connections from the most sensitive neurons in the sensory population. The results suggest a common, feedback-driven mechanism for some forms of associative and perceptual learning.},
	number = {5},
	journal = {Nature neuroscience},
	author = {Law, Chi-Tat and Gold, Joshua I},
	month = may,
	year = {2009},
	keywords = {Animals, Association Learning, Computer Simulation, decision making, Feedback, Haplorhini, Models, Neurological, Motion Perception, Neural Networks (Computer), Neural Pathways, Neuropsychological Tests, Photic Stimulation, Psychomotor Performance, Reinforcement (Psychology), Reward, Visual Perception},
	pages = {655--663}
}

@article{townsend_general_2012,
	title = {General recognition theory extended to include response times: {Predictions} for a class of parallel systems},
	volume = {56},
	shorttitle = {General recognition theory extended to include response times},
	abstract = {General Recognition Theory (GRT; Ashby \&amp; Townsend, 1986) is a multidimensional theory of classification. Originally developed to study various types of perceptual independence, it has also been widely employed in diverse cognitive venues, such as categorization. The initial theory and applications have been static, that is, lacking a time variable and focusing on patterns of responses, such as confusion matrices. Ashby proposed a parallel, dynamic stochastic version of GRT with application to perceptual independence based on discrete linear systems theory with imposed noise (Ashby, 1989). The current study again focuses on cognitive/perceptual independence within an identification classification paradigm. We extend stochastic GRT and its implicated methodology for cognitive/perceptual independence, to an entire class of parallel systems. This goal is met in a distribution-free manner and includes all linear and non-linear systems satisfying very general conditions. A number of theorems are proven concerning stochastic forms of independence. However, the theorems all assume the stochastic version of decisional separability. A vital task remains to investigate the consequences of failures of stochastic decisional separability.},
	number = {6},
	urldate = {2015-03-16},
	journal = {Journal of Mathematical Psychology},
	author = {Townsend, James T and Houpt, Joseph W and Silbert, Noah H},
	month = dec,
	year = {2012},
	keywords = {Cognitive architecture, General recognition theory, Linear stochastic systems, Parallel processing, Perceptual independence, Perceptual separability, Response times},
	pages = {476--494}
}

@article{badre_frontal_2010,
	title = {Frontal cortex and the discovery of abstract action rules},
	volume = {66},
	issn = {1097-4199},
	abstract = {Although we often encounter circumstances with which we have no prior experience, we rapidly learn how to behave in these novel situations. Such adaptive behavior relies on abstract behavioral rules that are generalizable, rather than concrete rules mapping specific cues to specific responses. Although the frontal cortex is known to support concrete rule learning, less well understood are the neural mechanisms supporting the acquisition of abstract rules. Here, we use a reinforcement learning paradigm to demonstrate that more anterior regions along the rostro-caudal axis of frontal cortex support rule learning at higher levels of abstraction. Moreover, these results indicate that when humans confront new rule learning problems, this rostro-caudal division of labor supports the search for relationships between context and action at multiple levels of abstraction simultaneously.},
	language = {eng},
	number = {2},
	journal = {Neuron},
	author = {Badre, David and Kayser, Andrew S and D'Esposito, Mark},
	month = apr,
	year = {2010},
	pmid = {20435006},
	keywords = {Adolescent, Adult, Analysis of Variance, Brain Mapping, Cues, Female, Frontal Lobe, Humans, Image Processing, Computer-Assisted, Learning, Magnetic Resonance Imaging, Male, Models, Neurological, Nerve Net, Neurons, Neuropsychological Tests, Photic Stimulation, Psychomotor Performance, Reaction Time},
	pages = {315--326}
}

@article{shenoy_rational_2011,
	title = {Rational {Decision}-{Making} in {Inhibitory} {Control}},
	volume = {5},
	issn = {1662-5161},
	abstract = {An important aspect of cognitive flexibility is inhibitory control, the ability to dynamically modify or cancel planned actions in response to changes in the sensory environment or task demands. We formulate a probabilistic, rational decision-making framework for inhibitory control in the stop signal paradigm. Our model posits that subjects maintain a Bayes-optimal, continually updated representation of sensory inputs, and repeatedly assess the relative value of stopping and going on a fine temporal scale, in order to make an optimal decision on when and whether to go on each trial. We further posit that they implement this continual evaluation with respect to a global objective function capturing the various reward and penalties associated with different behavioral outcomes, such as speed and accuracy, or the relative costs of stop errors and go errors. We demonstrate that our rational decision-making model naturally gives rise to basic behavioral characteristics consistently observed for this paradigm, as well as more subtle effects due to contextual factors such as reward contingencies or motivational factors. Furthermore, we show that the classical race model can be seen as a computationally simpler, perhaps neurally plausible, approximation to optimal decision-making. This conceptual link allows us to predict how the parameters of the race model, such as the stopping latency, should change with task parameters and individual experiences/ability.},
	urldate = {2013-12-09},
	journal = {Frontiers in Human Neuroscience},
	author = {Shenoy, Pradeep and Yu, Angela J.},
	month = may,
	year = {2011}
}

@article{salamone_motivational_2002,
	title = {Motivational views of reinforcement: implications for understanding the behavioral functions of nucleus accumbens dopamine},
	volume = {137},
	issn = {0166-4328},
	shorttitle = {Motivational views of reinforcement},
	abstract = {Although the Skinnerian 'Empirical Law of Effect' does not directly consider the fundamental properties of stimuli that enable them to act as reinforcers, such considerations are critical for determining if nucleus accumbens dopamine systems mediate reinforcement processes. Researchers who have attempted to identify the critical characteristics of reinforcing stimuli or activities have generally arrived at an emphasis upon motivational factors. A thorough review of the behavioral literature indicates that, across several different investigators offering a multitude of theoretical approaches, motivation is seen by many as being fundamental to the process of reinforcement. The reinforcer has been described as a goal, a commodity, an incentive, or a stimulus that is being approached, self-administered, attained or preserved. Reinforcers also have been described as activities that are preferred, deprived or in some way being regulated. It is evident that this 'motivational' or 'regulatory' view of reinforcement has had enormous influence over the hypothesis that DA directly mediates 'reward' or 'reinforcement' processes. Indeed, proponents of the DA/reward hypothesis regularly cite motivational theorists and employ their language. Nevertheless, considerable evidence indicates that low/moderate doses of DA antagonists, and depletions of DA in nucleus accumbens, can suppress instrumental responding for food while, at the same time, these conditions leave fundamental aspects of reinforcement (i.e. primary or unconditioned reinforcement; primary motivation or primary incentive properties of natural reinforcers) intact. Several complex features of the literature on dopaminergic involvement in reinforcement are examined below, and it is argued that the assertions that DA mediates 'reward' or 'reinforcement' are inaccurate and grossly oversimplified. Thus, it appears as though it is no longer tenable to assert that drugs of abuse are simply turning on the brain's natural 'reward system'. In relation to the hypothesis that DA systems are involved in 'wanting', but not 'liking', it is suggested in the present review that 'wanting' has both directional aspects (e.g. appetite to consume food) and activational aspects (e.g. activation for initiating and sustaining instrumental actions; tendency to work for food). The present paper reviews findings in support of the hypothesis that low doses of DA antagonists and accumbens DA depletions do not impair appetite to consume food, but do impair activational aspects of motivation. This suggestion is consistent with the studies showing that low doses of DA antagonists and accumbens DA depletions alter the relative allocation of instrumental responses, making the animals less likely to engage in instrumental responses that have a high degree of work-related response costs. In addition, this observation is consistent with studies demonstrating that accumbens DA depletions make rats highly sensitive to ratio requirements on operant schedules. Although accumbens DA is not seen as directly mediating appetite to consume food, principles of behavioral economics indicate that accumbens DA could be involved in the elasticity of demand for food in terms of the tendency to pay work-related response costs. Future research must focus upon how specific aspects of task requirements (i.e. ratio requirements, intermittence of reinforcement, temporal features of response requirements, dependence upon conditioned stimuli) interact with the effects of accumbens DA depletions, and which particular factors determine sensitivity to the effects of DA antagonism or depletion.},
	number = {1-2},
	journal = {Behavioural brain research},
	author = {Salamone, John D and Correa, Mercè},
	month = dec,
	year = {2002},
	keywords = {Animals, Appetite, Conditioning, Operant, Corpus Striatum, Dopamine, Dopamine Agonists, Dopamine Antagonists, Motivation, Nucleus Accumbens, Rats, Reinforcement (Psychology)},
	pages = {3--25}
}

@article{zucca_inverse_2009,
	title = {On the {Inverse} {First}-{Passage}-{Time} {Problem} for a {Wiener} {Process}},
	volume = {19},
	issn = {1050-5164},
	abstract = {The inverse first-passage problem for a Wiener process \$(W\_\{t\})\_\{t\}{\textbackslash}geq0\$ seeks to determine a function b: \${\textbackslash}mathbb\{R\}\_\{+\} {\textbackslash}rightarrow {\textbackslash}mathbb\{R\}\$ such that \${\textbackslash}tau = inf\{t {\textgreater} 0{\textbar}W\_\{t\} {\textbackslash}geq b(t)\}\$ has a given law. In this paper two methods for approximating the unknown function b are presented. The errors of the two methods are studied. A set of examples illustrates the methods. Possible applications are enlighted.},
	number = {4},
	urldate = {2013-07-08},
	journal = {The Annals of Applied Probability},
	author = {Zucca, Cristina and Sacerdote, Laura},
	month = aug,
	year = {2009},
	pages = {1319--1346},
	file = {JSTOR Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\NE45FS6N\\Zucca and Sacerdote - 2009 - On the Inverse First-Passage-Time Problem for a Wi.pdf:application/pdf}
}

@article{song_approximation_2011,
	title = {An approximation for the inverse first passage time problem},
	volume = {43},
	issn = {0001-8678},
	abstract = {We propose an approximation for the inverse first passage time problem. It is
similar in spirit and method to the tangent approximation for the original
first passage time problem. We provide evidence that the technique is quite
accurate in many cases. We also identify some cases where the approximation
performs poorly.},
	number = {1},
	urldate = {2013-07-08},
	journal = {Advances in Applied Probability},
	author = {Song, Jing-Sheng and Zipkin, Paul},
	month = mar,
	year = {2011},
	pages = {264--275}
}

@article{jones_unfalsifiability_2014,
	title = {Unfalsifiability and mutual translatability of major modeling schemes for choice reaction time},
	volume = {121},
	issn = {1939-1471},
	abstract = {[Correction Notice: An Erratum for this article was reported in Vol 121(1) of Psychological Review (see record 2014-03591-005). The link to supplemental material was missing. All versions of this article have been corrected.] Much current research on speeded choice utilizes models in which the response is triggered by a stochastic process crossing a deterministic threshold. This article focuses on 2 such model classes, 1 based on continuous-time diffusion and the other on linear ballistic accumulation (LBA). Both models assume random variability in growth rates and in other model components across trials. We show that if the form of this variability is unconstrained, the models can exactly match any possible pattern of response probabilities and response time distributions. Thus, the explanatory or predictive content of these models is determined not by their structural assumptions but, rather, by distributional assumptions (e.g., Gaussian distributions) that are traditionally regarded as implementation details. Selective influence assumptions (i.e., which experimental manipulations affect which model parameters) are shown to have no restrictive effect, except for the theoretically questionable assumption that speed-accuracy instructions do not affect growth rates. The 2nd contribution of this article concerns translation of falsifiable models between universal modeling languages. Specifically, we translate the predictions of the diffusion and LBA models (with their parametric and selective influence assumptions intact) into the Grice modeling framework, in which accumulation processes are deterministic and thresholds are random variables. The Grice framework is also known to reproduce any possible pattern of response probabilities and times, and hence it can be used as a common language for comparing models. It is found that only a few simple properties of empirical data are necessary predictions of the diffusion and LBA models.},
	number = {1},
	journal = {Psychological Review},
	author = {Jones, Matt and Dzhafarov, Ehtibar N.},
	month = jan,
	year = {2014},
	keywords = {Choice Behavior, Data Interpretation, Statistical, decision making, Empirical Research, Humans, Models, Psychological, Models, Statistical, Probability, Reaction Time, Reproducibility of Results, Statistical Distributions, Stochastic Processes},
	pages = {1--32}
}

@article{krigolson_evidence_2006,
	title = {Evidence for hierarchical error processing in the human brain},
	volume = {137},
	issn = {0306-4522},
	abstract = {Human goal-directed behavior depends on multiple neural systems that monitor and correct for different types of errors. For example, tracking errors in continuous motor tasks appear to be processed by a system involving posterior parietal cortex, whereas errors in speeded response and trial-and-error learning tasks appear to be processed by a system involving frontal-medial cortex. To date, it is unknown whether there is a functional relationship between the posterior and frontal error systems. We recorded the event-related brain potential from participants engaged in a tracking task to investigate the role of the frontal system in continuous motor control. Our results demonstrate that tracking errors elicit temporally distinct error-related event-related brain potentials over frontal and posterior regions of the scalp, suggesting an interaction between the subcomponents of a hierarchically organized system for error processing. Specifically, we propose that the frontal error system assesses high-level errors (i.e. goal attainment) whereas the posterior error system is responsible for evaluating low-level errors (i.e. trajectory deviations during motor control).},
	language = {eng},
	number = {1},
	journal = {Neuroscience},
	author = {Krigolson, Olav E and Holroyd, Clay B},
	year = {2006},
	pmid = {16343779},
	keywords = {Adult, Brain, Brain Mapping, Evoked Potentials, Female, Humans, Male, Psychomotor Performance},
	pages = {13--17}
}

@article{badre_functional_2007,
	title = {Functional magnetic resonance imaging evidence for a hierarchical organization of the prefrontal cortex},
	volume = {19},
	issn = {0898-929X},
	abstract = {The prefrontal cortex (PFC) is central to flexible and organized action. Recent theoretical and empirical results suggest that the rostro-caudal axis of the frontal lobes may reflect a hierarchical organization of control. Here, we test whether the rostro-caudal axis of the PFC is organized hierarchically, based on the level of abstraction at which multiple representations compete to guide selection of action. Four functional magnetic resonance imaging (fMRI) experiments parametrically manipulated the set of task-relevant (a) responses, (b) features, (c) dimensions, and (d) overlapping cue-to-dimension mappings. A systematic posterior to anterior gradient was evident within the PFC depending on the manipulated level of representation. Furthermore, across four fMRI experiments, activation in PFC subregions was consistent with the sub- and superordinate relationships that define an abstract representational hierarchy. In addition to providing further support for a representational hierarchy account of the rostro-caudal gradient in the PFC, these data provide important empirical constraints on current theorizing about control hierarchies and the PFC.},
	language = {eng},
	number = {12},
	journal = {Journal of cognitive neuroscience},
	author = {Badre, David and D'Esposito, Mark},
	month = dec,
	year = {2007},
	pmid = {17892391},
	keywords = {Adolescent, Adult, Brain Mapping, Female, Humans, Image Processing, Computer-Assisted, Magnetic Resonance Imaging, Male, Mental Processes, Oxygen, Photic Stimulation, Prefrontal Cortex, Psychomotor Performance, Visual Perception},
	pages = {2082--2099}
}

@book{murphy_machine_2012,
	title = {Machine {Learning}: {A} {Probabilistic} {Perspective}},
	shorttitle = {Machine {Learning}},
	abstract = {Today's Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package -- PMTK (probabilistic modeling toolkit) -- that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students.},
	publisher = {MIT Press},
	author = {Murphy, Kevin P.},
	month = aug,
	year = {2012},
	keywords = {Computers / Intelligence (AI) \& Semantics, Computers / Machine Theory}
}

@article{dzhafarov_grice-representability_1993,
	title = {Grice-{Representability} of {Response} {Time} {Distribution} {Families}},
	volume = {58},
	issn = {0033-3123},
	abstract = {A systematic investigation of the Grice modeling scheme for response time (RT) clarifies fundamental notions about RT modeling. The analysis presented can be used to determine what in a certain RT model constitutes a set of empirically testable assumptions and what is merely an arbitrary choice of mathematical language. (SLD)},
	number = {2},
	journal = {Psychometrika},
	author = {Dzhafarov, Ehtibar N.},
	month = jan,
	year = {1993},
	keywords = {Equations (Mathematics), Evaluation Criteria, Mathematical Models, Probability, Reaction Time, Statistical Distributions, Stimuli},
	pages = {281--314},
	file = {Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\K66ZSUZW\\eric.ed.gov.html:text/html}
}

@incollection{hotaling_dynamic_2015,
	address = {Oxford},
	title = {Dynamic {Decision} {Making} {A}2  - {Wright}, {James} {D}.},
	isbn = {978-0-08-097087-5},
	abstract = {This article is a revision of the previous edition article by J.R. Busemeyer, vol 6, pp. 3903–3908, © 2001, Elsevier Ltd.
Abstract
This section reviews a specialty within the field of decision making known as dynamic decision making. Dynamic decisions are characterized by a decision maker choosing among various actions at different points in time in order to control and optimize performance of a dynamic stochastic system. Realistic examples include fighting fires, navigational control, battlefield decisions, medical emergencies, and so on. The section has four parts. The first reviews basic theory concerning optimal decision principles in a dynamic context, the second summarizes empirical approaches to the study of human performance on dynamic decision tasks, the third presents theoretical models that describe how humans learn to control dynamic systems, and the last discusses methodological issues arising from the study of complex decisions including differences between field versus laboratory research.},
	urldate = {2016-08-24},
	booktitle = {International {Encyclopedia} of the {Social} \& {Behavioral} {Sciences} ({Second} {Edition})},
	publisher = {Elsevier},
	author = {Hotaling, Jared M. and Fakhari, Pegah and Busemeyer, Jerome R.},
	year = {2015},
	keywords = {Control theory, Dynamic decision making, Dynamic systems, Learning, Problem Solving},
	pages = {708--713},
	file = {ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\U2N92ZJN\\B9780080970868430400.html:text/html}
}

@article{oud_irrational_2016,
	title = {Irrational time allocation in decision-making},
	volume = {283},
	copyright = {© 2016 The Author(s). http://royalsocietypublishing.org/licence},
	issn = {0962-8452, 1471-2954},
	abstract = {Time is an extremely valuable resource but little is known about the efficiency of time allocation in decision-making. Empirical evidence suggests that in many ecologically relevant situations, decision difficulty and the relative reward from making a correct choice, compared to an incorrect one, are inversely linked, implying that it is optimal to use relatively less time for difficult choice problems. This applies, in particular, to value-based choices, in which the relative reward from choosing the higher valued item shrinks as the values of the other options get closer to the best option and are thus more difficult to discriminate. Here, we experimentally show that people behave sub-optimally in such contexts. They do not respond to incentives that favour the allocation of time to choice problems in which the relative reward for choosing the best option is high; instead they spend too much time on problems in which the reward difference between the options is low. We demonstrate this by showing that it is possible to improve subjects' time allocation with a simple intervention that cuts them off when their decisions take too long. Thus, we provide a novel form of evidence that organisms systematically spend their valuable time in an inefficient way, and simultaneously offer a potential solution to the problem.},
	number = {1822},
	urldate = {2016-02-16},
	journal = {Proc. R. Soc. B},
	author = {Oud, Bastiaan and Krajbich, Ian and Miller, Kevin and Cheong, Jin Hyun and Botvinick, Matthew and Fehr, Ernst},
	month = jan,
	year = {2016},
	pages = {20151439},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\NFRCF634\\Oud et al. - 2016 - Irrational time allocation in decision-making.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\Z7B5PKHQ\\Oud et al. - 2016 - Irrational time allocation in decision-making.html:text/html}
}

@article{schmajuk_purposive_1992,
	title = {Purposive behavior and cognitive mapping: a neural network model},
	volume = {67},
	issn = {0340-1200, 1432-0770},
	shorttitle = {Purposive behavior and cognitive mapping},
	url = {http://europepmc.org/abstract/MED/1627685},
	number = {2},
	urldate = {2014-04-15},
	journal = {Biological Cybernetics},
	author = {Schmajuk, N. A. and Thieme, A. D.},
	month = jun,
	year = {1992},
	pages = {165--174},
	file = {Purposive behavior and cognitive mapping\: a neural network model. - Abstract - Europe PubMed Central:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\RNDXIHF7\\1627685.html:text/html}
}

@book{aggarwal_recommender_2016,
	title = {Recommender {Systems}: {The} {Textbook}},
	shorttitle = {Recommender {Systems}},
	abstract = {This book comprehensively covers the topic of recommender systems, which provide personalized recommendations of products or services to users based on their previous searches or purchases. Recommender system methods have been adapted to diverse applications including query log mining, social networking, news recommendations, and computational advertising. This book synthesizes both fundamental and advanced topics of a research area that has now reached maturity.  The chapters of this book  are organized into three categories: - Algorithms and evaluation:  These chapters discuss the fundamental algorithms in recommender systems, including collaborative filtering methods, content-based methods, knowledge-based methods, ensemble-based methods, and evaluation. - Recommendations in specific domains and contexts: the context of a recommendation can be viewed as important side information that affects the recommendation goals. Different types of context such as temporal data, spatial data, social data, tagging data, and trustworthiness are explored. - Advanced topics and applications:  Various robustness aspects of recommender systems, such as shilling systems, attack models, and their defenses are discussed. In addition, recent topics, such as learning to rank, multi-armed bandits, group systems, multi-criteria systems, and active learning systems, are introduced together with applications. Although this book primarily serves as a textbook, it will also appeal to industrial practitioners and researchers due to its focus on applications and references. Numerous examples and exercises have been provided, and a solution manual is available for instructors.},
	publisher = {Springer},
	author = {Aggarwal, Charu C.},
	month = mar,
	year = {2016},
	keywords = {Computers / Databases / Data Mining, Computers / Information Technology, Computers / Intelligence (AI) \& Semantics}
}

@article{palmer_effect_2005,
	title = {The effect of stimulus strength on the speed and accuracy of a perceptual decision},
	volume = {5},
	abstract = {Both the speed and the accuracy of a perceptual judgment depend on the strength of the sensory stimulation. When stimulus strength is high, accuracy is high and response time is fast; when stimulus strength is low, accuracy is low and response time is slow. Although the psychometric function is well established as a tool for analyzing the relationship between accuracy and stimulus strength, the corresponding chronometric function for the relationship between response time and stimulus strength has not received as much consideration. In this article, we describe a theory of perceptual decision making based on a diffusion model. In it, a decision is based on the additive accumulation of sensory evidence over time to a bound. Combined with simple scaling assumptions, the proportional-rate and power-rate diffusion models predict simple analytic expressions for both the chronometric and psychometric functions. In a series of psychophysical experiments, we show that this theory accounts for response time and accuracy as a function of both stimulus strength and speed-accuracy instructions. In particular, the results demonstrate a close coupling between response time and accuracy. The theory is also shown to subsume the predictions of Piéron’s Law, a power function dependence of response time on stimulus strength. The theory’s analytic chronometric function allows one to extend theories of accuracy to response time.},
	number = {5},
	urldate = {2014-01-19},
	journal = {Journal of Vision},
	author = {Palmer, John and Huk, Alexander C. and Shadlen, Michael N},
	month = may,
	year = {2005},
	keywords = {Decision, psychometric function, response time, speed-accuracy tradeoff, temporal summation},
	pages = {1}
}

@book{luce_response_1986,
	title = {Response {Times}: {Their} {Role} in {Inferring} {Elementary} {Mental} {Organization}},
	isbn = {978-0-19-536146-9},
	shorttitle = {Response {Times}},
	publisher = {Oxford University Press},
	author = {Luce, Robert Duncan},
	year = {1986}
}

@article{tolman_insight_1930,
	title = {Insight in rats},
	volume = {4},
	copyright = {(c) 2012 APA, all rights reserved},
	abstract = {A repetition, under somewhat different conditions and with a larger group of animals, of an earlier experiment by Hsiao, who found that 3 rats were capable of grasping "a material, inner relation of two things to each other." The present authors conducted 3 separate experiments with 3 different mazes. In the first experiment, the maze used was very similar to that previously used by Hsiao. However, no evidence of "insight" was obtained. Failure to verify the earlier findings was probably due to the fact that the amount and distribution of preliminary training was different in the two cases. Results from the second experiment were also negative. In the third experiment, "insight," in the sense in which the authors use the term, was definitely proved. "To explain the fact that no insight was obtained in Maze II although it was obtained in Maze III which had an identical ground pattern, it would seem important that Maze III had no side walls as did Maze II and hence the rats were able in Maze III to 'see' the situation as a whole. Or, even if the rats in Maze III were not able to 'see' all the paths at any one moment, they might still have been better able to grasp the connections between the paths, owing perhaps to the open space on all sides of the runways, which may have served to accentuate the relations between the paths."},
	journal = {University of California Publications in Psychology},
	author = {Tolman, Edward Chace and Honzik, C H},
	year = {1930},
	pages = {215--232},
	file = {APA PsycNET Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\M6CG3F98\\1933-01837-001.html:text/html}
}

@article{frank_hold_2006,
	title = {Hold your horses: a dynamic computational role for the subthalamic nucleus in decision making},
	volume = {19},
	issn = {0893-6080},
	shorttitle = {Hold your horses},
	abstract = {The basal ganglia (BG) coordinate decision making processes by facilitating adaptive frontal motor commands while suppressing others. In previous work, neural network simulations accounted for response selection deficits associated with BG dopamine depletion in Parkinson's disease. Novel predictions from this model have been subsequently confirmed in Parkinson patients and in healthy participants under pharmacological challenge. Nevertheless, one clear limitation of that model is in its omission of the subthalamic nucleus (STN), a key BG structure that participates in both motor and cognitive processes. The present model incorporates the STN and shows that by modulating when a response is executed, the STN reduces premature responding and therefore has substantial effects on which response is ultimately selected, particularly when there are multiple competing responses. Increased cortical response conflict leads to dynamic adjustments in response thresholds via cortico-subthalamic-pallidal pathways. The model accurately captures the dynamics of activity in various BG areas during response selection. Simulated dopamine depletion results in emergent oscillatory activity in BG structures, which has been linked with Parkinson's tremor. Finally, the model accounts for the beneficial effects of STN lesions on these oscillations, but suggests that this benefit may come at the expense of impaired decision making.},
	number = {8},
	journal = {Neural networks: the official journal of the International Neural Network Society},
	author = {Frank, Michael J},
	month = oct,
	year = {2006},
	keywords = {Action Potentials, Animals, Basal Ganglia, Biological Clocks, Computer Simulation, decision making, Humans, Neural Networks (Computer), Neural Pathways, Neurons, Nonlinear Dynamics, Reaction Time, Subthalamic Nucleus},
	pages = {1120--1136}
}

@article{diederich_simple_2003,
	title = {Simple matrix methods for analyzing diffusion models of choice probability, choice response time, and simple response time},
	volume = {47},
	issn = {0022-2496},
	abstract = {Diffusion processes (e.g., Wiener process, Ornstein–Uhlenbeck process) are powerful approaches to model human information processes in a variety of psychological tasks. Lack of mathematical tractability, however, has prevented broad applications of these models to empirical data. This tutorial explains step by step, using a matrix approach, how to construct these models, how to implement them on a computer, and how to calculate the predictions made by these models. In particular, we present models for binaries choices for unidimensional and multiattribute choice alternatives; for simple reaction time tasks; and for three alternatives choice problems.},
	number = {3},
	urldate = {2014-12-07},
	journal = {Journal of Mathematical Psychology},
	author = {Diederich, Adele and Busemeyer, Jerome R},
	month = jun,
	year = {2003},
	keywords = {Diffusion models, Markov Chains, Ornstein–Uhlenbeck process, Wiener process},
	pages = {304--322},
	file = {ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\W2ERQVNR\\S0022249603000038.html:text/html}
}

@article{collins_cognitive_2013,
	title = {Cognitive control over learning: creating, clustering, and generalizing task-set structure},
	volume = {120},
	issn = {1939-1471},
	shorttitle = {Cognitive control over learning},
	abstract = {Learning and executive functions such as task-switching share common neural substrates, notably prefrontal cortex and basal ganglia. Understanding how they interact requires studying how cognitive control facilitates learning but also how learning provides the (potentially hidden) structure, such as abstract rules or task-sets, needed for cognitive control. We investigate this question from 3 complementary angles. First, we develop a new context-task-set (C-TS) model, inspired by nonparametric Bayesian methods, specifying how the learner might infer hidden structure (hierarchical rules) and decide to reuse or create new structure in novel situations. Second, we develop a neurobiologically explicit network model to assess mechanisms of such structured learning in hierarchical frontal cortex and basal ganglia circuits. We systematically explore the link between these modeling levels across task demands. We find that the network provides an approximate implementation of high-level C-TS computations, with specific neural mechanisms modulating distinct C-TS parameters. Third, this synergism yields predictions about the nature of human optimal and suboptimal choices and response times during learning and task-switching. In particular, the models suggest that participants spontaneously build task-set structure into a learning problem when not cued to do so, which predicts positive and negative transfer in subsequent generalization tests. We provide experimental evidence for these predictions and show that C-TS provides a good quantitative fit to human sequences of choices. These findings implicate a strong tendency to interactively engage cognitive control and learning, resulting in structured abstract representations that afford generalization opportunities and, thus, potentially long-term rather than short-term optimality.},
	number = {1},
	journal = {Psychological review},
	author = {Collins, Anne G E and Frank, Michael J},
	month = jan,
	year = {2013},
	pmid = {23356780},
	pages = {190--229}
}

@article{khodadadi_mimicry_2015,
	title = {On mimicry among sequential sampling models},
	volume = {68–69},
	issn = {0022-2496},
	abstract = {Sequential sampling models are widely used in modeling the empirical data obtained from different decision making experiments. Since 1960s, several instantiations of these models have been proposed. A common assumption among these models is that the subject accumulates noisy information during the time course of a decision. The decision is made when the accumulated information favoring one of the responses reaches a decision boundary. Different models, however, make different assumptions about the information accumulation process and the implementation of the decision boundaries. Comparison among these models has proven to be challenging. In this paper we investigate the relationship between several of these models using a theoretical framework called the inverse first passage time problem. This framework has been used in the literature of applied probability theory in investigating the range of the first passage time distributions that can be produced by a stochastic process. In this paper, we use this framework to prove that any Wiener process model with two time-constant boundaries can be mimicked by an independent race model with time-varying boundaries. We also examine the numerical computation of the mimicking boundaries. We show that the mimicking boundaries of the race model are not symmetric. We then propose an equivalent race model in which the boundaries are symmetric and time-constant but the drift coefficients are time-varying.},
	urldate = {2016-02-24},
	journal = {Journal of Mathematical Psychology},
	author = {Khodadadi, Arash and Townsend, James T.},
	month = oct,
	year = {2015},
	keywords = {Independent race model, Inverse first passage time problem, Model mimicry, Sequential sampling models, Wiener process},
	pages = {37--48},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\NQQ2DCMK\\Khodadadi and Townsend - 2015 - On mimicry among sequential sampling models.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\ACFZ3DZA\\Khodadadi and Townsend - 2015 - On mimicry among sequential sampling models.html:text/html}
}

@phdthesis{valov_first_2009,
	title = {First {Passage} {Times}: {Integral} {Equations}, {Randomization} and {Analytical} {Approximations}},
	school = {University of Toronto},
	author = {Valov, A V},
	year = {2009}
}

@article{krigolson_hierarchical_2007,
	title = {Hierarchical error processing: different errors, different systems},
	volume = {1155},
	issn = {0006-8993},
	shorttitle = {Hierarchical error processing},
	abstract = {Error processing during motor control involves the evaluation of "high-level" errors (i.e., failures to meet a system goal) by a frontal system involving anterior cingulate cortex and the evaluation of "low-level" errors (i.e., discrepancies between actual and desired motor commands) by a posterior system involving posterior parietal cortex. We have recently demonstrated that high-level errors committed within the context of a continuous tracking task elicited an error-related negativity (ERN) -- a component of the event-related brain potential (ERP) generated within medial-frontal cortex that is sensitive to error commission. The purpose of the present study was to demonstrate that low-level motor errors do not elicit an ERN, but may instead evoke other ERP components associated with visual processing and online motor control. Participants performed a computer aiming task in which they manipulated a joystick to move a cursor from a start to a target position. On a random subset of trials the target jumped to a new position at movement onset, requiring the participants to modify their current motor command. Further, on one half of these "target perturbation" trials the cursor did not respond to corrective movements of the joystick. Consistent with our previous findings, we found that the uncorrectable errors elicited an ERN. We also found that the target perturbations on both correctable and uncorrectable trials did not elicit an ERN, but rather evoked two other ERP components, the N100 and P300. These results suggest that medial-frontal cortex is insensitive to low-level motor errors, and are in line with a recent theory that holds that the P300 reflects stimulus-response optimization by the impact of locus coeruleus activity on posterior cortex.},
	language = {eng},
	journal = {Brain research},
	author = {Krigolson, Olav E and Holroyd, Clay B},
	month = jun,
	year = {2007},
	pmid = {17498670},
	keywords = {Brain, Brain Mapping, Electrophysiology, Evoked Potentials, Humans, Motor Activity, Reaction Time, Reproducibility of Results, Space Perception, Time Factors},
	pages = {70--80}
}

@article{dayan_decision_2008,
	title = {Decision theory, reinforcement learning, and the brain},
	volume = {8},
	issn = {1530-7026},
	abstract = {Decision making is a core competence for animals and humans acting and surviving in environments they only partially comprehend, gaining rewards and punishments for their troubles. Decision-theoretic concepts permeate experiments and computational models in ethology, psychology, and neuroscience. Here, we review a well-known, coherent Bayesian approach to decision making, showing how it unifies issues in Markovian decision problems, signal detection psychophysics, sequential sampling, and optimal exploration and discuss paradigmatic psychological and neural examples of each problem. We discuss computational issues concerning what subjects know about their task and how ambitious they are in seeking optimal solutions; we address algorithmic topics concerning model-based and model-free methods for making choices; and we highlight key aspects of the neural implementation of decision making.},
	number = {4},
	journal = {Cognitive, affective \& behavioral neuroscience},
	author = {Dayan, Peter and Daw, Nathaniel D},
	month = dec,
	year = {2008},
	keywords = {Algorithms, Animals, Bayes Theorem, Brain, Cognition, Cost-Benefit Analysis, decision making, Decision Theory, Exploratory Behavior, Humans, Markov Chains, Models, Psychological, Models, Statistical, Problem Solving, Reinforcement (Psychology), Signal Detection, Psychological, Uncertainty},
	pages = {429--453}
}

@article{daw_model-based_2011,
	title = {Model-based influences on humans' choices and striatal prediction errors},
	volume = {69},
	issn = {1097-4199},
	abstract = {The mesostriatal dopamine system is prominently implicated in model-free reinforcement learning, with fMRI BOLD signals in ventral striatum notably covarying with model-free prediction errors. However, latent learning and devaluation studies show that behavior also shows hallmarks of model-based planning, and the interaction between model-based and model-free values, prediction errors, and preferences is underexplored. We designed a multistep decision task in which model-based and model-free influences on human choice behavior could be distinguished. By showing that choices reflected both influences we could then test the purity of the ventral striatal BOLD signal as a model-free report. Contrary to expectations, the signal reflected both model-free and model-based predictions in proportions matching those that best explained choice behavior. These results challenge the notion of a separate model-free learner and suggest a more integrated computational architecture for high-level human decision-making.},
	number = {6},
	journal = {Neuron},
	author = {Daw, Nathaniel D. and Gershman, Samuel J. and Seymour, Ben and Dayan, Peter and Dolan, Raymond J.},
	month = mar,
	year = {2011},
	keywords = {Adult, Basal Ganglia, Brain Mapping, Choice Behavior, Dopamine, Female, Humans, Logistic Models, Magnetic Resonance Imaging, Male, Models, Neurological, Neurons, Neuropsychological Tests, Reinforcement (Psychology)},
	pages = {1204--1215}
}

@article{smith_poisson_2010,
	title = {From {Poisson} shot noise to the integrated {Ornstein}–{Uhlenbeck} process: {Neurally} principled models of information accumulation in decision-making and response time},
	volume = {54},
	issn = {0022-2496},
	abstract = {In the diffusion model of decision-making, evidence is accumulated by a Wiener diffusion process. A neurally motivated account of diffusive evidence accumulation is given, in which diffusive accumulation arises from an interaction between neural integration processes operating on short and long time scales. The short time scale process is modeled as a Poisson shot noise process with exponential decay. Stimulus information is coded by excitatory–inhibitory shot noise pairs. The long time scale process is modeled as algebraic integration, possibly implemented as a first-order autoregressive process realized by recurrent connections within a population of neurons. At high intensities, an excitatory–inhibitory shot noise pair converges weakly to an Ornstein–Uhlenbeck (OU) velocity process. The integrated OU process, or OU displacement process, obtained by integrating the velocity process over time, is indistinguishable at long times from the Wiener process. Diffusive information accumulation may therefore be characterized as an integrated OU process whose properties mimic those of the Wiener process.},
	number = {2},
	urldate = {2014-12-09},
	journal = {Journal of Mathematical Psychology},
	author = {Smith, Philip L.},
	month = apr,
	year = {2010},
	keywords = {accumulator model, Decision-making, diffusion process, Ornstein–Uhlenbeck process, response time, Shot noise},
	pages = {266--283},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\FQWAESCX\\Smith - 2010 - From Poisson shot noise to the integrated Ornstein.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\WV7X4FN5\\S0022249609001576.html:text/html}
}

@article{mullen_deoptim:_2011,
	title = {{DEoptim}: {An} {R} {Package} for {Global} {Optimization} by {Differential} {Evolution}},
	volume = {40},
	shorttitle = {{DEoptim}},
	abstract = {This article describes the R package DEoptim, which implements the Differential Evolution algorithm for global optimization of a real-valued function of a real-valued parameter vector. The implementation of Differential Evolution in DEoptim interfaces with C code for efficiency. The utility of the package is illustrated by case studies in fitting a Parratt model for X-ray reflectometry data and a Markov-Switching Generalized AutoRegressive Conditional Heteroskedasticity  model for the returns of the Swiss Market Index.},
	number = {6},
	urldate = {2016-06-16},
	journal = {Journal of Statistical Software},
	author = {Mullen, Katharine and Ardia, David and Gil, David L. and Windover, Donald and Cline, James},
	year = {2011},
	keywords = {differential evolution, evolutionary algorithm, global optimization, R software},
	pages = {1--26},
	file = {Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\7IVD8XWD\\papers.html:text/html}
}

@article{rapoport_models_1971,
	title = {Models for deferred decision making},
	volume = {8},
	issn = {0022-2496},
	abstract = {Deferred decision theory assumes two simple hypotheses, observations that are purchased sequentially, losses for incorrect terminal decisions, and a constant loss per observation which may depend on the true hypothesis. After every observation, the decision maker may either make a terminal decision and incur a terminal loss if he is incorrect or purchase another observation; his objective is to minimize subjectively expected loss.

The optimal decision policy is presented and numerical results are given for Gaussian and exponential stimulus models. The theory is extended to the case where loss per observation varies from one trial to another. Predictions regarding statistics obtained from data are derived, effects of discrepancies from the optimal decision policy are examined, and descriptive models are proposed and compared to the normative model.},
	number = {4},
	urldate = {2016-08-13},
	journal = {Journal of Mathematical Psychology},
	author = {Rapoport, Amnon and Burkheimer, Graham J.},
	month = nov,
	year = {1971},
	pages = {508--538},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\GV5DFTRS\\Rapoport and Burkheimer - 1971 - Models for deferred decision making.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\SR2MA38T\\0022249671900058.html:text/html}
}

@article{ivanoff_fmri_2008,
	title = {{fMRI} {Evidence} for a {Dual} {Process} {Account} of the {Speed}-{Accuracy} {Tradeoff} in {Decision}-{Making}},
	volume = {3},
	abstract = {BackgroundThe speed and accuracy of decision-making have a well-known trading relationship: hasty decisions are more prone to errors while careful, accurate judgments take more time. Despite the pervasiveness of this speed-accuracy trade-off (SAT) in decision-making, its neural basis is still unknown.Methodology/Principal FindingsUsing functional magnetic resonance imaging (fMRI) we show that emphasizing the speed of a perceptual decision at the expense of its accuracy lowers the amount of evidence-related activity in lateral prefrontal cortex. Moreover, this speed-accuracy difference in lateral prefrontal cortex activity correlates with the speed-accuracy difference in the decision criterion metric of signal detection theory. We also show that the same instructions increase baseline activity in a dorso-medial cortical area involved in the internal generation of actions.Conclusions/SignificanceThese findings suggest that the SAT is neurally implemented by modulating not only the amount of externally-derived sensory evidence used to make a decision, but also the internal urge to make a response. We propose that these processes combine to control the temporal dynamics of the speed-accuracy trade-off in decision-making.},
	number = {7},
	urldate = {2014-01-19},
	journal = {PLoS ONE},
	author = {Ivanoff, Jason and Branning, Philip and Marois, René},
	month = jul,
	year = {2008},
	pages = {e2635}
}

@article{ratcliff_reinforcement-based_2012,
	title = {Reinforcement-based decision making in corticostriatal circuits: mutual constraints by neurocomputational and diffusion models},
	volume = {24},
	issn = {1530-888X},
	shorttitle = {Reinforcement-based decision making in corticostriatal circuits},
	abstract = {In this letter, we examine the computational mechanisms of reinforce-ment-based decision making. We bridge the gap across multiple levels of analysis, from neural models of corticostriatal circuits-the basal ganglia (BG) model (Frank, 2005 , 2006 ) to simpler but mathematically tractable diffusion models of two-choice decision making. Specifically, we generated simulated data from the BG model and fit the diffusion model (Ratcliff, 1978 ) to it. The standard diffusion model fits underestimated response times under conditions of high response and reinforcement conflict. Follow-up fits showed good fits to the data both by increasing nondecision time and by raising decision thresholds as a function of conflict and by allowing this threshold to collapse with time. This profile captures the role and dynamics of the subthalamic nucleus in BG circuitry, and as such, parametric modulations of projection strengths from this nucleus were associated with parametric increases in decision boundary and its modulation by conflict. We then present data from a human reinforcement learning experiment involving decisions with low- and high-reinforcement conflict. Again, the standard model failed to fit the data, but we found that two variants similar to those that fit the BG model data fit the experimental data, thereby providing a convergence of theoretical accounts of complex interactive decision-making mechanisms consistent with available data. This work also demonstrates how to make modest modifications to diffusion models to summarize core computations of the BG model. The result is a better fit and understanding of reinforcement-based choice data than that which would have occurred with either model alone.},
	number = {5},
	journal = {Neural computation},
	author = {Ratcliff, Roger and Frank, Michael J},
	month = may,
	year = {2012},
	keywords = {Basal Ganglia, Computer Simulation, decision making, Feedback, Humans, Learning, Models, Neurological, Neural Networks (Computer), Reinforcement (Psychology), Subthalamic Nucleus},
	pages = {1186--1229}
}

@article{wahlstrom_learning_2014-1,
	title = {Learning deep dynamical models from image pixels},
	url = {http://arxiv.org/abs/1410.7550},
	abstract = {Modeling dynamical systems is important in many disciplines, e.g., control, robotics, or neurotechnology. Commonly the state of these systems is not directly observed, but only available through noisy and potentially high-dimensional observations. In these cases, system identification, i.e., finding the measurement mapping and the transition mapping (system dynamics) in latent space can be challenging. For linear system dynamics and measurement mappings efficient solutions for system identification are available. However, in practical applications, the linearity assumptions does not hold, requiring non-linear system identification techniques. If additionally the observations are high-dimensional (e.g., images), non-linear system identification is inherently hard. To address the problem of non-linear system identification from high-dimensional observations, we combine recent advances in deep learning and system identification. In particular, we jointly learn a low-dimensional embedding of the observation by means of deep auto-encoders and a predictive transition model in this low-dimensional space. We demonstrate that our model enables learning good predictive models of dynamical systems from pixel information only.},
	urldate = {2016-12-12},
	journal = {arXiv:1410.7550 [cs, stat]},
	author = {Wahlström, Niklas and Schön, Thomas B. and Deisenroth, Marc Peter},
	month = oct,
	year = {2014},
	note = {arXiv: 1410.7550},
	keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Systems and Control, Statistics - Machine Learning},
	annote = {Comment: 10 pages, 11 figures}
}

@article{smith_stochastic_2000,
	title = {Stochastic {Dynamic} {Models} of {Response} {Time} and {Accuracy}: {A} {Foundational} {Primer}},
	volume = {44},
	issn = {0022-2496},
	shorttitle = {Stochastic {Dynamic} {Models} of {Response} {Time} and {Accuracy}},
	abstract = {A large class of statistical decision models for performance in simple information processing tasks can be described by linear, first-order, stochastic differential equations (SDEs), whose solutions are diffusion processes. In such models, the first passage time for the diffusion process through a response criterion determines the time at which an observer makes a decision about the identity of a stimulus. Because the assumptions of many cognitive models lead to SDEs that are time inhomogeneous, classical methods for solving such first passage time problems are usually inapplicable. In contrast, recent integral equation methods often yield solutions to both the one-sided and the two-sided first passage time problems, even in the presence of time inhomogeneity. These methods, which are of particular relevance to the cognitive modeler, are described in detail, together with illustrative applications. Copyright 2000 Academic Press.},
	number = {3},
	journal = {Journal of mathematical psychology},
	author = {Smith, Philip L.},
	month = sep,
	year = {2000},
	pages = {408--463}
}

@article{gullapalli_stochastic_1990,
	title = {A stochastic reinforcement learning algorithm for learning real-valued functions},
	volume = {3},
	number = {6},
	journal = {Neural networks},
	author = {Gullapalli, V},
	year = {1990},
	pages = {671--692}
}

@article{gold_banburismus_2002,
	title = {Banburismus and the {Brain}: {Decoding} the {Relationship} between {Sensory} {Stimuli}, {Decisions}, and {Reward}},
	volume = {36},
	issn = {0896-6273},
	shorttitle = {Banburismus and the {Brain}},
	abstract = {This article relates a theoretical framework developed by British codebreakers in World War II to the neural computations thought to be responsible for forming categorical decisions about sensory stimuli. In both, a weight of evidence is computed and accumulated to support or oppose the alternative interpretations. A decision is reached when the evidence reaches a threshold value. In the codebreaking scheme, the threshold determined the speed and accuracy of the decision process. Here we propose that in the brain, the threshold may be controlled by neural circuits that calculate the rate of reward.},
	number = {2},
	urldate = {2013-12-03},
	journal = {Neuron},
	author = {Gold, Joshua I. and Shadlen, Michael N},
	month = oct,
	year = {2002},
	pages = {299--308}
}

@article{khodadadi_learning_2016,
	title = {Learning to {Allocate} {Limited} {Time} to {Decisions} with {Different} {Expected} {Outcomes}},
	url = {http://arxiv.org/abs/1607.05334},
	urldate = {2016-07-31},
	journal = {arXiv preprint arXiv:1607.05334},
	author = {Khodadadi, Arash and Fakhari, Pegah and Busemeyer, Jerome R.},
	year = {2016},
	file = {[PDF] from arxiv.org:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\HGEG2WJ6\\Khodadadi et al. - 2016 - Learning to Allocate Limited Time to Decisions wit.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\DTIXHZ7V\\1607.html:text/html}
}

@article{simen_rapid_2006,
	title = {Rapid decision threshold modulation by reward rate in a neural network},
	volume = {19},
	issn = {0893-6080},
	abstract = {Optimal performance in two-alternative, free response decision-making tasks can be achieved by the drift-diffusion model of decision making--which can be implemented in a neural network--as long as the threshold parameter of that model can be adapted to different task conditions. Evidence exists that people seek to maximize reward in such tasks by modulating response thresholds. However, few models have been proposed for threshold adaptation, and none have been implemented using neurally plausible mechanisms. Here we propose a neural network that adapts thresholds in order to maximize reward rate. The model makes predictions regarding optimal performance and provides a benchmark against which actual performance can be compared, as well as testable predictions about the way in which reward rate may be encoded by neural mechanisms.},
	number = {8},
	journal = {Neural networks: the official journal of the International Neural Network Society},
	author = {Simen, Patrick and Cohen, Jonathan D and Holmes, Philip},
	month = oct,
	year = {2006},
	keywords = {Algorithms, Animals, Computer Simulation, decision making, Differential Threshold, Discrimination (Psychology), Humans, Models, Psychological, Nerve Net, Neural Networks (Computer), Reaction Time, Reward},
	pages = {1013--1026}
}

@book{ljung_system_1998,
	title = {System {Identification}: {Theory} for the {User}},
	shorttitle = {System {Identification}},
	abstract = {The field's leading text, now completely updated.   Modeling dynamical systems — theory, methodology, and applications.   Lennart Ljung's System Identification: Theory for the User is a complete, coherent description of the theory, methodology, and practice of System Identification. This completely revised Second Edition introduces subspace methods, methods that utilize frequency domain data, and general non-linear black box methods, including neural networks and neuro-fuzzy modeling. The book contains many new computer-based examples designed for Ljung's market-leading software, System Identification Toolbox for MATLAB.   Ljung combines careful mathematics, a practical understanding of real-world applications, and extensive exercises. He introduces both black-box and tailor-made models of linear as well as non-linear systems, and he describes principles, properties, and algorithms for a variety of identification techniques:    Nonparametric time-domain and frequency-domain methods.   Parameter estimation methods in a general prediction error setting.   Frequency domain data and frequency domain interpretations.   Asymptotic analysis of parameter estimates.   Linear regressions, iterative search methods, and other ways to compute estimates.   Recursive (adaptive) estimation techniques.    Ljung also presents detailed coverage of the key issues that can make or break system identification projects, such as defining objectives, designing experiments, controlling the bias distribution of transfer-function estimates, and carefully validating the resulting models.  The first edition of System Identification has been the field's most widely cited reference for over a decade. This new edition will be the new text of choice for anyone concerned with system identification theory and practice.},
	publisher = {Pearson Education},
	author = {Ljung, Lennart},
	month = dec,
	year = {1998},
	note = {Google-Books-ID: fYSrk4wDKPsC},
	keywords = {Technology \& Engineering / Electrical}
}

@article{barkan_item2vec:_2016,
	title = {Item2Vec: {Neural} {Item} {Embedding} for {Collaborative} {Filtering}},
	shorttitle = {Item2Vec},
	url = {http://arxiv.org/abs/1603.04259},
	abstract = {Many Collaborative Filtering (CF) algorithms are item-based in the sense that they analyze item-item relations in order to produce item similarities. Recently, several works in the field of Natural Language Processing (NLP) suggested to learn a latent representation of words using neural embedding algorithms. Among them, the Skip-gram with Negative Sampling (SGNS), also known as word2vec, was shown to provide state-of-the-art results on various linguistics tasks. In this paper, we show that item-based CF can be cast in the same framework of neural word embedding. Inspired by SGNS, we describe a method we name item2vec for item-based CF that produces embedding for items in a latent space. The method is capable of inferring item-item relations even when user information is not available. We present experimental results that demonstrate the effectiveness of the item2vec method and show it is competitive with SVD.},
	journal = {arXiv:1603.04259 [cs]},
	author = {Barkan, Oren and Koenigstein, Noam},
	month = mar,
	year = {2016},
	note = {arXiv: 1603.04259},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Information Retrieval, Computer Science - Learning},
	file = {arXiv\:1603.04259 PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\8GT8N9KD\\Barkan and Koenigstein - 2016 - Item2Vec Neural Item Embedding for Collaborative .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\JKJ28H2P\\1603.html:text/html}
}

@article{friedman_sparse_2008,
	title = {Sparse inverse covariance estimation with the graphical lasso},
	volume = {9},
	url = {https://academic.oup.com/biostatistics/article/9/3/432/224260/Sparse-inverse-covariance-estimation-with-the},
	abstract = {We consider the problem of estimating sparse graphs by a lasso penalty applied to the inverse covariance matrix. Using a coordinate descent procedure for the lasso, we develop a simple algorithm—the graphical lasso—that is remarkably fast: It solves a 1000-node problem (∼500000 parameters) in at most a minute and is 30–4000 times faster than competing methods. It also provides a conceptual link between the exact problem and the approximation suggested by Meinshausen and Bühlmann (2006). We illustrate the method on some cell-signaling data from proteomics.},
	number = {3},
	urldate = {2017-09-08},
	journal = {Biostatistics},
	author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
	month = jul,
	year = {2008},
	pages = {432--441},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\8BJBUGK3\\Friedman et al. - 2008 - Sparse inverse covariance estimation with the grap.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\52WXZ8KC\\Sparse-inverse-covariance-estimation-with-the.html:text/html}
}

@article{brown_simplest_2008,
	title = {The simplest complete model of choice response time: linear ballistic accumulation},
	volume = {57},
	issn = {1095-5623},
	abstract = {We propose a linear ballistic accumulator (LBA) model of decision making and reaction time. The LBA is simpler than other models of choice response time, with independent accumulators that race towards a common response threshold. Activity in the accumulators increases in a linear and deterministic manner. The simplicity of the model allows complete analytic solutions for choices between any number of alternatives. These solutions (and freely-available computer code) make the model easy to apply to both binary and multiple choice situations. Using data from five previously published experiments, we demonstrate that the LBA model successfully accommodates empirical phenomena from binary and multiple choice tasks that have proven difficult for other theoretical accounts. Our results are encouraging in a field beset by the tradeoff between complexity and completeness.},
	number = {3},
	journal = {Cognitive psychology},
	author = {Brown, Scott D and Heathcote, Andrew},
	month = nov,
	year = {2008},
	keywords = {Choice Behavior, decision making, Empirical Research, Humans, Linear Models, Models, Psychological, Reaction Time},
	pages = {153--178}
}

@article{daw_uncertainty-based_2005,
	title = {Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control},
	volume = {8},
	issn = {1097-6256},
	abstract = {A broad range of neural and behavioral data suggests that the brain contains multiple systems for behavioral choice, including one associated with prefrontal cortex and another with dorsolateral striatum. However, such a surfeit of control raises an additional choice problem: how to arbitrate between the systems when they disagree. Here, we consider dual-action choice systems from a normative perspective, using the computational theory of reinforcement learning. We identify a key trade-off pitting computational simplicity against the flexible and statistically efficient use of experience. The trade-off is realized in a competition between the dorsolateral striatal and prefrontal systems. We suggest a Bayesian principle of arbitration between them according to uncertainty, so each controller is deployed when it should be most accurate. This provides a unifying account of a wealth of experimental evidence about the factors favoring dominance by either system.},
	number = {12},
	journal = {Nature neuroscience},
	author = {Daw, Nathaniel D and Niv, Yael and Dayan, Peter},
	month = dec,
	year = {2005},
	keywords = {Animals, Bayes Theorem, Cognition, decision making, Humans, Models, Neurological, Neostriatum, Neural Networks (Computer), Neural Pathways, Prefrontal Cortex, Volition},
	pages = {1704--1711}
}

@article{bogacz_humans_2010,
	title = {Do humans produce the speed-accuracy trade-off that maximizes reward rate?},
	volume = {63},
	issn = {1747-0226},
	abstract = {In this paper we investigate trade-offs between speed and accuracy that are produced by humans when confronted with a sequence of choices between two alternatives. We assume that the choice process is described by the drift diffusion model, in which the speed-accuracy trade-off is primarily controlled by the value of the decision threshold. We test the hypothesis that participants choose the decision threshold that maximizes reward rate, defined as an average number of rewards per unit of time. In particular, we test four predictions derived on the basis of this hypothesis in two behavioural experiments. The data from all participants of our experiments provide support only for some of the predictions, and on average the participants are slower and more accurate than predicted by reward rate maximization. However, when we limit our analysis to subgroups of 30-50\% of participants who earned the highest overall rewards, all the predictions are satisfied by the data. This suggests that a substantial subset of participants do select decision thresholds that maximize reward rate. We also discuss possible reasons why the remaining participants select thresholds higher than optimal, including the possibility that participants optimize a combination of reward rate and accuracy or that they compensate for the influence of timing uncertainty, or both.},
	number = {5},
	journal = {Quarterly journal of experimental psychology (2006)},
	author = {Bogacz, Rafal and Hu, Peter T and Holmes, Philip and Cohen, Jonathan D},
	month = may,
	year = {2010},
	keywords = {Choice Behavior, decision making, Female, Humans, Male, Models, Psychological, Motion Perception, Photic Stimulation, Predictive Value of Tests, Probability, Psychomotor Performance, Reaction Time, Reinforcement Schedule, Reward, Young Adult},
	pages = {863--891}
}

@article{thura_decision_2012,
	title = {Decision making by urgency gating: theory and experimental support},
	volume = {108},
	copyright = {Copyright © 2012 the American Physiological Society},
	issn = {0022-3077, 1522-1598},
	shorttitle = {Decision making by urgency gating},
	abstract = {It is often suggested that decisions are made when accumulated sensory information reaches a fixed accuracy criterion. This is supported by many studies showing a gradual build up of neural activity to a threshold. However, the proposal that this build up is caused by sensory accumulation is challenged by findings that decisions are based on information from a time window much shorter than the build-up process. Here, we propose that in natural conditions where the environment can suddenly change, the policy that maximizes reward rate is to estimate evidence by accumulating only novel information and then compare the result to a decreasing accuracy criterion. We suggest that the brain approximates this policy by multiplying an estimate of sensory evidence with a motor-related urgency signal and that the latter is primarily responsible for neural activity build up. We support this hypothesis using human behavioral data from a modified random-dot motion task in which motion coherence changes during each trial.},
	number = {11},
	urldate = {2016-06-17},
	journal = {Journal of Neurophysiology},
	author = {Thura, David and Beauregard-Racine, Julie and Fradet, Charles-William and Cisek, Paul},
	month = dec,
	year = {2012},
	pages = {2912--2930},
	file = {Full Text PDF:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\NIW429KA\\Thura et al. - 2012 - Decision making by urgency gating theory and expe.pdf:application/pdf;Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\2TUGKASN\\2912.full.html:text/html}
}

@article{sanders_decision_1967,
	title = {Decision making during paced arrival of probabilistic information},
	volume = {27},
	issn = {0001-6918},
	abstract = {Four exploratory experiments are described in which the basic assumptions of the Edwards-Wald model for decision making in probabilistic sequential tasks are tested. The assumptions are (1) continuous revision of the likelihood ratio on the basis of incoming data and (2) a fixed decision criterion on the basis of costs and pay-offs. The results suggest that the decision criterion shifts from rather strict to quite risky as clear evidence is postponed, so that the criterion is certainly not fixed. The findings were not contrary to the idea of revision of the likelihood ratio.},
	urldate = {2016-08-13},
	journal = {Acta Psychologica},
	author = {Sanders, A. F. and Linden, W. Ter},
	month = jan,
	year = {1967},
	pages = {170--177},
	file = {ScienceDirect Snapshot:C\:\\Users\\arakhoda\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\2riejh4m.default\\zotero\\storage\\K5NTMBE7\\0001691867900571.html:text/html}
}

@book{townsend_stochastic_1983,
	title = {The {Stochastic} {Modeling} of {Elementary} {Psychological} {Processes}},
	isbn = {978-0-521-27433-3},
	publisher = {Cambridge University Press},
	author = {Townsend, James T and Ashby, F. Gregory},
	year = {1983}
}

@misc{noauthor_instacart_2017,
	title = {Instacart {Market} {Basket} {Analysis}},
	url = {https://www.kaggle.com/c/instacart-market-basket-analysis},
	year = {2017}
}

@article{ribas-fernandes_neural_2011,
	title = {A neural signature of hierarchical reinforcement learning},
	volume = {71},
	issn = {1097-4199},
	abstract = {Human behavior displays hierarchical structure: simple actions cohere into subtask sequences, which work together to accomplish overall task goals. Although the neural substrates of such hierarchy have been the target of increasing research, they remain poorly understood. We propose that the computations supporting hierarchical behavior may relate to those in hierarchical reinforcement learning (HRL), a machine-learning framework that extends reinforcement-learning mechanisms into hierarchical domains. To test this, we leveraged a distinctive prediction arising from HRL. In ordinary reinforcement learning, reward prediction errors are computed when there is an unanticipated change in the prospects for accomplishing overall task goals. HRL entails that prediction errors should also occur in relation to task subgoals. In three neuroimaging studies we observed neural responses consistent with such subgoal-related reward prediction errors, within structures previously implicated in reinforcement learning. The results reported support the relevance of HRL to the neural processes underlying hierarchical behavior.},
	number = {2},
	journal = {Neuron},
	author = {Ribas-Fernandes, José J F and Solway, Alec and Diuk, Carlos and McGuire, Joseph T and Barto, Andrew G and Niv, Yael and Botvinick, Matthew},
	month = jul,
	year = {2011},
	pmid = {21791294},
	keywords = {Adolescent, Adult, Brain, Brain Mapping, Brain Waves, Computer Simulation, Electroencephalography, Female, Humans, Image Processing, Computer-Assisted, Linear Models, Magnetic Resonance Imaging, Male, Models, Biological, Oxygen, Psychomotor Performance, Reinforcement (Psychology), Young Adult},
	pages = {370--379}
}

@article{van_zandt_comparison_2000,
	title = {A comparison of two response time models applied to perceptual matching},
	volume = {7},
	issn = {1069-9384},
	abstract = {Two models, a Poisson race model and a diffusion model, are fit to data from a perceptual matching task. In each model, information about the similarity or the difference between two stimuli accumulates toward thresholds for either response. Stimulus variables are assumed to influence the rate at which information accumulates, and response variables are assumed to influence the level of the response thresholds. Three experiments were conducted to assess the performance of each model. In Experiment 1, observers performed under different response deadlines; in Experiment 2, response bias was manipulated by changing the relative frequency of same and different stimuli. In Experiment 3, stimulus pairs were presented at three eccentricities: foveal, parafoveal, and peripheral. We examined whether the race and diffusion models could fit the response time and accuracy data through changes only in response parameters (for Experiments 1 and 2) or stimulus parameters (for Experiment 3). Comparisons between the two models suggest that the race model, which has not been studied extensively, can account for perceptual matching data at least as well as the diffusion model. Furthermore, without the constraints on the parameters provided by the experimental conditions, the diffusion and the race models are indistinguishable. This finding emphasizes the importance of fitting models across several conditions and imposing logical psychological constraints on the parameters of models.},
	number = {2},
	journal = {Psychonomic bulletin \& review},
	author = {Van Zandt, Trisha and Colonius, Hans and Proctor, R W},
	month = jun,
	year = {2000},
	keywords = {Adult, Data Interpretation, Statistical, Discrimination Learning, Female, Humans, Male, Models, Psychological, Models, Statistical, Pattern Recognition, Visual, Poisson Distribution, Probability Learning, Psychomotor Performance, Reaction Time, Statistical Distributions},
	pages = {208--256}
}

@article{busemeyer_survey_2002,
	series = {Random {Utility} {Theory} and {Probabilistic} measurement theory},
	title = {Survey of decision field theory},
	volume = {43},
	issn = {0165-4896},
	abstract = {This article summarizes the cumulative progress of a cognitive-dynamical approach to decision making and preferential choice called decision field theory. This review includes applications to (a) binary decisions among risky and uncertain actions, (b) multi-attribute preferential choice, (c) multi-alternative preferential choice, and (d) certainty equivalents such as prices. The theory provides natural explanations for violations of choice principles including strong stochastic transitivity, independence of irrelevant alternatives, and regularity. The theory also accounts for the relation between choice and decision time, preference reversals between choice and certainty equivalents, and preference reversals under time pressure. Comparisons with other dynamic models of decision-making and other random utility models of preference are discussed.},
	number = {3},
	urldate = {2014-10-25},
	journal = {Mathematical Social Sciences},
	author = {Busemeyer, Jerome R and Diederich, Adele},
	month = jul,
	year = {2002},
	keywords = {Diffusion models, Dynamic decisions, Multi-alternative choice, Multi-attribute choice, Random utility, Regularity violations, Stochastic choice},
	pages = {345--370}
}